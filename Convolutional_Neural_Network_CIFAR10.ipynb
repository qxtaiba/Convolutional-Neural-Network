{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "kernel6c16c03324.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2e6d4d5b8664890a6b4684734f1c26f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c99b341268204bbc8d30914543170707",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2aef6fa1ab04e41a55b30293130465e",
              "IPY_MODEL_c9fa43577f14433fbd55aac89abdd569"
            ]
          }
        },
        "c99b341268204bbc8d30914543170707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2aef6fa1ab04e41a55b30293130465e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0fe44369d9324cc98ca01ec504e79c2b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01f4952a6b754d9c8c30a66538c36ca7"
          }
        },
        "c9fa43577f14433fbd55aac89abdd569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f96dad039f646eb87010ea1315278cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 14924754.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfda701ae77e49db9d9184c14a0094ec"
          }
        },
        "0fe44369d9324cc98ca01ec504e79c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01f4952a6b754d9c8c30a66538c36ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f96dad039f646eb87010ea1315278cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfda701ae77e49db9d9184c14a0094ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhiqsL5yq6Hs",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "Image classification is the process of taking an input (like a picture) and outputting a class (like “cat”) or a probability that the input is a particular class (“there’s a 90% probability that this input is a cat”). You can look at a picture and know that you’re looking at a terrible shot of your own face, but how can a computer learn to do that? With a convolutional neural network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWvKzRSFq6Ht",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "# Goals\n",
        "We would like you to establish a neural network involving advance DNN modules (i.e. convolution layers, RELU, pooling and fully connection layers and etc.)  to distinguish the specific category of an input image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWnbisS1q6Ht",
        "colab_type": "text"
      },
      "source": [
        "-------------\n",
        "## Packages\n",
        "Let's first import the necessary packages,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq65JNo8q6Hu",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import warnings\n",
        "from collections import namedtuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.jit.annotations import Optional, Tuple\n",
        "from torch import Tensor\n",
        "from torch.optim import lr_scheduler\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWTZ6Qpq6Hx",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "## GPU Device Configuration\n",
        "Then, we set up and configure our computational devices: \n",
        "Whether we use GPU or perform the calculation on CPU.\n",
        "we use the torch.devices() and torch.cude.is_available() functions to configure our computational devices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I16peTAIq6Hy",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "413ab277-0fc2-4c21-a3f5-ca607d58e4ae"
      },
      "source": [
        "torch.cuda.is_available()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2utskPq6H1",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "## Configuration\n",
        "### hyper parameters\n",
        "We then set up and hyper parameters that need for the our model.\n",
        "we need to define several hyper parameters for our model:\n",
        "1. learning rate\n",
        "2. batch size when training\n",
        "3. batch size when testing\n",
        "4. numbper of epoches\n",
        "5. out put directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crJlLMCsq6H1",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.0001\n",
        "batch_size_training = 128\n",
        "batch_size_testing = 128\n",
        "epoches = 25\n",
        "filename = \"./output\"\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    os.makedirs(filename)\n",
        "\n",
        "filename = \"./data\"\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    os.makedirs(filename)\n",
        "\n",
        "filename = \"./figures\"\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    os.makedirs(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtomIyL9q6H4",
        "colab_type": "text"
      },
      "source": [
        "Create a directory if not exists\n",
        "using os.path.exists() to check whether it is exist\n",
        "using os.makedires to create a directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GDJ-gbJq6H8",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "##  Data Loading\n",
        "Next, we are going to load our data. \n",
        "### We need to prepare our data:\n",
        "\n",
        "### We first import necessary librarys for data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0niU_NAcq6H8",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os.path\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torchvision.datasets as dset\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from ipywidgets import IntProgress\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDlC_wnLq6H_",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "###  Image processing\n",
        "Then, we define a image preprocessing object that our dataloader can directly use this object to preprocess our data\n",
        "We use the pytorch API to preform the data processing.\n",
        "1. Use transforms.Compose()\n",
        "2. Use .RandomHorizontalFlip()\n",
        "3. You add any extra transforms you like.\n",
        "4. Create this transform for both training set and testting set. Note that the testing spilit do not require any transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGh4aoWlq6IA",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_training = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "transform_testing = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozqPzNXNq6IC",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "### We then download and prepare the data with the transforms defined above:\n",
        "1. Use command torchvision.datasets.CIFAR10() with root, train, download and transform posional arguments.\n",
        "2. Use the same command to create both train split and test split.\n",
        "3. Use torch.utils.data.DataLoader() to create the data loader based on the data we have.\n",
        "3. Use this command for both training split data loader and test split data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSwS9tJfq6ID",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "f2e6d4d5b8664890a6b4684734f1c26f",
            "c99b341268204bbc8d30914543170707",
            "e2aef6fa1ab04e41a55b30293130465e",
            "c9fa43577f14433fbd55aac89abdd569",
            "0fe44369d9324cc98ca01ec504e79c2b",
            "01f4952a6b754d9c8c30a66538c36ca7",
            "6f96dad039f646eb87010ea1315278cf",
            "dfda701ae77e49db9d9184c14a0094ec"
          ]
        },
        "outputId": "3f4f7ba7-6a34-40ab-a757-4939297bcef6"
      },
      "source": [
        "cifar_training = dset.CIFAR10(root=\"./data\", train = True, transform = transform_training, download = True )\n",
        "cifar_testing = dset.CIFAR10(root=\"./data\", train = False, transform = transform_testing, download = True )\n",
        "\n",
        "data_loader_training = data.DataLoader(dataset = cifar_training, batch_size=batch_size_training,)\n",
        "data_loader_testing = data.DataLoader( dataset =cifar_testing, batch_size = batch_size_testing)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e6d4d5b8664890a6b4684734f1c26f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bngWwEbq6IF",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "##  Network\n",
        "Next, we are going to design our GoogLeNet\n",
        "### First, we define our GoogLeNet class\n",
        "### You need to refer the paepr below to understand the structure.\n",
        "### https://arxiv.org/abs/1409.4842\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bbYcqS0q6IG",
        "colab_type": "text"
      },
      "source": [
        "------\n",
        "### Inception Module with dimension reductions (There exist many implement methods)\n",
        "1. Create a python class called Inception which inherits nn.module\n",
        "\n",
        "2. Create a init function to init this python class\n",
        "    1. Require in_planes, kernel_1_x, kernel_3_in, kernel_3_x, kernel_5_in, kernel_5_x and pool_planes 7 arguments.\n",
        "    \n",
        "    2. Consists of 4 variables b1,b2,b3,b4\n",
        "    \n",
        "    3. b1 is a block consists of 2D convaluation, a 2D batch normalization layer and a ReLU activation function\n",
        "    \n",
        "    4. b2 is a block consists of tow 2D convaluations, two 2D batch normalization layers and tow ReLU activation functions\n",
        "    \n",
        "    5. b3 is a block consists of three 2D convaluations, three 2D batch normalization layers and three ReLU activation functions\n",
        "    \n",
        "    6. b4 is a block consists of a Maxpooling layer, a 2D convaluation, a 2D batch normalization layer and a ReLU activation function\n",
        "    \n",
        "3. Create the forward function\n",
        "\n",
        "    1. this forward function will forward the input function though every block and return the concatenation of all the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQCBRK6vq6IH",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_planes, kernel_1_x, kernel_3_in, kernel_3_x, kernel_5_in, kernel_5_x, pool_planes):\n",
        "        super(Inception, self).__init__()\n",
        "    \n",
        "        # 1x1 conv branch\n",
        "        self.b1 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, kernel_1_x, kernel_size=1),\n",
        "            nn.BatchNorm2d(kernel_1_x),\n",
        "            nn.ReLU(True))\n",
        "\n",
        "        # 1x1 conv -> 3x3 conv branch\n",
        "        self.b2 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, kernel_3_in, kernel_size=1),\n",
        "            nn.BatchNorm2d(kernel_3_in),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(kernel_3_in, kernel_3_x, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(kernel_3_x),\n",
        "            nn.ReLU(True))\n",
        "\n",
        "        # 1x1 conv -> 5x5 conv branch\n",
        "        self.b3 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, kernel_5_in, kernel_size=1),\n",
        "            nn.BatchNorm2d(kernel_5_in),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(kernel_5_in, kernel_5_x, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(kernel_5_x),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(kernel_5_x, kernel_5_x, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(kernel_5_x),\n",
        "            nn.ReLU(True))\n",
        "\n",
        "        # 3x3 pool -> 1x1 conv branch\n",
        "        self.b4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
        "            nn.BatchNorm2d(pool_planes),\n",
        "            nn.ReLU(True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.b1(x)\n",
        "        y2 = self.b2(x)\n",
        "        y3 = self.b3(x)\n",
        "        y4 = self.b4(x)\n",
        "        return torch.cat([y1,y2,y3,y4], 1)\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C1G2kHwq6IJ",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "### GoogLeNet Module (There exist many implement methods)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkowiWarq6IK",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"./Picture1.png\" height=\"1000\" width=\"10000\">\n",
        "\n",
        "\n",
        "1. Create a python class called GoogLeNet which inherits nn.module\n",
        "\n",
        "2. Create a init function to init this python class\n",
        "\n",
        "    1. Consists of a variables that serves as all layers before the inception, which contains a 2D convaluation with padding=1, kernel_size=3 output channel=192, a 2D batch normalization layer and a ReLU activation fucntion.\n",
        "    \n",
        "    3. Two Inception block\n",
        "    \n",
        "    4. Maxpooling layer\n",
        "    \n",
        "    5. Seven Inception block\n",
        "    \n",
        "    6. Average Pooling layer\n",
        "    \n",
        "    7. A fully connected layer.\n",
        "    \n",
        "3. Create the forward function\n",
        "\n",
        "    1. this forward function will forward the input function though every block and return the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2bvVqlQq6IL",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "\n",
        "        self.pre_inception = nn.Sequential(\n",
        "            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(True))\n",
        "        \n",
        "        self.inception_block_1 = Inception(192,  64,  96, 128, 16, 32, 32)\n",
        "        self.inception_block_2 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.inception_block_3 = Inception(480, 192,  96, 208, 16,  48,  64)\n",
        "        self.inception_block_4 = Inception(512, 160, 112, 224, 24,  64,  64)\n",
        "        self.inception_block_5 = Inception(512, 128, 128, 256, 24,  64,  64)\n",
        "        self.inception_block_6 = Inception(512, 112, 144, 288, 32,  64,  64)\n",
        "        self.inception_block_7 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception_block_8 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception_block_9 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.average_pool = nn.AvgPool2d(8, stride=1)\n",
        "\n",
        "        self.fully_connected_layer = nn.Linear(1024,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        output = self.pre_inception(x)\n",
        "        output = self.inception_block_1(output)\n",
        "        output = self.inception_block_2(output)\n",
        "        output = self.max_pool(output)\n",
        "        output = self.inception_block_3(output)\n",
        "        output = self.inception_block_4(output)\n",
        "        output = self.inception_block_5(output)\n",
        "        output = self.inception_block_6(output)\n",
        "        output = self.inception_block_7(output)\n",
        "        output = self.max_pool(output)\n",
        "        output = self.inception_block_8(output)\n",
        "        output = self.inception_block_9(output)\n",
        "        output = self.average_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.fully_connected_layer(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLTA-YmSq6IP",
        "colab_type": "text"
      },
      "source": [
        "### Next, we create the networka and send it to the target device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AZw8dMoq6IP",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8a8500e-6dc7-420c-ddd1-b6564167070e"
      },
      "source": [
        "network = GoogLeNet()\n",
        "network.to(device)\n",
        "\n",
        "# if device == 'cuda':\n",
        "#     network = torch.nn.DataParallel(net)\n",
        "#     cudnn.benchmark = True"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (pre_inception): Sequential(\n",
              "    (0): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (inception_block_1): Inception(\n",
              "    (b1): Sequential(\n",
              "      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_block_2): Inception(\n",
              "    (b1): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (inception_block_3): Inception(\n",
              "    (b1): Sequential(\n",
              "      (0): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_block_4): Inception(\n",
              "    (b1): Sequential(\n",
              "      (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_block_5): Inception(\n",
              "    (b1): Sequential(\n",
              "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_block_6): Inception(\n",
              "    (b1): Sequential(\n",
              "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_block_7): Inception(\n",
              "    (b1): Sequential(\n",
              "      (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_block_8): Inception(\n",
              "    (b1): Sequential(\n",
              "      (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_block_9): Inception(\n",
              "    (b1): Sequential(\n",
              "      (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (average_pool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "  (fully_connected_layer): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CttdPKaKq6IS",
        "colab_type": "text"
      },
      "source": [
        "### Finally, We create:\n",
        " 1. an optimizer  (we use adam optimzer here)\n",
        " 2. A Criterion (CrossEntropy) function\n",
        " 3. A Scheduler which is used to decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-cfqJgzOUDU",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b2PmOgFq6IU",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "##  Training\n",
        "Then, we are going to train our Network\n",
        "\n",
        "1. Set our network to the training model.\n",
        "2. Init the train loss, total data and number corrected predictions. \n",
        "3. For each data in the training split\n",
        "    1. Put the data to the correct devices using .to()\n",
        "    2. Reset the gradient of the optimzier.\n",
        "    3. Feed the data forward to the google net\n",
        "    4. Use the criterion function to compute the loss term\n",
        "    5. Backprop the loss\n",
        "    6. Update the network parameters using the optimzier\n",
        "    7. Accumulate the training loss\n",
        "    8. Find the prediciton. hint: using torch.max()\n",
        "    9. Increment the data size\n",
        "    10. Increment the corrected prediction\n",
        "    11. Print log\n",
        "    \n",
        "-----\n",
        "##  Testing\n",
        "Then, we are going to test our module\n",
        "\n",
        "1. Set our network to the test model.\n",
        "2. Init the test loss, total data and number corrected predictions. \n",
        "3. For each data in the training split, we warp it using torch.no_grad()\n",
        "    1. Put the data to the correct devices using .to()\n",
        "    2. Feed the data forward to the google net\n",
        "    3. Use the criterion function to compute the loss term\n",
        "    4. Accumulate the training loss\n",
        "    5. Find the prediciton. hint: using torch.max()\n",
        "    6. Increment the data size\n",
        "    7. Increment the corrected prediction\n",
        "    8. Print log\n",
        "\n",
        "-----\n",
        "##  Epochs:\n",
        "For each epoch:\n",
        "1. we first step our scheduler\n",
        "2. we train our module\n",
        "3. we test our module\n",
        "4. we update the testing accuracy\n",
        "5. we save the module at the end and print the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd7ok4HEL55Q",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_nn():\n",
        "    network.train()\n",
        "    accum_training_loss = 0\n",
        "    total_data = 0\n",
        "    correc_pred = 0\n",
        "    for j, (image, label) in enumerate(data_loader_training):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = network(image)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        accum_training_loss += loss.data\n",
        "        temp, prediction = torch.max(output.data,1)\n",
        "        total_data += label.size(0)\n",
        "        correc_pred += (prediction == label).sum()\n",
        "    scheduler.step()\n",
        "\n",
        "    return accum_training_loss, total_data, correc_pred\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qLzAgZxL6HQ",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_nn():\n",
        "    network.eval()\n",
        "    accum_training_loss = 0\n",
        "    total_data = 0\n",
        "    correc_pred = 0\n",
        "    with torch.no_grad():            \n",
        "        for j, (image, label) in enumerate(data_loader_testing):\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "            output = network(image)\n",
        "            loss = criterion(output, label)\n",
        "            accum_training_loss += loss.data\n",
        "            temp, prediction = torch.max(output.data,1)\n",
        "            total_data += label.size(0)\n",
        "            correc_pred += (prediction == label).sum()\n",
        "\n",
        "    return accum_training_loss, total_data, correc_pred\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zms4lAZiL6PB",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "311bd807-a484-46cf-8eb7-e544256f737a"
      },
      "source": [
        "test_accuracy_list, train_accuracy_list, accum_training_loss_test_list, accum_training_loss_train_list,learning_rate_list = [], [], [], [], []\n",
        "\n",
        "best_accuracy = 0\n",
        "\n",
        "for i in range(epoches):\n",
        "    \n",
        "    print(\"Epoch {} | Learning Rate {}\".format(i, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "    accum_training_loss_train, total_data_train, correc_pred_train = train_nn()\n",
        "    accum_training_loss_test, total_data_test, correc_pred_test = test_nn()\n",
        "\n",
        "    test_accuracy = (correc_pred_test.item()/total_data_test)*100\n",
        "    train_accuracy = (correc_pred_train.item()/total_data_train)*100\n",
        "\n",
        "    print(\"\\tTrain Accuracy {}, Test Accuracy {}\".format(train_accuracy, test_accuracy),end=\"\")\n",
        "    print(\", Train Loss {}, Test Loss {}\" .format(accum_training_loss_train, accum_training_loss_test))\n",
        "\n",
        "    if test_accuracy > best_accuracy:\n",
        "        \n",
        "        state = {\n",
        "            'net': network.state_dict(),\n",
        "            'epoch': i,\n",
        "            'train accuracy': train_accuracy,\n",
        "            'test accuracy': test_accuracy,\n",
        "            'train loss': accum_training_loss_train,\n",
        "            'test loss': accum_training_loss_test\n",
        "        }\n",
        "        torch.save(state, './output/output.pt')\n",
        "\n",
        "    test_accuracy_list.append(test_accuracy)\n",
        "    train_accuracy_list.append(train_accuracy)\n",
        "    accum_training_loss_test_list.append(accum_training_loss_test)\n",
        "    accum_training_loss_train_list.append(accum_training_loss_train)\n",
        "    learning_rate_list.append(optimizer.param_groups[0]['lr'])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 54.02400000000001, Test Accuracy 63.75999999999999, Train Loss 499.54083251953125, Test Loss 80.78498077392578\n",
            "Epoch 1 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 70.658, Test Accuracy 72.95, Train Loss 325.8468933105469, Test Loss 62.8060302734375\n",
            "Epoch 2 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 77.99000000000001, Test Accuracy 77.4, Train Loss 248.5711669921875, Test Loss 53.15684127807617\n",
            "Epoch 3 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 82.646, Test Accuracy 80.99, Train Loss 198.86416625976562, Test Loss 44.68674850463867\n",
            "Epoch 4 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 85.33800000000001, Test Accuracy 81.38, Train Loss 168.89962768554688, Test Loss 43.61044692993164\n",
            "Epoch 5 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 87.484, Test Accuracy 83.94, Train Loss 144.39846801757812, Test Loss 40.017173767089844\n",
            "Epoch 6 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 89.134, Test Accuracy 82.84, Train Loss 123.42965698242188, Test Loss 41.83345031738281\n",
            "Epoch 7 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 90.632, Test Accuracy 84.11, Train Loss 107.01225280761719, Test Loss 40.49107360839844\n",
            "Epoch 8 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 91.83, Test Accuracy 84.58, Train Loss 93.55431365966797, Test Loss 40.14958190917969\n",
            "Epoch 9 | Learning Rate 0.0001\n",
            "\tTrain Accuracy 92.932, Test Accuracy 85.44, Train Loss 81.18193817138672, Test Loss 37.94896697998047\n",
            "Epoch 10 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 95.836, Test Accuracy 88.77000000000001, Train Loss 51.62763214111328, Test Loss 29.126331329345703\n",
            "Epoch 11 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 96.898, Test Accuracy 89.12, Train Loss 39.29726028442383, Test Loss 28.768169403076172\n",
            "Epoch 12 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 97.436, Test Accuracy 89.33, Train Loss 34.04890823364258, Test Loss 28.761653900146484\n",
            "Epoch 13 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 97.76599999999999, Test Accuracy 89.41, Train Loss 30.053634643554688, Test Loss 28.807275772094727\n",
            "Epoch 14 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 98.134, Test Accuracy 89.2, Train Loss 26.462690353393555, Test Loss 30.24808120727539\n",
            "Epoch 15 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 98.398, Test Accuracy 89.3, Train Loss 23.176984786987305, Test Loss 29.701021194458008\n",
            "Epoch 16 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 98.636, Test Accuracy 89.3, Train Loss 20.776500701904297, Test Loss 30.059038162231445\n",
            "Epoch 17 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 98.81400000000001, Test Accuracy 89.36, Train Loss 18.74831199645996, Test Loss 31.401899337768555\n",
            "Epoch 18 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 99.05000000000001, Test Accuracy 89.4, Train Loss 15.987088203430176, Test Loss 31.634536743164062\n",
            "Epoch 19 | Learning Rate 1e-05\n",
            "\tTrain Accuracy 99.236, Test Accuracy 89.46, Train Loss 13.854412078857422, Test Loss 31.707244873046875\n",
            "Epoch 20 | Learning Rate 1.0000000000000002e-06\n",
            "\tTrain Accuracy 99.334, Test Accuracy 89.60000000000001, Train Loss 12.347585678100586, Test Loss 30.91712188720703\n",
            "Epoch 21 | Learning Rate 1.0000000000000002e-06\n",
            "\tTrain Accuracy 99.324, Test Accuracy 89.67, Train Loss 11.642020225524902, Test Loss 30.698272705078125\n",
            "Epoch 22 | Learning Rate 1.0000000000000002e-06\n",
            "\tTrain Accuracy 99.42999999999999, Test Accuracy 89.73, Train Loss 11.068970680236816, Test Loss 30.777179718017578\n",
            "Epoch 23 | Learning Rate 1.0000000000000002e-06\n",
            "\tTrain Accuracy 99.478, Test Accuracy 89.75, Train Loss 10.383949279785156, Test Loss 30.815250396728516\n",
            "Epoch 24 | Learning Rate 1.0000000000000002e-06\n",
            "\tTrain Accuracy 99.528, Test Accuracy 89.68, Train Loss 10.487438201904297, Test Loss 30.884929656982422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBN-N8uGFzxG",
        "colab_type": "text"
      },
      "source": [
        "## Graphing Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sbU-_sVAtk4",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "94356ff2-ad6f-4636-804b-5dae0d8016e5"
      },
      "source": [
        "x = [i for i in range(25)]\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(x,test_accuracy_list,\"g\")\n",
        "plt.plot(x,train_accuracy_list,\"r\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training/Validation Accuracy\")\n",
        "ax = plt.subplot(111)\n",
        "ax.plot(x, test_accuracy_list, label = \"Validation\")\n",
        "ax.plot(x, train_accuracy_list, label= \"Training\")\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n",
        "plt.show()\n",
        "plt.savefig('./figures/accuracyFig.png')\n",
        "\n",
        "train_loss_list = [x / len(data_loader_training) for x in accum_training_loss_train_list]\n",
        "test_loss_list = [x / len(data_loader_testing) for x in accum_training_loss_test_list]\n",
        "\n",
        "plt.plot(x,train_loss_list)\n",
        "plt.plot(x,test_loss_list)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training/Validation Loss Convergence\")\n",
        "ax = plt.subplot(111)\n",
        "ax.plot(x, test_loss_list, label = \"Validation\")\n",
        "ax.plot(x, train_loss_list, label= \"Training\")\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n",
        "plt.show()\n",
        "plt.savefig('./figures/lossFig.png')\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORKM8p22GGss",
        "colab_type": "text"
      },
      "source": [
        "## Tabling Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEkiTOYHo1vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "a6100342-2aa6-465e-8a3b-f1eb2130609e"
      },
      "source": [
        "train_loss_table = []\n",
        "test_loss_table = []\n",
        "for i in range(len(accum_training_loss_train_list)):\n",
        "    train_loss_table.append(accum_training_loss_train_list[i].item())\n",
        "for i in range(len(accum_training_loss_test_list)):\n",
        "    test_loss_table.append(accum_training_loss_test_list[i].item())\n",
        "\n",
        "df = pd.DataFrame({\"Epoch\": x, \"Learn Rate\": learning_rate_list,\"Train Loss\":train_loss_table, \"Test Loss\":test_loss_table, \"Train Acc.\":train_accuracy_list, \"Test Acc.\": test_accuracy_list})\n",
        "df\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Learn Rate</th>\n",
              "      <th>Train Loss</th>\n",
              "      <th>Test Loss</th>\n",
              "      <th>Train Acc.</th>\n",
              "      <th>Test Acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>499.540833</td>\n",
              "      <td>80.784981</td>\n",
              "      <td>54.024</td>\n",
              "      <td>63.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>325.846893</td>\n",
              "      <td>62.806030</td>\n",
              "      <td>70.658</td>\n",
              "      <td>72.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>248.571167</td>\n",
              "      <td>53.156841</td>\n",
              "      <td>77.990</td>\n",
              "      <td>77.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>198.864166</td>\n",
              "      <td>44.686749</td>\n",
              "      <td>82.646</td>\n",
              "      <td>80.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>168.899628</td>\n",
              "      <td>43.610447</td>\n",
              "      <td>85.338</td>\n",
              "      <td>81.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>144.398468</td>\n",
              "      <td>40.017174</td>\n",
              "      <td>87.484</td>\n",
              "      <td>83.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>123.429657</td>\n",
              "      <td>41.833450</td>\n",
              "      <td>89.134</td>\n",
              "      <td>82.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>107.012253</td>\n",
              "      <td>40.491074</td>\n",
              "      <td>90.632</td>\n",
              "      <td>84.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>93.554314</td>\n",
              "      <td>40.149582</td>\n",
              "      <td>91.830</td>\n",
              "      <td>84.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>81.181938</td>\n",
              "      <td>37.948967</td>\n",
              "      <td>92.932</td>\n",
              "      <td>85.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>51.627632</td>\n",
              "      <td>29.126331</td>\n",
              "      <td>95.836</td>\n",
              "      <td>88.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>39.297260</td>\n",
              "      <td>28.768169</td>\n",
              "      <td>96.898</td>\n",
              "      <td>89.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>34.048908</td>\n",
              "      <td>28.761654</td>\n",
              "      <td>97.436</td>\n",
              "      <td>89.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>30.053635</td>\n",
              "      <td>28.807276</td>\n",
              "      <td>97.766</td>\n",
              "      <td>89.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>26.462690</td>\n",
              "      <td>30.248081</td>\n",
              "      <td>98.134</td>\n",
              "      <td>89.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>23.176985</td>\n",
              "      <td>29.701021</td>\n",
              "      <td>98.398</td>\n",
              "      <td>89.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>20.776501</td>\n",
              "      <td>30.059038</td>\n",
              "      <td>98.636</td>\n",
              "      <td>89.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>18.748312</td>\n",
              "      <td>31.401899</td>\n",
              "      <td>98.814</td>\n",
              "      <td>89.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>15.987088</td>\n",
              "      <td>31.634537</td>\n",
              "      <td>99.050</td>\n",
              "      <td>89.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>13.854412</td>\n",
              "      <td>31.707245</td>\n",
              "      <td>99.236</td>\n",
              "      <td>89.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>12.347586</td>\n",
              "      <td>30.917122</td>\n",
              "      <td>99.334</td>\n",
              "      <td>89.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>11.642020</td>\n",
              "      <td>30.698273</td>\n",
              "      <td>99.324</td>\n",
              "      <td>89.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>11.068971</td>\n",
              "      <td>30.777180</td>\n",
              "      <td>99.430</td>\n",
              "      <td>89.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>10.383949</td>\n",
              "      <td>30.815250</td>\n",
              "      <td>99.478</td>\n",
              "      <td>89.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>10.487438</td>\n",
              "      <td>30.884930</td>\n",
              "      <td>99.528</td>\n",
              "      <td>89.68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Epoch  Learn Rate  Train Loss  Test Loss  Train Acc.  Test Acc.\n",
              "0       0    0.000100  499.540833  80.784981      54.024      63.76\n",
              "1       1    0.000100  325.846893  62.806030      70.658      72.95\n",
              "2       2    0.000100  248.571167  53.156841      77.990      77.40\n",
              "3       3    0.000100  198.864166  44.686749      82.646      80.99\n",
              "4       4    0.000100  168.899628  43.610447      85.338      81.38\n",
              "5       5    0.000100  144.398468  40.017174      87.484      83.94\n",
              "6       6    0.000100  123.429657  41.833450      89.134      82.84\n",
              "7       7    0.000100  107.012253  40.491074      90.632      84.11\n",
              "8       8    0.000100   93.554314  40.149582      91.830      84.58\n",
              "9       9    0.000010   81.181938  37.948967      92.932      85.44\n",
              "10     10    0.000010   51.627632  29.126331      95.836      88.77\n",
              "11     11    0.000010   39.297260  28.768169      96.898      89.12\n",
              "12     12    0.000010   34.048908  28.761654      97.436      89.33\n",
              "13     13    0.000010   30.053635  28.807276      97.766      89.41\n",
              "14     14    0.000010   26.462690  30.248081      98.134      89.20\n",
              "15     15    0.000010   23.176985  29.701021      98.398      89.30\n",
              "16     16    0.000010   20.776501  30.059038      98.636      89.30\n",
              "17     17    0.000010   18.748312  31.401899      98.814      89.36\n",
              "18     18    0.000010   15.987088  31.634537      99.050      89.40\n",
              "19     19    0.000001   13.854412  31.707245      99.236      89.46\n",
              "20     20    0.000001   12.347586  30.917122      99.334      89.60\n",
              "21     21    0.000001   11.642020  30.698273      99.324      89.67\n",
              "22     22    0.000001   11.068971  30.777180      99.430      89.73\n",
              "23     23    0.000001   10.383949  30.815250      99.478      89.75\n",
              "24     24    0.000001   10.487438  30.884930      99.528      89.68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YrUndwcGWxo",
        "colab_type": "text"
      },
      "source": [
        "## Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_K4t_R5_Nbxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4d77b34b-a111-4e65-b9cf-8a47c5bc729a"
      },
      "source": [
        "model = torch.load('./output/output.pt')\n",
        "\n",
        "print(\"Number of Iterations:\", model[\"epoch\"])\n",
        "print(\"Training Accuracy:\", model[\"train accuracy\"])\n",
        "print(\"Testing Accuracy:\", model[\"test accuracy\"])\n",
        "print(\"Training Loss:\", model[\"train loss\"].item())\n",
        "print(\"Testing Loss:\", model[\"test loss\"].item())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Iterations: 24\n",
            "Training Accuracy: 99.528\n",
            "Testing Accuracy: 89.68\n",
            "Training Loss: 10.487438201904297\n",
            "Testing Loss: tensor(30.8849, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEnKArQNIRtO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9028285d-2dc3-4257-d21d-004afe0fe8eb"
      },
      "source": [
        "print(\"Model\", model[\"net\"])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         ...,\n",
            "\n",
            "         [[-0.0064]],\n",
            "\n",
            "         [[-0.0025]],\n",
            "\n",
            "         [[-0.0204]]],\n",
            "\n",
            "\n",
            "        [[[-0.0364]],\n",
            "\n",
            "         [[-0.0293]],\n",
            "\n",
            "         [[ 0.0397]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0427]],\n",
            "\n",
            "         [[ 0.0139]],\n",
            "\n",
            "         [[ 0.0163]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0080]],\n",
            "\n",
            "         [[-0.0056]],\n",
            "\n",
            "         [[-0.0015]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0329]],\n",
            "\n",
            "         [[-0.0407]],\n",
            "\n",
            "         [[ 0.0285]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0165]],\n",
            "\n",
            "         [[-0.0252]],\n",
            "\n",
            "         [[ 0.0147]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0292]],\n",
            "\n",
            "         [[-0.0148]],\n",
            "\n",
            "         [[ 0.0078]]],\n",
            "\n",
            "\n",
            "        [[[-0.0035]],\n",
            "\n",
            "         [[-0.0072]],\n",
            "\n",
            "         [[-0.0092]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0314]],\n",
            "\n",
            "         [[-0.0044]],\n",
            "\n",
            "         [[-0.0361]]],\n",
            "\n",
            "\n",
            "        [[[-0.0441]],\n",
            "\n",
            "         [[-0.0433]],\n",
            "\n",
            "         [[-0.0331]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0145]],\n",
            "\n",
            "         [[-0.0031]],\n",
            "\n",
            "         [[-0.0203]]]], device='cuda:0')), ('inception_block_7.b1.0.bias', tensor([-9.3877e-03,  2.6327e-02, -2.7750e-02,  2.5018e-02, -4.2331e-02,\n",
            "         2.5392e-02,  3.4903e-02,  2.6979e-02, -1.4143e-02, -1.7565e-02,\n",
            "        -4.3434e-02, -1.2982e-03,  2.1050e-02, -2.3246e-02, -2.7396e-02,\n",
            "        -4.2674e-02,  2.4485e-02,  1.8251e-02,  1.9325e-02, -2.3153e-02,\n",
            "         9.1230e-03, -3.3168e-02, -2.6100e-02,  1.1493e-02,  5.7169e-05,\n",
            "         3.2812e-02,  2.1140e-02, -4.1073e-02, -3.9529e-02, -7.4044e-03,\n",
            "        -1.9055e-02,  1.3185e-03, -3.7948e-02, -3.3059e-02,  1.4582e-02,\n",
            "         3.9986e-03,  1.8619e-03, -2.8562e-03,  2.3374e-02, -4.2513e-02,\n",
            "         1.3922e-02,  4.1899e-02,  3.6870e-02,  1.9824e-03, -2.1041e-02,\n",
            "        -2.8025e-02, -2.2062e-02,  1.5291e-02, -3.5419e-02,  2.6684e-02,\n",
            "        -5.0996e-03, -1.0137e-02,  1.2106e-02,  7.4212e-03,  2.4595e-02,\n",
            "         3.5413e-02, -2.8438e-02, -3.0151e-02, -4.9893e-03, -3.3959e-02,\n",
            "         4.3380e-02, -3.4119e-02,  3.5929e-02,  3.3671e-02,  2.1667e-02,\n",
            "        -3.7056e-02,  3.6151e-02,  1.6571e-02,  3.3397e-02,  6.6503e-03,\n",
            "         1.6421e-02,  2.2600e-02, -3.5540e-02,  2.6701e-02,  4.1842e-02,\n",
            "         9.2133e-03, -2.7888e-02,  3.4785e-02,  1.3246e-02,  1.0935e-02,\n",
            "         2.2815e-02, -4.0774e-03,  1.7312e-03,  1.5154e-02, -2.2498e-03,\n",
            "         2.8704e-02,  2.0614e-02,  2.4043e-02,  4.0306e-02,  9.4462e-03,\n",
            "        -1.3591e-02, -2.0860e-02, -3.6367e-02,  1.0824e-02,  3.4097e-03,\n",
            "         2.8272e-02,  2.3966e-02, -1.1827e-02, -1.8401e-02,  1.3352e-02,\n",
            "        -5.3597e-03, -2.7207e-02,  3.4105e-02,  1.9671e-03,  1.0911e-02,\n",
            "        -4.1021e-02,  2.9301e-02,  7.9843e-03,  2.3325e-02, -2.4143e-02,\n",
            "         1.0072e-02, -1.3441e-02,  1.6981e-02, -5.5215e-03,  6.1922e-03,\n",
            "         2.5868e-02, -4.2795e-02,  6.3249e-03, -1.5475e-03, -4.2172e-02,\n",
            "         1.9382e-02,  3.7341e-02,  4.2050e-02, -1.3557e-02, -1.9619e-02,\n",
            "         3.0569e-02, -3.8229e-02, -3.7899e-02,  1.7303e-02,  2.1633e-02,\n",
            "        -2.7564e-02,  1.9210e-02, -1.4107e-02,  5.9173e-03, -3.5388e-02,\n",
            "        -1.9833e-02, -3.5645e-02, -1.8206e-02, -8.3857e-03, -2.6319e-02,\n",
            "         1.5137e-02,  1.5620e-03, -9.3243e-03, -3.1267e-02, -3.4466e-02,\n",
            "        -1.2941e-02, -4.2715e-02, -3.1829e-02, -2.2268e-02, -1.3893e-02,\n",
            "         2.9485e-02,  1.7086e-02,  7.7061e-03,  3.7961e-02,  1.5288e-02,\n",
            "         3.0242e-02, -1.4454e-03,  1.2881e-02, -1.2318e-02, -2.2834e-02,\n",
            "         3.3878e-02, -2.2536e-02, -4.2246e-02, -1.0247e-02, -7.3872e-03,\n",
            "        -1.8544e-02,  2.4168e-02, -3.4584e-03,  2.8019e-02,  3.9422e-02,\n",
            "         3.8682e-02,  7.7654e-03,  2.2352e-02, -7.5120e-03, -3.5311e-02,\n",
            "         1.7865e-02,  3.4695e-02, -3.2187e-02,  4.3373e-02,  3.5467e-02,\n",
            "        -9.2643e-03,  3.8217e-02,  2.3985e-02, -3.7381e-02, -2.0212e-02,\n",
            "        -8.3602e-04,  1.9133e-02, -3.9791e-02,  6.3929e-03, -2.8691e-02,\n",
            "         2.3312e-02, -1.3292e-02,  8.9762e-03,  3.4083e-02, -3.4452e-03,\n",
            "        -3.2847e-03,  3.6687e-02, -4.1188e-02, -2.4744e-02, -3.5095e-03,\n",
            "        -1.7776e-02,  3.9993e-03, -1.4897e-02, -3.3341e-02, -2.0737e-02,\n",
            "        -1.7763e-03, -4.6196e-03, -3.1251e-02, -3.6381e-02, -4.2231e-02,\n",
            "        -2.8733e-02, -1.1726e-02, -3.9328e-02, -3.5635e-02,  3.9667e-03,\n",
            "        -1.5446e-02,  4.2872e-02, -3.1465e-02, -3.0889e-02, -1.1106e-03,\n",
            "        -3.9378e-02, -2.7271e-02, -1.0002e-02, -6.5019e-03,  2.0241e-03,\n",
            "        -1.3728e-02, -2.8275e-02, -2.2400e-02,  3.2848e-02,  1.7345e-02,\n",
            "        -4.2794e-02, -4.0629e-02, -2.6742e-02,  2.6060e-02, -9.9479e-03,\n",
            "        -2.4352e-02,  3.8293e-02,  4.4863e-03,  4.2556e-02,  1.5312e-02,\n",
            "        -3.7247e-02, -2.0935e-02, -4.0085e-02, -3.4917e-02,  1.9529e-02,\n",
            "        -3.0101e-02,  2.1478e-02, -6.5604e-03, -3.7325e-02, -2.5919e-02,\n",
            "        -9.6470e-03, -1.3555e-02,  4.0816e-02, -6.0637e-03, -3.4497e-02,\n",
            "        -2.9606e-02], device='cuda:0')), ('inception_block_7.b1.1.weight', tensor([1.0052, 0.9950, 1.0063, 0.9951, 0.9948, 1.0062, 0.9904, 1.0013, 0.9901,\n",
            "        0.9963, 0.9962, 0.9977, 1.0020, 0.9934, 0.9862, 1.0036, 0.9983, 1.0054,\n",
            "        1.0027, 0.9997, 0.9951, 1.0060, 1.0012, 1.0083, 0.9942, 0.9929, 1.0028,\n",
            "        1.0049, 1.0034, 0.9939, 1.0020, 1.0035, 1.0000, 1.0002, 0.9933, 0.9944,\n",
            "        1.0030, 0.9932, 1.0093, 0.9990, 1.0038, 1.0114, 0.9907, 0.9966, 0.9918,\n",
            "        0.9969, 1.0055, 0.9979, 0.9878, 0.9884, 0.9891, 1.0020, 1.0048, 0.9915,\n",
            "        1.0040, 0.9924, 0.9928, 1.0018, 1.0036, 0.9986, 0.9859, 0.9955, 0.9828,\n",
            "        0.9936, 1.0032, 0.9994, 1.0002, 1.0026, 0.9935, 1.0007, 0.9906, 1.0063,\n",
            "        0.9954, 0.9941, 1.0019, 0.9974, 0.9932, 0.9921, 1.0046, 0.9915, 1.0023,\n",
            "        0.9979, 1.0046, 1.0058, 1.0058, 0.9905, 0.9997, 0.9961, 0.9956, 0.9986,\n",
            "        0.9983, 0.9936, 1.0104, 0.9957, 1.0040, 1.0040, 0.9963, 0.9957, 0.9899,\n",
            "        1.0072, 0.9957, 0.9964, 1.0071, 1.0042, 1.0035, 0.9992, 0.9957, 1.0034,\n",
            "        0.9927, 0.9999, 0.9917, 1.0028, 0.9968, 0.9915, 1.0065, 0.9995, 1.0070,\n",
            "        1.0034, 0.9944, 0.9925, 1.0002, 0.9905, 0.9939, 0.9977, 0.9989, 0.9910,\n",
            "        1.0010, 0.9930, 1.0018, 0.9985, 0.9878, 1.0022, 1.0008, 0.9917, 1.0002,\n",
            "        1.0107, 0.9973, 0.9959, 1.0001, 0.9982, 1.0049, 1.0037, 0.9999, 1.0008,\n",
            "        0.9938, 1.0031, 1.0028, 0.9983, 0.9924, 1.0021, 0.9964, 0.9979, 0.9964,\n",
            "        0.9871, 0.9894, 1.0038, 0.9941, 1.0068, 1.0016, 1.0003, 1.0065, 0.9983,\n",
            "        1.0007, 0.9980, 1.0025, 0.9942, 1.0038, 1.0041, 0.9970, 0.9950, 1.0089,\n",
            "        0.9912, 1.0001, 1.0010, 1.0090, 0.9977, 1.0210, 0.9967, 0.9939, 0.9886,\n",
            "        1.0011, 1.0031, 1.0100, 1.0006, 1.0013, 0.9890, 0.9905, 0.9973, 0.9864,\n",
            "        0.9944, 1.0009, 0.9998, 0.9982, 1.0025, 0.9975, 0.9929, 0.9994, 1.0049,\n",
            "        0.9927, 0.9868, 1.0069, 0.9869, 1.0086, 0.9816, 0.9964, 0.9950, 1.0066,\n",
            "        0.9965, 0.9839, 0.9993, 1.0044, 0.9954, 1.0021, 0.9997, 1.0008, 0.9984,\n",
            "        0.9903, 0.9943, 0.9977, 0.9890, 0.9858, 0.9987, 0.9996, 0.9988, 1.0013,\n",
            "        1.0019, 0.9919, 0.9961, 0.9914, 0.9993, 1.0029, 0.9935, 1.0074, 0.9975,\n",
            "        1.0061, 1.0022, 1.0084, 0.9902, 1.0107, 1.0002, 1.0079, 1.0107, 0.9969,\n",
            "        1.0028, 0.9967, 0.9985, 1.0018, 0.9990, 1.0037, 0.9974, 1.0024, 0.9844,\n",
            "        0.9978, 1.0071, 0.9981, 0.9951], device='cuda:0')), ('inception_block_7.b1.1.bias', tensor([-1.1089e-02, -1.5488e-02, -9.3503e-03, -1.3074e-02, -1.2061e-02,\n",
            "        -6.2771e-03, -1.5835e-02,  2.8002e-03, -5.7026e-03,  3.3056e-03,\n",
            "        -1.5947e-03, -1.1613e-02, -1.3655e-02, -2.4670e-03, -1.0556e-02,\n",
            "         6.0183e-03, -3.6613e-03, -1.1335e-02, -1.0360e-02, -6.6498e-03,\n",
            "        -9.7027e-03, -1.0218e-03, -1.5465e-02, -4.5757e-03, -1.4865e-02,\n",
            "        -2.1546e-02, -1.2415e-02,  2.0471e-03, -2.0923e-03, -1.1693e-02,\n",
            "        -1.1029e-03, -1.1071e-02,  1.1413e-03, -7.3386e-03, -3.3363e-03,\n",
            "        -1.5752e-02,  7.2151e-03, -1.1116e-02, -5.5156e-03, -7.1218e-03,\n",
            "        -6.1992e-03, -2.7868e-03,  1.7282e-03, -5.9046e-03, -3.1507e-03,\n",
            "        -1.4484e-02, -3.1897e-03, -7.8814e-03, -1.3116e-02, -1.0030e-02,\n",
            "        -5.1394e-03, -1.3831e-02,  5.0057e-03, -1.1907e-02,  4.8389e-03,\n",
            "        -1.3606e-03, -1.3770e-02,  7.5023e-03, -1.1144e-02,  1.1003e-05,\n",
            "        -1.8275e-02, -4.1307e-03, -9.6870e-03, -1.0613e-02, -5.6260e-03,\n",
            "         1.3055e-02, -5.1370e-03,  1.2465e-03,  7.2263e-03, -1.1342e-02,\n",
            "        -7.1737e-03, -3.9210e-03, -9.5065e-03, -1.6215e-02, -5.3453e-03,\n",
            "        -1.1912e-02, -1.0626e-02, -7.2656e-03, -8.4470e-03, -2.1404e-02,\n",
            "        -4.3864e-03, -1.6119e-02,  5.3167e-03, -2.0566e-03, -3.9031e-03,\n",
            "        -1.3768e-02, -2.4164e-03, -1.9056e-02, -9.8206e-03, -1.7432e-02,\n",
            "        -3.1226e-03,  2.9011e-03, -2.7506e-02,  2.8831e-03, -3.0008e-04,\n",
            "        -7.7495e-03, -7.1414e-03, -7.1562e-03, -1.3041e-02, -1.3782e-03,\n",
            "         1.6894e-03, -7.8673e-03,  2.5226e-04, -9.3609e-03,  1.0724e-03,\n",
            "        -1.2244e-02, -9.2542e-03, -1.3073e-02,  9.9125e-04,  1.1252e-02,\n",
            "         4.1113e-04, -1.1163e-02, -1.0715e-02, -1.2924e-02, -9.2609e-03,\n",
            "        -3.2818e-04, -5.2537e-03, -1.5319e-03, -1.4613e-03, -5.0076e-03,\n",
            "        -1.1782e-02, -1.6415e-02, -1.4227e-02, -5.0209e-03, -8.1427e-03,\n",
            "        -7.1408e-03, -5.6092e-03, -6.4569e-03, -1.7863e-02, -3.8941e-03,\n",
            "        -1.5294e-02, -2.5427e-03, -7.8964e-03, -8.6761e-03, -1.5255e-02,\n",
            "        -1.6755e-02, -1.3870e-02, -8.9147e-03, -7.9960e-03, -1.2507e-02,\n",
            "        -6.8644e-03, -1.7506e-03, -6.9868e-03, -9.0662e-03, -1.1658e-02,\n",
            "         3.6918e-03, -9.2143e-04, -1.1281e-02, -1.3381e-02, -5.0778e-03,\n",
            "         6.5207e-03, -6.5558e-03, -1.3568e-02, -7.3235e-03, -4.6874e-03,\n",
            "        -9.1405e-03, -2.7447e-03,  2.4608e-04, -2.2345e-02,  1.1262e-03,\n",
            "        -1.3147e-02, -1.3409e-03,  9.9401e-04, -7.7779e-03, -1.0544e-02,\n",
            "        -1.1282e-02,  7.0324e-03, -6.2701e-03, -2.6901e-03, -9.9920e-03,\n",
            "         1.2695e-02, -4.3922e-03, -1.1222e-02,  1.7392e-03, -1.5505e-02,\n",
            "        -1.3038e-02, -1.0933e-02, -2.3510e-03, -8.1120e-03, -4.8422e-03,\n",
            "         7.8919e-03,  1.1846e-03,  3.4824e-04, -4.9598e-04, -6.3669e-03,\n",
            "        -1.5889e-02, -1.0529e-02, -9.8066e-03, -1.1445e-02,  2.9026e-03,\n",
            "        -7.8026e-03, -5.1557e-03, -9.3152e-03, -1.6557e-02, -5.9459e-03,\n",
            "        -2.8768e-03, -4.0946e-03, -1.6027e-02, -8.8310e-03, -1.2165e-02,\n",
            "        -1.5635e-02, -4.0973e-03, -8.6164e-03, -2.1964e-02,  1.6693e-03,\n",
            "        -3.1558e-03, -1.1297e-02, -1.8123e-02, -1.9725e-02,  5.6568e-03,\n",
            "        -5.8560e-03,  2.0469e-03,  1.4512e-03, -2.9174e-03, -7.9620e-03,\n",
            "        -7.4632e-03, -1.1365e-02,  7.3851e-04, -1.0420e-02, -6.5280e-03,\n",
            "        -1.8241e-03, -1.5918e-02, -5.1105e-03, -9.6769e-03, -1.6943e-02,\n",
            "        -5.5326e-04, -3.7536e-03, -4.2977e-03, -7.8381e-03,  6.6883e-03,\n",
            "        -1.1206e-02, -5.4341e-03, -7.7470e-03, -1.4111e-02, -1.0621e-02,\n",
            "        -1.1406e-04, -7.9519e-03, -8.6453e-03, -7.4233e-03,  7.4433e-03,\n",
            "        -1.3995e-02, -9.1447e-03, -1.4326e-02, -7.9444e-03, -3.3753e-03,\n",
            "        -9.1146e-03, -1.3503e-02, -9.7578e-03, -5.7677e-03, -1.6543e-02,\n",
            "        -2.8694e-03, -1.2268e-02, -1.8252e-02, -3.5812e-03, -5.1912e-03,\n",
            "        -6.8783e-03], device='cuda:0')), ('inception_block_7.b1.1.running_mean', tensor([-0.0144,  0.1980, -0.0251,  0.0789, -0.8679, -0.2711, -0.2573, -0.3554,\n",
            "        -0.0871, -0.5572, -0.2318, -0.0764, -0.3419,  0.2759,  0.0556, -0.4379,\n",
            "         0.2036, -0.0683, -0.2656, -0.3424,  0.4313, -0.3004, -0.1675,  0.0696,\n",
            "         0.1884,  0.0972,  0.1614, -0.3213, -0.0721,  0.0328, -0.3294,  0.2997,\n",
            "         0.1956,  0.1530, -0.4062, -0.6362, -0.4040, -0.0181, -0.3950, -0.2109,\n",
            "        -0.4102, -0.1866, -0.2117, -0.2601, -0.5289, -0.4578, -0.0983, -0.3152,\n",
            "        -0.2343, -0.2372, -0.2377, -0.1233,  0.1396, -0.2248,  0.3369,  0.4916,\n",
            "        -0.5534, -0.1174, -0.1554, -0.0207, -0.1911,  0.0682, -0.2347,  0.4820,\n",
            "        -0.0539, -0.2227, -0.0058, -0.0558, -0.3314, -0.0794, -0.1443, -0.0131,\n",
            "        -0.3565, -0.1098,  0.3154,  0.0580,  0.0770, -0.4270, -0.0253, -0.3842,\n",
            "        -0.4479, -0.2411, -0.0274, -0.2820, -0.5851, -0.1418, -0.2769,  0.3067,\n",
            "        -0.1348, -0.2511, -0.0212, -0.4809, -0.0426, -0.4305, -0.0588, -0.3752,\n",
            "        -0.3812, -0.2313,  0.0990,  0.0805, -0.3705, -0.1192, -0.0545, -0.0774,\n",
            "         0.1973,  0.0244,  0.1056,  0.1644, -0.3344, -0.0761, -0.4659, -0.0784,\n",
            "        -0.1987, -0.0953, -0.0606, -0.5899,  0.2689,  0.1977, -0.1108, -0.4360,\n",
            "        -0.2932,  0.2044,  0.0684, -0.1328, -0.1210, -0.0291,  0.0503,  0.1269,\n",
            "        -0.0466,  0.0984, -0.3411, -0.3137, -0.2458,  0.3038, -0.0782, -0.5789,\n",
            "        -0.0095, -0.2308, -0.0570, -0.3704, -0.2279, -0.0035, -0.0129, -0.0867,\n",
            "         0.0201,  0.2587, -0.4016,  0.0663, -0.1866, -0.1711, -0.3248, -0.5238,\n",
            "         0.1750,  0.0887, -0.1648,  0.2914, -0.1845, -0.1821,  0.1482, -0.2273,\n",
            "        -0.1273, -0.0201,  0.0682,  0.2832, -0.7231, -0.3639,  0.2793, -0.0802,\n",
            "         0.2155, -0.2425, -0.4428, -0.2422, -0.2421, -0.2062, -0.2185,  0.6238,\n",
            "        -0.0979,  0.3097, -0.0732,  0.2925, -0.2722, -0.6985,  0.2658,  0.0471,\n",
            "        -0.2119, -0.1759, -0.4122, -0.0734, -0.1201, -0.2933, -0.5416,  0.2811,\n",
            "        -0.2131, -0.2083, -0.4531, -0.3157,  0.1981, -0.0358, -0.3630,  0.1076,\n",
            "        -0.3289, -0.0800, -0.4208, -0.2074,  0.0172, -0.4627,  0.1128,  0.6198,\n",
            "        -0.1173, -0.2349,  0.1316, -0.0216, -0.5879, -0.1599, -0.0245, -0.2609,\n",
            "         0.0242,  0.0242, -0.1112,  0.2550, -0.0770, -0.4029,  0.4343,  0.2476,\n",
            "        -0.2226, -0.2286, -0.1526, -0.4646,  0.3156, -0.2308,  0.0602, -0.4735,\n",
            "        -0.4664,  0.4392, -0.3176, -0.5334,  0.5397, -0.2744,  0.3459,  0.2176,\n",
            "        -0.8802,  0.0487, -0.4913,  0.1546, -0.0364, -0.3075,  0.4208, -0.2005,\n",
            "        -0.3697, -0.0943, -0.9008, -0.1110,  0.3260, -0.2847,  0.4246,  0.2623],\n",
            "       device='cuda:0')), ('inception_block_7.b1.1.running_var', tensor([0.1554, 0.1951, 0.1787, 0.1436, 0.1522, 0.1861, 0.1697, 0.1845, 0.1792,\n",
            "        0.1573, 0.2309, 0.1957, 0.2158, 0.1640, 0.2053, 0.1099, 0.2489, 0.1744,\n",
            "        0.1608, 0.1972, 0.1936, 0.1786, 0.1732, 0.1840, 0.1995, 0.1665, 0.1814,\n",
            "        0.1762, 0.1701, 0.2123, 0.3835, 0.1792, 0.1505, 0.1633, 0.1703, 0.1390,\n",
            "        0.1448, 0.2413, 0.1772, 0.2032, 0.1574, 0.1053, 0.1983, 0.2026, 0.1937,\n",
            "        0.1920, 0.2044, 0.2010, 0.2240, 0.2005, 0.1995, 0.1990, 0.1334, 0.1570,\n",
            "        0.1800, 0.1469, 0.1459, 0.1427, 0.1835, 0.1613, 0.2936, 0.2311, 0.2377,\n",
            "        0.1536, 0.1986, 0.1170, 0.1864, 0.1465, 0.1582, 0.1488, 0.1518, 0.1596,\n",
            "        0.1365, 0.1378, 0.1228, 0.1491, 0.1550, 0.2618, 0.1988, 0.1606, 0.1595,\n",
            "        0.1475, 0.1677, 0.1739, 0.1414, 0.2038, 0.1561, 0.1102, 0.1764, 0.2194,\n",
            "        0.3014, 0.1328, 0.1262, 0.1672, 0.1591, 0.2018, 0.1905, 0.2128, 0.1746,\n",
            "        0.1853, 0.1734, 0.1660, 0.1797, 0.1612, 0.2999, 0.2190, 0.1486, 0.1453,\n",
            "        0.1987, 0.1546, 0.2261, 0.1569, 0.1490, 0.1957, 0.1671, 0.2069, 0.1475,\n",
            "        0.1956, 0.1212, 0.1883, 0.1328, 0.1860, 0.1812, 0.2048, 0.1797, 0.1590,\n",
            "        0.1537, 0.2997, 0.1872, 0.1356, 0.1559, 0.1598, 0.1434, 0.1922, 0.1853,\n",
            "        0.1953, 0.1834, 0.1503, 0.1821, 0.1687, 0.1580, 0.1524, 0.2556, 0.1551,\n",
            "        0.1761, 0.2198, 0.1370, 0.2028, 0.1487, 0.1682, 0.1606, 0.1927, 0.1843,\n",
            "        0.1376, 0.1398, 0.2355, 0.1908, 0.1876, 0.1383, 0.1679, 0.1349, 0.1285,\n",
            "        0.1573, 0.2124, 0.1431, 0.1800, 0.1620, 0.1790, 0.1690, 0.1871, 0.1499,\n",
            "        0.1907, 0.1805, 0.2075, 0.1690, 0.1733, 0.1703, 0.1739, 0.1584, 0.2306,\n",
            "        0.1862, 0.1581, 0.1356, 0.1537, 0.1273, 0.1867, 0.1982, 0.1407, 0.1630,\n",
            "        0.1725, 0.1409, 0.2562, 0.2038, 0.1730, 0.1789, 0.2004, 0.1999, 0.1434,\n",
            "        0.2037, 0.1603, 0.2766, 0.1107, 0.1937, 0.1880, 0.1392, 0.2047, 0.1508,\n",
            "        0.2749, 0.1599, 0.2056, 0.2093, 0.1472, 0.1628, 0.2149, 0.1731, 0.1700,\n",
            "        0.1478, 0.1616, 0.1662, 0.1325, 0.2203, 0.1636, 0.2031, 0.1280, 0.1522,\n",
            "        0.2560, 0.2173, 0.1949, 0.1563, 0.1935, 0.1523, 0.1840, 0.2392, 0.1284,\n",
            "        0.2633, 0.1462, 0.1840, 0.2692, 0.1662, 0.1352, 0.1872, 0.1766, 0.2053,\n",
            "        0.1562, 0.1813, 0.1739, 0.2129, 0.1707, 0.1673, 0.1649, 0.1364, 0.1230,\n",
            "        0.1418, 0.1531, 0.1209, 0.1990], device='cuda:0')), ('inception_block_7.b1.1.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_7.b2.0.weight', tensor([[[[ 0.0272]],\n",
            "\n",
            "         [[ 0.0321]],\n",
            "\n",
            "         [[ 0.0397]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0508]],\n",
            "\n",
            "         [[ 0.0348]],\n",
            "\n",
            "         [[-0.0196]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0299]],\n",
            "\n",
            "         [[-0.0203]],\n",
            "\n",
            "         [[ 0.0256]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0111]],\n",
            "\n",
            "         [[-0.0268]],\n",
            "\n",
            "         [[ 0.0176]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0381]],\n",
            "\n",
            "         [[ 0.0140]],\n",
            "\n",
            "         [[ 0.0204]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0020]],\n",
            "\n",
            "         [[-0.0192]],\n",
            "\n",
            "         [[-0.0117]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0241]],\n",
            "\n",
            "         [[-0.0331]],\n",
            "\n",
            "         [[-0.0450]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0113]],\n",
            "\n",
            "         [[ 0.0350]],\n",
            "\n",
            "         [[ 0.0396]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0187]],\n",
            "\n",
            "         [[-0.0238]],\n",
            "\n",
            "         [[-0.0314]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0139]],\n",
            "\n",
            "         [[ 0.0133]],\n",
            "\n",
            "         [[-0.0309]]],\n",
            "\n",
            "\n",
            "        [[[-0.0245]],\n",
            "\n",
            "         [[-0.0354]],\n",
            "\n",
            "         [[ 0.0234]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0193]],\n",
            "\n",
            "         [[-0.0142]],\n",
            "\n",
            "         [[ 0.0019]]]], device='cuda:0')), ('inception_block_7.b2.0.bias', tensor([-0.0400,  0.0254,  0.0324,  0.0403,  0.0275, -0.0167, -0.0221, -0.0113,\n",
            "        -0.0014,  0.0068, -0.0154, -0.0354,  0.0076, -0.0181, -0.0227,  0.0347,\n",
            "        -0.0307, -0.0013, -0.0291,  0.0212,  0.0153,  0.0198,  0.0057, -0.0171,\n",
            "         0.0256, -0.0147,  0.0125, -0.0292, -0.0176, -0.0145, -0.0215, -0.0065,\n",
            "         0.0412,  0.0279,  0.0342, -0.0346, -0.0428,  0.0225,  0.0110,  0.0110,\n",
            "        -0.0075,  0.0429, -0.0141, -0.0010, -0.0176,  0.0301, -0.0074,  0.0404,\n",
            "         0.0033,  0.0117, -0.0300,  0.0357,  0.0141, -0.0027,  0.0367, -0.0255,\n",
            "        -0.0139,  0.0331, -0.0087,  0.0072,  0.0292, -0.0329, -0.0278, -0.0309,\n",
            "         0.0109, -0.0407,  0.0004,  0.0061,  0.0159,  0.0185, -0.0133,  0.0229,\n",
            "         0.0198, -0.0263,  0.0330,  0.0001,  0.0274, -0.0218,  0.0267,  0.0207,\n",
            "         0.0044,  0.0123,  0.0199, -0.0236,  0.0232,  0.0228,  0.0008, -0.0427,\n",
            "         0.0160,  0.0120, -0.0378, -0.0121,  0.0219,  0.0295, -0.0199,  0.0368,\n",
            "         0.0089,  0.0345,  0.0148, -0.0399, -0.0358,  0.0312, -0.0392,  0.0130,\n",
            "         0.0267,  0.0407,  0.0422, -0.0005,  0.0266,  0.0333,  0.0058,  0.0250,\n",
            "         0.0334, -0.0231,  0.0404,  0.0058,  0.0201,  0.0122,  0.0076,  0.0337,\n",
            "         0.0415,  0.0275, -0.0281,  0.0134,  0.0248, -0.0297, -0.0082, -0.0057,\n",
            "        -0.0196,  0.0104, -0.0241,  0.0051, -0.0328, -0.0095,  0.0360,  0.0322,\n",
            "        -0.0416, -0.0310, -0.0358, -0.0145,  0.0329,  0.0402,  0.0200, -0.0219,\n",
            "        -0.0292, -0.0249,  0.0090, -0.0324, -0.0140,  0.0186, -0.0047, -0.0072,\n",
            "         0.0064,  0.0117, -0.0342,  0.0234, -0.0201, -0.0180, -0.0095, -0.0041],\n",
            "       device='cuda:0')), ('inception_block_7.b2.1.weight', tensor([0.9992, 0.9986, 0.9893, 1.0082, 0.9977, 0.9969, 1.0102, 0.9947, 1.0131,\n",
            "        1.0026, 1.0030, 1.0003, 1.0071, 0.9960, 0.9897, 1.0079, 0.9879, 0.9968,\n",
            "        0.9988, 0.9900, 0.9994, 0.9956, 0.9942, 0.9953, 0.9899, 1.0102, 0.9948,\n",
            "        0.9977, 0.9961, 0.9901, 1.0000, 0.9979, 0.9997, 1.0002, 0.9984, 0.9979,\n",
            "        1.0120, 0.9954, 1.0026, 0.9994, 0.9972, 1.0031, 1.0025, 0.9914, 1.0007,\n",
            "        1.0002, 0.9986, 1.0146, 0.9939, 0.9951, 1.0061, 0.9991, 1.0022, 0.9965,\n",
            "        1.0033, 1.0108, 0.9922, 1.0059, 1.0036, 1.0004, 1.0070, 0.9977, 1.0076,\n",
            "        1.0091, 0.9961, 0.9976, 0.9961, 1.0027, 0.9812, 0.9999, 0.9988, 1.0029,\n",
            "        1.0006, 0.9944, 1.0006, 0.9912, 0.9976, 0.9948, 0.9999, 0.9986, 1.0088,\n",
            "        0.9969, 0.9960, 1.0091, 0.9989, 0.9995, 1.0005, 0.9944, 0.9993, 1.0012,\n",
            "        1.0015, 0.9934, 1.0052, 0.9997, 1.0013, 1.0022, 1.0079, 1.0042, 1.0047,\n",
            "        0.9974, 1.0013, 0.9957, 1.0035, 0.9995, 0.9898, 1.0014, 1.0158, 1.0147,\n",
            "        1.0037, 0.9958, 0.9946, 0.9969, 1.0017, 1.0059, 0.9948, 0.9987, 1.0080,\n",
            "        1.0041, 0.9919, 0.9887, 0.9960, 0.9986, 1.0047, 0.9968, 0.9917, 1.0026,\n",
            "        0.9982, 0.9959, 1.0015, 1.0033, 1.0048, 0.9922, 1.0126, 1.0069, 0.9958,\n",
            "        1.0006, 0.9992, 1.0027, 0.9950, 1.0044, 1.0019, 1.0021, 1.0015, 1.0008,\n",
            "        1.0045, 1.0068, 1.0007, 1.0082, 1.0003, 1.0049, 1.0030, 1.0015, 1.0117,\n",
            "        1.0015, 0.9996, 0.9953, 1.0150, 1.0037, 0.9987, 0.9926],\n",
            "       device='cuda:0')), ('inception_block_7.b2.1.bias', tensor([-4.4671e-03, -4.5198e-03, -1.5634e-02,  1.7264e-03, -1.2022e-02,\n",
            "        -4.9566e-03, -9.4931e-04, -9.0518e-03,  7.4738e-03, -1.0840e-02,\n",
            "        -2.4855e-03, -2.4131e-04, -4.3072e-03, -1.6458e-02, -8.6774e-03,\n",
            "        -2.0106e-03, -1.8994e-02, -6.3536e-03, -1.2138e-02, -4.2901e-05,\n",
            "        -7.0809e-03, -1.4696e-02, -1.1336e-02, -7.0737e-03, -1.9217e-03,\n",
            "         1.5166e-03, -1.9902e-02, -1.0526e-02, -5.0927e-03, -1.6285e-02,\n",
            "        -9.2902e-03, -7.4071e-03, -7.5668e-03, -2.5183e-03, -7.9629e-03,\n",
            "        -9.7921e-03, -2.8965e-03, -1.1275e-02, -9.0572e-03, -7.9760e-03,\n",
            "        -5.0249e-03, -9.2371e-03, -1.4061e-02, -6.5798e-03, -4.8435e-03,\n",
            "         1.8102e-03, -8.9409e-03,  2.3324e-03, -1.1779e-02, -3.6901e-03,\n",
            "        -7.6271e-03, -2.9888e-03, -2.7329e-03, -9.0938e-03, -1.1525e-02,\n",
            "        -2.9681e-03, -7.2085e-03, -1.3555e-04,  2.1795e-03, -1.8301e-02,\n",
            "         7.4451e-03, -1.0743e-02, -9.7850e-04, -4.0284e-03, -3.8282e-03,\n",
            "        -1.7064e-02, -8.2475e-03, -1.9129e-03, -1.4576e-02, -2.9500e-03,\n",
            "        -7.6073e-03, -1.3188e-03, -6.9646e-03, -6.4057e-03, -2.4611e-03,\n",
            "        -1.0741e-02, -1.1724e-02, -7.5143e-03, -7.9530e-03, -7.4362e-03,\n",
            "        -9.7452e-03, -6.2210e-03, -1.0579e-03, -9.3095e-04, -6.9104e-03,\n",
            "        -1.4297e-02, -8.1686e-03, -1.3622e-02, -1.5104e-02, -1.0784e-02,\n",
            "        -6.5483e-03, -6.5626e-03, -3.9883e-03, -7.3712e-03, -1.3469e-02,\n",
            "        -8.7121e-03, -1.1341e-02,  9.5109e-04, -1.8327e-03, -1.4517e-02,\n",
            "        -8.4618e-03, -6.0893e-03, -6.9525e-03, -1.4929e-02, -1.6593e-02,\n",
            "        -1.0427e-02, -3.5190e-04, -1.1685e-02, -3.7184e-03, -9.7943e-03,\n",
            "        -2.3814e-03, -1.1650e-02, -1.0182e-02, -1.1871e-03, -1.1917e-02,\n",
            "        -1.2956e-02,  3.7720e-04, -1.0318e-02, -1.1536e-02, -1.5159e-02,\n",
            "        -2.9501e-03,  5.1576e-03, -3.4225e-05, -1.0891e-02, -1.6510e-02,\n",
            "        -5.2427e-03, -1.6779e-02, -1.2065e-02, -6.2207e-03, -4.4826e-03,\n",
            "         1.0935e-04, -1.2340e-02, -1.2637e-03, -5.5776e-03, -7.9455e-03,\n",
            "        -1.2373e-02, -1.3447e-02,  1.4029e-03, -1.7038e-03, -6.5267e-03,\n",
            "        -1.3467e-02,  6.9966e-03, -9.9871e-03,  3.1172e-03, -1.9391e-04,\n",
            "         1.0184e-02,  4.2314e-03, -1.2679e-02, -6.8012e-03,  1.9645e-03,\n",
            "        -4.9939e-03,  6.6947e-04, -1.9004e-04, -3.2067e-03, -7.3704e-03,\n",
            "        -1.3342e-02, -1.1085e-03, -7.3356e-03, -2.6718e-03, -1.8414e-02],\n",
            "       device='cuda:0')), ('inception_block_7.b2.1.running_mean', tensor([ 0.1757, -0.3123,  0.1141, -0.4602, -0.2470, -0.1199, -0.4422,  0.8119,\n",
            "        -0.1617,  0.1063,  0.1533, -0.0034, -0.2021, -0.0322,  0.1081, -0.6741,\n",
            "         0.0541,  0.2419,  0.0691,  0.1670, -0.0579, -0.3891,  0.2399, -0.3748,\n",
            "         0.1586, -0.4183, -0.0351,  0.2131, -0.6162,  0.0861, -0.0814, -0.0482,\n",
            "        -0.1306, -0.1716, -0.2313, -0.0039,  0.0062, -0.3987, -0.2210,  0.2070,\n",
            "        -0.2450,  0.7418, -0.5335, -0.4066,  0.0850,  0.2124,  0.0162,  0.0563,\n",
            "         0.0531, -0.2411, -0.2955, -0.5929, -0.0507,  0.1011,  0.1014, -0.1498,\n",
            "        -0.3778, -0.4163, -0.1078,  0.1895, -0.5144,  0.6685, -0.1113,  0.1998,\n",
            "        -0.3522,  0.1758, -0.1686, -0.1012,  0.0578,  0.1969,  0.2320,  0.0956,\n",
            "        -0.0239,  0.0117,  0.0725, -0.5095, -0.0921, -0.4875, -0.0247,  0.1495,\n",
            "        -0.3681,  0.0534,  0.0247, -0.0862, -0.1451, -0.3695, -0.0544, -0.0521,\n",
            "        -0.4460,  0.4284, -0.2206, -0.3543, -0.4004,  0.3720,  0.1982, -0.6947,\n",
            "         0.0805, -0.0651, -0.4441,  0.1438, -0.3134, -0.4843, -0.1208, -0.2805,\n",
            "        -0.0396, -0.5451, -0.5125, -0.0691, -0.2529, -0.1581,  0.0340,  0.2340,\n",
            "        -0.4031,  0.1046,  0.2231, -0.2643,  0.0486,  0.0271,  0.0540,  0.4999,\n",
            "        -0.3179,  0.0716, -0.2608,  0.1362,  0.1097, -0.2679, -0.3838,  0.0862,\n",
            "        -0.1179, -0.5985, -0.1625,  0.0372,  0.0814,  0.0068, -0.1076, -0.0028,\n",
            "        -0.3707, -0.0982,  0.4723, -0.1511, -0.2648,  0.2663, -0.2978, -0.2236,\n",
            "        -0.0624, -0.0309, -0.4236,  0.0507, -0.4421, -0.1612,  0.4985,  0.2744,\n",
            "        -0.4721,  0.3743, -0.1949, -0.2856,  0.3242, -0.2296,  0.0951, -0.1641],\n",
            "       device='cuda:0')), ('inception_block_7.b2.1.running_var', tensor([0.1874, 0.1491, 0.1930, 0.2158, 0.1805, 0.1764, 0.2020, 0.1748, 0.2625,\n",
            "        0.1475, 0.1501, 0.1825, 0.2347, 0.1636, 0.1912, 0.1967, 0.1798, 0.2097,\n",
            "        0.1646, 0.2544, 0.1701, 0.1654, 0.1579, 0.1459, 0.1916, 0.1948, 0.1451,\n",
            "        0.1475, 0.2262, 0.1481, 0.2676, 0.1753, 0.1487, 0.1954, 0.2470, 0.1841,\n",
            "        0.2456, 0.1748, 0.1960, 0.1681, 0.2696, 0.1633, 0.1798, 0.1484, 0.1747,\n",
            "        0.1295, 0.1606, 0.2247, 0.2253, 0.2322, 0.1831, 0.1823, 0.2276, 0.3172,\n",
            "        0.1548, 0.1562, 0.2500, 0.1825, 0.1577, 0.2214, 0.1740, 0.1933, 0.1351,\n",
            "        0.1567, 0.1912, 0.1486, 0.1606, 0.1916, 0.2467, 0.1773, 0.2007, 0.1702,\n",
            "        0.1483, 0.1699, 0.1566, 0.2303, 0.2108, 0.1751, 0.1789, 0.1545, 0.1588,\n",
            "        0.1856, 0.2125, 0.1631, 0.1876, 0.1418, 0.1890, 0.1859, 0.2195, 0.1492,\n",
            "        0.1613, 0.1718, 0.1651, 0.1728, 0.2136, 0.1407, 0.1963, 0.1885, 0.1509,\n",
            "        0.1830, 0.2109, 0.1811, 0.1723, 0.1799, 0.2653, 0.1522, 0.1770, 0.1923,\n",
            "        0.1689, 0.1910, 0.1348, 0.1697, 0.1703, 0.1899, 0.1754, 0.2454, 0.1843,\n",
            "        0.1595, 0.2037, 0.1744, 0.1847, 0.2119, 0.1884, 0.2359, 0.2067, 0.2020,\n",
            "        0.1647, 0.2023, 0.2099, 0.1951, 0.1687, 0.1870, 0.1763, 0.1821, 0.1652,\n",
            "        0.1958, 0.2343, 0.1503, 0.1546, 0.2200, 0.1460, 0.2207, 0.1450, 0.1418,\n",
            "        0.1329, 0.1689, 0.2316, 0.1857, 0.1710, 0.1892, 0.1606, 0.1715, 0.1602,\n",
            "        0.2193, 0.1463, 0.2896, 0.1416, 0.1527, 0.1574, 0.1699],\n",
            "       device='cuda:0')), ('inception_block_7.b2.1.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_7.b2.3.weight', tensor([[[[-0.0038, -0.0081, -0.0220],\n",
            "          [-0.0194, -0.0088,  0.0170],\n",
            "          [-0.0068, -0.0072,  0.0267]],\n",
            "\n",
            "         [[ 0.0257,  0.0300, -0.0028],\n",
            "          [-0.0019,  0.0240,  0.0272],\n",
            "          [-0.0102, -0.0074, -0.0156]],\n",
            "\n",
            "         [[-0.0055,  0.0192, -0.0163],\n",
            "          [ 0.0141,  0.0175, -0.0097],\n",
            "          [-0.0134, -0.0078,  0.0211]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0112, -0.0157, -0.0039],\n",
            "          [ 0.0045, -0.0062, -0.0159],\n",
            "          [-0.0105, -0.0218, -0.0030]],\n",
            "\n",
            "         [[-0.0066,  0.0082,  0.0013],\n",
            "          [-0.0027,  0.0157,  0.0102],\n",
            "          [ 0.0206,  0.0105,  0.0164]],\n",
            "\n",
            "         [[ 0.0078, -0.0096,  0.0023],\n",
            "          [-0.0034,  0.0292,  0.0128],\n",
            "          [ 0.0081, -0.0323,  0.0023]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0110,  0.0221, -0.0208],\n",
            "          [-0.0219,  0.0169,  0.0118],\n",
            "          [ 0.0271, -0.0142, -0.0368]],\n",
            "\n",
            "         [[-0.0141,  0.0069, -0.0150],\n",
            "          [ 0.0284, -0.0116, -0.0038],\n",
            "          [ 0.0169, -0.0030, -0.0232]],\n",
            "\n",
            "         [[ 0.0045,  0.0121, -0.0130],\n",
            "          [-0.0015, -0.0130,  0.0148],\n",
            "          [ 0.0022,  0.0100,  0.0047]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0177,  0.0171, -0.0127],\n",
            "          [ 0.0089,  0.0066,  0.0126],\n",
            "          [-0.0132,  0.0120,  0.0119]],\n",
            "\n",
            "         [[ 0.0015,  0.0012, -0.0092],\n",
            "          [-0.0009, -0.0041,  0.0055],\n",
            "          [ 0.0044,  0.0221, -0.0055]],\n",
            "\n",
            "         [[ 0.0128,  0.0214, -0.0182],\n",
            "          [-0.0225,  0.0091,  0.0188],\n",
            "          [-0.0053,  0.0263, -0.0133]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0152,  0.0273,  0.0075],\n",
            "          [-0.0217, -0.0180, -0.0087],\n",
            "          [ 0.0142, -0.0189, -0.0247]],\n",
            "\n",
            "         [[ 0.0131, -0.0013,  0.0060],\n",
            "          [-0.0301,  0.0013, -0.0036],\n",
            "          [-0.0212, -0.0236,  0.0072]],\n",
            "\n",
            "         [[-0.0239,  0.0188, -0.0256],\n",
            "          [ 0.0123, -0.0156, -0.0167],\n",
            "          [ 0.0294,  0.0126, -0.0063]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0069, -0.0013, -0.0197],\n",
            "          [-0.0235, -0.0267,  0.0044],\n",
            "          [ 0.0092,  0.0185, -0.0202]],\n",
            "\n",
            "         [[ 0.0007,  0.0323, -0.0205],\n",
            "          [ 0.0023, -0.0196,  0.0165],\n",
            "          [-0.0102, -0.0177, -0.0096]],\n",
            "\n",
            "         [[-0.0082,  0.0051, -0.0094],\n",
            "          [-0.0228,  0.0189,  0.0239],\n",
            "          [-0.0248, -0.0187,  0.0257]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0030,  0.0135,  0.0003],\n",
            "          [ 0.0143,  0.0186,  0.0152],\n",
            "          [-0.0049, -0.0247,  0.0196]],\n",
            "\n",
            "         [[ 0.0040,  0.0092, -0.0211],\n",
            "          [-0.0253,  0.0041, -0.0198],\n",
            "          [-0.0042, -0.0138,  0.0032]],\n",
            "\n",
            "         [[-0.0075,  0.0190,  0.0180],\n",
            "          [ 0.0013, -0.0123,  0.0254],\n",
            "          [-0.0088,  0.0223, -0.0166]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0091,  0.0092, -0.0126],\n",
            "          [-0.0189,  0.0140,  0.0072],\n",
            "          [ 0.0249,  0.0067, -0.0224]],\n",
            "\n",
            "         [[ 0.0136, -0.0286, -0.0148],\n",
            "          [-0.0161, -0.0009, -0.0294],\n",
            "          [-0.0031, -0.0052, -0.0064]],\n",
            "\n",
            "         [[ 0.0160, -0.0132, -0.0301],\n",
            "          [-0.0170, -0.0043, -0.0114],\n",
            "          [-0.0069, -0.0175, -0.0202]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0156,  0.0243,  0.0295],\n",
            "          [ 0.0065, -0.0019,  0.0060],\n",
            "          [-0.0019,  0.0031,  0.0237]],\n",
            "\n",
            "         [[ 0.0213, -0.0149, -0.0090],\n",
            "          [-0.0060, -0.0181, -0.0204],\n",
            "          [-0.0049, -0.0065, -0.0127]],\n",
            "\n",
            "         [[ 0.0179, -0.0069,  0.0152],\n",
            "          [-0.0102, -0.0128, -0.0103],\n",
            "          [ 0.0199, -0.0094, -0.0054]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0094,  0.0146,  0.0265],\n",
            "          [-0.0204, -0.0276, -0.0069],\n",
            "          [ 0.0240,  0.0326,  0.0020]],\n",
            "\n",
            "         [[ 0.0064, -0.0182, -0.0148],\n",
            "          [-0.0019,  0.0285,  0.0003],\n",
            "          [ 0.0250,  0.0148,  0.0202]],\n",
            "\n",
            "         [[-0.0177, -0.0197,  0.0024],\n",
            "          [-0.0054, -0.0053,  0.0107],\n",
            "          [ 0.0085, -0.0114, -0.0086]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0271, -0.0209,  0.0225],\n",
            "          [ 0.0174,  0.0273, -0.0061],\n",
            "          [ 0.0172,  0.0039, -0.0042]],\n",
            "\n",
            "         [[ 0.0263,  0.0114,  0.0095],\n",
            "          [-0.0169,  0.0098,  0.0022],\n",
            "          [-0.0055,  0.0308,  0.0047]],\n",
            "\n",
            "         [[ 0.0096, -0.0074, -0.0105],\n",
            "          [ 0.0131, -0.0184, -0.0134],\n",
            "          [ 0.0208, -0.0290,  0.0032]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0045,  0.0043,  0.0385],\n",
            "          [ 0.0199,  0.0028,  0.0365],\n",
            "          [ 0.0057, -0.0166,  0.0089]],\n",
            "\n",
            "         [[ 0.0226,  0.0048,  0.0157],\n",
            "          [-0.0035, -0.0213, -0.0222],\n",
            "          [-0.0142,  0.0014,  0.0158]],\n",
            "\n",
            "         [[-0.0098,  0.0091,  0.0161],\n",
            "          [-0.0244,  0.0223, -0.0116],\n",
            "          [-0.0109,  0.0153, -0.0158]]]], device='cuda:0')), ('inception_block_7.b2.3.bias', tensor([-1.8525e-02,  1.7308e-03,  2.1043e-02,  9.2865e-03, -1.3608e-02,\n",
            "         1.2132e-02, -1.1377e-02, -1.4031e-02, -2.4452e-02, -8.6930e-03,\n",
            "        -2.3232e-02, -7.4603e-03,  8.0795e-03, -2.3991e-02, -1.0295e-02,\n",
            "         1.3442e-02, -7.4740e-03, -3.4596e-03,  8.6714e-03,  5.8454e-03,\n",
            "        -7.7930e-03,  6.6251e-03,  4.5948e-03,  3.3130e-03, -2.3580e-03,\n",
            "        -4.8760e-03, -9.4042e-03, -3.5863e-03, -8.4590e-03,  4.2005e-03,\n",
            "        -1.4269e-02,  1.1450e-03, -2.0857e-02,  1.7971e-02, -2.4490e-02,\n",
            "         5.5943e-03, -1.6362e-02,  4.7307e-03, -1.7191e-02, -2.2026e-02,\n",
            "        -2.6259e-02,  3.5861e-03,  1.6761e-02,  1.4351e-02, -1.3795e-02,\n",
            "         6.5092e-03, -2.1836e-02,  2.0744e-02, -1.7934e-02,  1.1534e-02,\n",
            "        -2.0489e-02,  1.5830e-02, -2.5841e-02,  2.1526e-02, -2.4090e-02,\n",
            "         1.7915e-02, -1.2550e-02,  1.6296e-03,  2.0993e-02,  1.2713e-02,\n",
            "         2.6097e-04, -2.0508e-02,  7.4969e-03, -2.3061e-02, -1.7111e-02,\n",
            "         2.1890e-02, -1.0798e-02, -2.1674e-02, -4.7574e-03, -2.3215e-02,\n",
            "         9.1824e-03,  1.3200e-02, -1.3696e-02, -2.5643e-02, -1.0739e-02,\n",
            "        -7.7822e-03,  1.1799e-02, -3.6478e-03,  1.4403e-02, -4.2900e-03,\n",
            "        -1.2963e-03,  1.0438e-02, -1.1310e-02, -2.3356e-02,  7.4277e-03,\n",
            "        -2.0868e-02, -2.5709e-02,  1.1275e-02,  1.3796e-02,  1.4935e-04,\n",
            "         2.0125e-02, -2.0311e-02,  7.0320e-03,  3.7082e-03,  2.3065e-02,\n",
            "        -4.9785e-03, -1.4355e-02,  2.2977e-02, -1.2643e-03,  6.9115e-03,\n",
            "         2.6480e-02,  1.4699e-02, -8.7021e-03, -1.7705e-02,  6.3142e-03,\n",
            "         1.6439e-02,  2.5768e-02,  8.9832e-03,  6.0826e-03,  1.4202e-02,\n",
            "         1.6370e-02, -2.4593e-02, -9.1696e-03, -5.4918e-03,  7.9363e-03,\n",
            "        -2.5449e-02,  2.2555e-02, -2.2273e-02, -1.4609e-02, -3.2648e-03,\n",
            "        -1.5407e-02, -1.7164e-02,  8.9195e-03, -1.7093e-02,  2.6323e-02,\n",
            "        -3.4845e-03,  2.3037e-03,  2.4412e-02,  2.5570e-02,  1.4638e-02,\n",
            "         5.9306e-03,  3.6170e-04,  1.5656e-02,  1.6340e-03, -4.4889e-03,\n",
            "        -1.7457e-02, -1.0625e-02,  1.4143e-02,  2.1602e-02,  5.2174e-03,\n",
            "         1.9053e-02,  1.7961e-02,  2.5414e-03,  1.4399e-02, -6.0362e-03,\n",
            "        -2.8547e-05,  2.2908e-02, -2.2875e-02, -1.3345e-02, -5.1014e-03,\n",
            "        -4.2759e-03,  1.9464e-03,  1.7124e-02, -2.3876e-02,  1.8778e-02,\n",
            "        -2.4633e-02, -5.0777e-03, -5.2587e-03,  5.0856e-03, -1.2415e-02,\n",
            "        -3.5735e-03, -1.5855e-03, -1.7365e-02,  1.3234e-02,  1.2786e-02,\n",
            "         1.7048e-02, -1.2071e-02,  2.4603e-02,  3.5785e-03, -1.2842e-02,\n",
            "         8.3754e-03, -1.4039e-02, -1.4184e-02, -2.1460e-02,  1.5380e-02,\n",
            "        -2.5195e-03, -2.4651e-02,  1.1661e-04,  3.4727e-03, -7.6882e-03,\n",
            "         2.6117e-02,  2.0999e-02, -2.5921e-02, -1.1013e-02,  2.4860e-02,\n",
            "        -9.3017e-03, -1.5740e-03, -1.1494e-02, -2.5174e-02,  2.0937e-02,\n",
            "        -2.0202e-02, -2.5604e-03,  4.9691e-03,  1.9013e-02, -2.2186e-02,\n",
            "         5.8354e-03, -8.3033e-03, -2.5808e-03, -2.1660e-03, -2.0905e-02,\n",
            "         1.1450e-02,  1.9302e-02,  2.0101e-02, -1.8292e-02, -2.5354e-02,\n",
            "         1.1357e-02,  2.5359e-02,  1.6213e-04, -1.2131e-02, -2.3441e-02,\n",
            "         5.0219e-03, -2.5988e-02, -2.9838e-03,  8.1763e-03, -9.1212e-03,\n",
            "         1.2898e-02,  3.3606e-03,  1.4663e-02,  8.0916e-03,  9.6166e-03,\n",
            "         2.5518e-03, -1.5541e-02,  2.1778e-02, -1.3515e-02,  1.0611e-02,\n",
            "         4.7658e-03,  5.4718e-03,  3.6457e-03, -2.3069e-02, -1.1867e-02,\n",
            "        -1.2048e-02,  2.5336e-02,  2.1154e-02, -5.8608e-03,  1.3646e-02,\n",
            "        -2.5476e-02, -2.0974e-03, -1.9684e-02,  7.7622e-03, -2.7230e-03,\n",
            "        -1.0065e-02,  5.0958e-03,  2.0625e-02,  1.9751e-02,  9.3344e-03,\n",
            "        -9.2809e-03, -2.8302e-03,  1.5100e-02,  1.0023e-02,  2.0750e-02,\n",
            "         8.5693e-03,  1.8009e-02, -1.1667e-02, -5.9256e-03,  1.8188e-02,\n",
            "        -2.0598e-02, -1.4636e-02,  2.0307e-02,  7.6172e-04,  2.6179e-02,\n",
            "        -2.0253e-02, -2.3277e-02, -1.2198e-02, -9.8306e-03,  9.6727e-03,\n",
            "        -7.5494e-03,  2.1308e-02,  2.6399e-02,  2.2141e-02,  2.2648e-02,\n",
            "         1.2306e-02, -1.0355e-02,  2.2250e-03, -5.2365e-03,  2.0672e-02,\n",
            "         2.1550e-02,  2.2861e-03, -2.6138e-02,  1.4887e-02, -1.5695e-02,\n",
            "        -2.1926e-02,  1.5827e-03,  8.2518e-04, -2.2357e-02, -1.2912e-02,\n",
            "        -2.0593e-02,  9.0014e-03, -2.3689e-02, -2.2960e-02, -2.1547e-02,\n",
            "        -8.3722e-03, -2.1317e-02, -6.8844e-03,  2.1459e-02,  1.0341e-02,\n",
            "        -2.2780e-02, -2.2082e-02,  2.2690e-02, -6.3650e-03, -1.4273e-02,\n",
            "        -1.8204e-02,  1.3398e-02, -1.7735e-02, -1.3839e-02,  1.0457e-02,\n",
            "         7.9479e-03,  2.1150e-03,  5.4231e-03,  2.4187e-02, -1.4813e-02,\n",
            "        -9.5719e-03,  3.4536e-04,  6.0985e-03, -1.5315e-02,  9.0322e-03,\n",
            "        -2.1367e-02, -2.4005e-02,  2.4253e-02, -2.2157e-02, -1.2322e-02],\n",
            "       device='cuda:0')), ('inception_block_7.b2.4.weight', tensor([1.0020, 0.9931, 1.0034, 0.9933, 1.0036, 0.9973, 1.0021, 1.0068, 0.9881,\n",
            "        1.0067, 0.9921, 0.9983, 0.9984, 1.0016, 0.9972, 0.9987, 0.9881, 1.0034,\n",
            "        1.0053, 1.0019, 1.0039, 1.0046, 0.9975, 1.0013, 0.9936, 1.0015, 0.9973,\n",
            "        1.0002, 0.9956, 0.9969, 0.9862, 1.0018, 0.9919, 0.9992, 0.9998, 0.9963,\n",
            "        1.0039, 0.9961, 1.0057, 1.0069, 0.9956, 1.0077, 1.0082, 0.9971, 1.0043,\n",
            "        0.9986, 0.9928, 0.9925, 1.0011, 1.0216, 1.0008, 0.9855, 0.9939, 1.0034,\n",
            "        0.9959, 0.9971, 0.9931, 0.9841, 1.0068, 1.0004, 1.0085, 1.0052, 1.0013,\n",
            "        0.9980, 0.9990, 0.9956, 1.0043, 1.0054, 1.0061, 1.0019, 1.0008, 0.9940,\n",
            "        0.9999, 1.0000, 1.0035, 1.0047, 1.0015, 0.9962, 1.0158, 1.0028, 0.9929,\n",
            "        0.9975, 0.9873, 1.0068, 1.0025, 0.9853, 0.9994, 1.0045, 1.0043, 1.0109,\n",
            "        1.0009, 0.9966, 0.9937, 0.9868, 0.9979, 0.9995, 1.0049, 1.0006, 0.9945,\n",
            "        1.0028, 0.9981, 0.9958, 1.0036, 1.0062, 1.0081, 0.9935, 1.0091, 0.9991,\n",
            "        0.9968, 0.9913, 0.9966, 1.0117, 0.9950, 0.9909, 0.9978, 1.0001, 0.9970,\n",
            "        1.0083, 0.9918, 0.9996, 1.0018, 1.0026, 0.9971, 1.0084, 0.9924, 1.0059,\n",
            "        1.0081, 1.0092, 1.0004, 0.9890, 1.0077, 0.9976, 0.9988, 0.9958, 0.9989,\n",
            "        0.9953, 1.0103, 0.9973, 0.9973, 0.9970, 1.0057, 1.0084, 1.0048, 0.9996,\n",
            "        0.9920, 1.0006, 1.0022, 1.0090, 1.0123, 1.0030, 1.0006, 0.9978, 0.9995,\n",
            "        0.9915, 1.0027, 0.9989, 1.0009, 0.9900, 0.9985, 1.0009, 0.9899, 1.0066,\n",
            "        0.9984, 1.0005, 0.9967, 0.9991, 1.0062, 1.0056, 1.0002, 0.9958, 0.9964,\n",
            "        1.0006, 1.0084, 1.0037, 0.9996, 0.9989, 0.9951, 1.0105, 1.0073, 1.0007,\n",
            "        0.9903, 1.0056, 1.0097, 0.9995, 1.0106, 1.0050, 0.9911, 0.9950, 0.9929,\n",
            "        0.9924, 0.9972, 0.9945, 0.9875, 0.9950, 0.9944, 1.0001, 1.0034, 1.0032,\n",
            "        0.9959, 0.9959, 0.9913, 1.0023, 0.9984, 1.0046, 0.9992, 1.0066, 0.9999,\n",
            "        1.0042, 0.9993, 1.0064, 0.9915, 0.9941, 0.9952, 0.9971, 1.0015, 1.0030,\n",
            "        1.0057, 1.0085, 0.9932, 0.9921, 0.9947, 0.9951, 0.9962, 0.9962, 0.9938,\n",
            "        1.0042, 0.9971, 1.0056, 1.0106, 0.9932, 0.9937, 0.9907, 1.0044, 0.9944,\n",
            "        1.0016, 1.0058, 1.0064, 0.9930, 0.9931, 1.0089, 0.9959, 0.9952, 0.9940,\n",
            "        1.0036, 1.0014, 1.0067, 0.9928, 0.9946, 0.9936, 0.9997, 0.9994, 1.0000,\n",
            "        1.0034, 0.9923, 0.9940, 1.0094, 0.9914, 0.9946, 0.9921, 1.0013, 1.0056,\n",
            "        0.9886, 1.0071, 0.9966, 0.9994, 1.0028, 1.0001, 1.0054, 1.0068, 1.0027,\n",
            "        1.0020, 0.9983, 1.0059, 0.9931, 1.0147, 1.0064, 0.9922, 1.0008, 1.0075,\n",
            "        0.9925, 1.0064, 0.9954, 0.9995, 1.0128, 0.9995, 0.9956, 0.9918, 0.9982,\n",
            "        0.9855, 0.9938, 0.9960, 1.0081, 1.0065, 0.9941, 0.9934, 0.9926, 0.9966,\n",
            "        0.9954, 0.9813, 1.0095, 0.9951, 0.9867, 0.9898, 1.0157, 1.0071, 1.0076,\n",
            "        0.9943, 0.9928, 1.0007, 0.9897, 1.0014, 0.9991, 0.9891, 0.9905, 0.9945,\n",
            "        0.9981, 0.9977, 0.9925, 1.0116, 1.0050], device='cuda:0')), ('inception_block_7.b2.4.bias', tensor([-1.1405e-02, -7.5851e-03, -1.2107e-02, -1.7419e-02, -4.4280e-03,\n",
            "        -1.7692e-03, -6.6275e-03, -6.7357e-03, -4.2283e-03, -6.4269e-03,\n",
            "        -1.1916e-02, -2.2452e-03, -1.3837e-02, -2.0144e-02, -7.5359e-03,\n",
            "        -1.9489e-02, -1.5618e-02,  4.1318e-03,  5.8936e-04, -1.1490e-02,\n",
            "        -1.3289e-02, -8.7523e-03, -3.1832e-03,  3.7012e-03, -1.1593e-02,\n",
            "        -8.7294e-03, -1.1501e-02,  2.3551e-03, -1.9718e-02, -4.0584e-03,\n",
            "        -1.1936e-02, -6.6397e-03, -1.0398e-02, -1.3771e-02, -9.5772e-03,\n",
            "         7.4889e-03, -4.5254e-03, -4.7928e-03,  8.7046e-03, -6.5338e-03,\n",
            "        -1.6409e-02, -1.2710e-02, -1.1438e-02, -5.1883e-03, -1.4225e-02,\n",
            "        -7.7499e-03, -1.0825e-03, -2.9587e-02, -1.0707e-02,  3.4821e-03,\n",
            "        -1.6244e-02, -2.1310e-02, -1.0282e-02, -4.4431e-03, -1.1427e-02,\n",
            "        -2.4088e-02, -6.2635e-03, -5.7119e-03, -9.8587e-03, -2.2650e-02,\n",
            "        -5.2656e-03, -4.0472e-03, -8.9650e-03, -6.8955e-03, -8.5791e-03,\n",
            "        -3.2447e-03, -1.5747e-02, -8.7634e-03, -1.0391e-02, -7.2662e-03,\n",
            "         1.0474e-02, -1.2203e-02, -1.5563e-02, -1.1362e-02, -1.4739e-03,\n",
            "        -5.1300e-03, -9.5225e-03, -1.2089e-03, -3.1403e-03, -6.3130e-03,\n",
            "        -1.0933e-02, -2.5162e-02, -1.8846e-02, -1.1810e-02, -5.3430e-03,\n",
            "        -2.5566e-03, -2.1190e-03, -9.3623e-03, -1.0930e-02, -3.1325e-03,\n",
            "        -2.0137e-02, -1.2067e-02, -1.6326e-02, -8.8927e-03, -1.4209e-02,\n",
            "        -5.7046e-03, -1.5749e-02, -1.6259e-02,  7.4367e-03, -2.4318e-02,\n",
            "         1.3362e-04, -2.1193e-02, -3.1036e-03, -7.6278e-03, -8.1197e-03,\n",
            "        -6.2245e-03, -4.6658e-03, -4.5983e-03, -1.1247e-02, -8.4388e-03,\n",
            "        -1.3716e-02, -3.9337e-03, -1.1562e-02, -8.5270e-03, -1.0980e-02,\n",
            "        -2.2035e-02, -2.3626e-03, -1.5528e-02, -4.0947e-03, -3.4931e-03,\n",
            "        -1.1075e-02,  3.0113e-03, -3.3817e-03, -5.9341e-03, -3.2977e-03,\n",
            "        -1.0318e-02, -9.6938e-03, -1.3909e-02, -1.7332e-03, -2.2399e-02,\n",
            "        -1.1896e-02, -1.5259e-02, -9.3699e-03, -1.1040e-02, -1.3910e-02,\n",
            "        -6.4517e-03, -3.4992e-03, -1.2171e-02, -1.3385e-02,  3.4961e-03,\n",
            "         4.9454e-03, -1.5253e-02,  3.2545e-03, -3.1622e-03, -1.9504e-02,\n",
            "        -9.0769e-03, -1.4570e-02, -6.5248e-03, -1.5793e-02,  5.3339e-03,\n",
            "        -1.6188e-02, -7.8552e-04, -2.5535e-04, -2.2533e-02, -1.7154e-02,\n",
            "        -1.4719e-02,  2.1298e-03, -1.3626e-02, -8.6856e-03, -1.0558e-02,\n",
            "        -1.2924e-02, -1.0611e-02, -1.8502e-02, -1.0508e-02, -6.9686e-03,\n",
            "        -1.2047e-02, -5.8648e-03, -1.6268e-02, -1.2542e-02, -8.7978e-03,\n",
            "        -8.3257e-03, -6.9936e-04, -6.8209e-03, -9.6313e-03, -1.1274e-02,\n",
            "        -1.0967e-02, -1.9438e-02, -2.2843e-02, -1.6771e-02, -1.3953e-02,\n",
            "        -2.1949e-02, -2.8703e-03, -1.2752e-02, -1.4328e-02, -6.3772e-03,\n",
            "        -1.7745e-02, -6.2465e-03, -1.4498e-02, -6.8568e-03, -1.0495e-02,\n",
            "        -1.1164e-02, -1.2760e-02, -1.3504e-02, -4.6334e-03, -1.5952e-02,\n",
            "        -1.6689e-02, -9.4259e-03,  2.5358e-06, -2.0567e-02, -1.8712e-02,\n",
            "        -1.8255e-02, -1.5024e-02, -1.6734e-03, -4.5161e-03, -1.5246e-02,\n",
            "         5.6668e-03, -1.5322e-02, -7.0530e-03, -8.5503e-03, -1.5599e-02,\n",
            "        -1.3950e-04, -1.5617e-02, -8.0334e-03, -1.2780e-02, -3.6605e-03,\n",
            "         2.0540e-03, -8.9380e-03, -1.1407e-02, -5.2812e-03, -1.8439e-02,\n",
            "        -2.9927e-03, -4.4997e-03, -5.3255e-03, -2.1013e-02, -1.9625e-04,\n",
            "        -7.9849e-03, -5.1459e-03,  1.3921e-03,  1.6719e-03, -1.2269e-02,\n",
            "        -8.1437e-03, -1.3307e-02, -2.2255e-02, -2.5646e-02, -1.2106e-02,\n",
            "         5.4478e-04,  6.7616e-03, -1.7387e-03, -1.2137e-02, -3.5781e-03,\n",
            "        -1.3597e-02, -1.1865e-02, -1.7662e-03, -6.2069e-03, -9.4780e-03,\n",
            "        -8.7704e-03, -1.5446e-02,  4.6861e-03, -1.1267e-02, -5.6354e-03,\n",
            "        -8.3812e-05, -1.3546e-02, -2.9301e-03, -1.3775e-02, -1.5380e-02,\n",
            "        -1.8653e-02, -1.2393e-02, -1.9746e-02, -1.6461e-02, -2.0589e-02,\n",
            "        -7.9397e-04, -1.2521e-02, -6.0610e-04, -5.5640e-03, -4.8608e-03,\n",
            "        -1.1090e-02, -3.1956e-03, -3.6366e-03, -1.6292e-02, -4.8002e-03,\n",
            "        -1.2586e-02, -1.2248e-02, -4.2857e-03, -1.3466e-02, -1.5263e-02,\n",
            "        -1.0851e-02, -9.4133e-03, -1.4346e-02,  6.6984e-03, -8.5350e-03,\n",
            "        -8.2556e-03, -6.7317e-03, -1.1918e-02, -1.2597e-02, -1.2959e-02,\n",
            "        -7.3394e-03, -1.5631e-02,  4.2870e-03, -1.6769e-02, -1.9801e-02,\n",
            "        -1.2808e-02,  2.3612e-04, -2.0938e-03, -6.8542e-03, -7.2381e-03,\n",
            "        -1.5667e-02, -1.2441e-03, -1.8335e-02, -1.7056e-02,  2.4250e-03,\n",
            "        -9.6544e-03, -9.9776e-03, -8.4628e-03, -1.6749e-02, -5.3402e-03,\n",
            "        -1.0938e-02,  2.9241e-03, -1.0956e-02, -9.2966e-03, -1.1105e-02,\n",
            "        -1.8130e-02, -1.0480e-02, -4.6159e-04, -8.9711e-03, -3.7785e-03,\n",
            "        -1.6586e-03, -7.2751e-03, -6.1776e-03, -1.1524e-02, -8.9885e-03],\n",
            "       device='cuda:0')), ('inception_block_7.b2.4.running_mean', tensor([-0.7160,  0.2349, -0.0667,  0.0701, -0.2495, -0.2721, -0.4108, -0.3746,\n",
            "        -1.2481, -0.4402,  0.0909, -0.9891,  0.0681,  0.1381, -0.0498, -0.0183,\n",
            "         0.1279,  0.1718,  0.4148, -0.7810,  0.1342, -0.5636, -0.9465, -0.1284,\n",
            "        -0.4340,  0.4134, -0.3399,  0.5041, -0.3914, -0.5113,  0.2040, -0.7373,\n",
            "        -0.9789, -0.5368,  0.3921, -0.7717, -0.7242,  0.1001, -0.5823, -0.1312,\n",
            "        -0.4866, -0.1295,  0.5542,  0.4425,  0.3175, -0.1909, -0.4548,  0.2105,\n",
            "        -0.1302, -1.0192,  0.4864, -0.5445,  0.0095, -0.3692, -0.2846,  0.1155,\n",
            "         0.1020, -0.4845,  0.2679, -0.1080, -0.2338, -1.0674,  0.0611, -0.1617,\n",
            "         0.0948,  0.3669,  0.0354, -1.0797, -0.8967, -0.3536, -0.5054, -0.8605,\n",
            "        -0.2234, -0.1008,  0.1169,  0.0317, -0.7157, -0.1859,  0.3863, -0.2770,\n",
            "        -0.2783, -0.4363, -0.9361, -0.1314, -0.4691, -0.1521, -0.9122, -0.0400,\n",
            "        -0.5528, -1.1421, -0.0479,  0.0934,  0.2305,  0.1580, -0.3646, -0.0377,\n",
            "        -0.3587,  0.5064, -0.5425,  0.0494, -0.7240,  0.4901, -0.6795,  0.0900,\n",
            "        -0.1528,  0.4884, -0.1267, -0.2444,  0.1690, -0.2105, -0.1109,  0.1282,\n",
            "        -0.4885, -1.0472, -0.5445,  0.6225, -0.3879,  0.0822, -0.4813,  0.2753,\n",
            "        -0.1066, -0.3417,  0.2952, -0.0014, -0.6017,  0.0532, -0.7832, -0.7400,\n",
            "        -0.7282, -0.6085,  0.0236,  0.8597, -0.5404, -0.1393, -0.3789, -0.2688,\n",
            "         0.5897, -1.0828, -0.1040, -0.2241, -0.5889,  0.2716, -0.2013,  0.4618,\n",
            "        -0.5440,  0.3539,  0.2062, -0.1791, -0.5850, -0.7449, -0.5349,  0.3767,\n",
            "        -0.3454,  0.0517,  0.1046, -0.0734,  0.0103, -0.8268,  0.5299, -0.4463,\n",
            "        -0.9495, -0.3946,  0.8107, -0.3544,  0.0505,  0.1456, -0.4099, -0.5400,\n",
            "        -0.3311, -0.0560, -0.7114, -0.7288,  0.9122, -0.6472, -0.0500, -0.3025,\n",
            "         0.2806, -0.0097, -0.1942,  0.1329, -0.6722, -0.5667,  0.1204,  0.3051,\n",
            "        -0.0240,  0.2221,  0.3867, -0.7850, -0.0412,  0.2927, -0.3357,  0.2770,\n",
            "         0.1952, -0.5634, -0.5874, -0.1240, -0.3355,  0.0735, -0.0481, -0.3534,\n",
            "         0.3705,  0.1524,  0.0582,  0.0097, -0.7053,  0.1345, -0.0253,  0.0524,\n",
            "        -0.3384, -0.3249, -0.4023, -0.3337,  0.1954, -0.0230,  0.3786, -0.4817,\n",
            "         0.2000, -0.2149, -0.8983, -0.2150,  0.3827, -0.3420,  0.1874, -0.6708,\n",
            "         0.2750, -0.3120, -0.0920, -0.1296, -0.9180,  0.2687, -0.2719, -0.3230,\n",
            "         0.1898,  0.3472, -0.4467, -0.2656, -0.7108,  0.2340,  0.2945, -0.2014,\n",
            "        -0.3634,  0.1654, -0.0622, -0.7161,  0.2260,  0.6376,  0.2299, -0.3936,\n",
            "        -0.0848, -0.6099, -0.0206, -0.1939, -0.0647, -1.0426,  0.1074, -0.7372,\n",
            "        -0.3892,  0.5573, -0.2112, -0.5553, -0.3186,  0.0788, -0.7030, -0.9475,\n",
            "         0.1155,  0.3352, -0.1855, -0.3667,  0.2600,  0.1080, -0.6698, -0.3330,\n",
            "        -0.7587, -0.5524, -0.5120, -0.6889,  0.3128,  0.2334, -0.4719, -0.2992,\n",
            "         0.1281,  0.0701, -0.4274,  0.3272, -0.2448, -0.1914, -0.0104, -0.2599,\n",
            "        -0.3866,  0.1592,  0.2713, -0.6448,  0.4156,  0.4691, -0.1180,  0.1206,\n",
            "        -0.1369,  0.8221, -0.6047, -1.0764, -0.4051,  1.0619, -0.4946, -0.3555,\n",
            "         0.3905,  0.0506, -0.5928,  0.5328, -0.3564, -0.0225, -0.3948, -0.3916,\n",
            "        -0.7679, -0.0712, -0.3515, -0.4891, -0.4204, -0.4202,  0.0676,  0.2812],\n",
            "       device='cuda:0')), ('inception_block_7.b2.4.running_var', tensor([0.2798, 0.3493, 0.2342, 0.2687, 0.3462, 0.4109, 0.5735, 0.2512, 0.4585,\n",
            "        0.3278, 0.3411, 0.3326, 0.2696, 0.3355, 0.2975, 0.3823, 0.2957, 0.3591,\n",
            "        0.3349, 0.2487, 0.4980, 0.3465, 0.2580, 0.2305, 0.2740, 0.2483, 0.3045,\n",
            "        0.3747, 0.3733, 0.2386, 0.3220, 0.4666, 0.4716, 0.4300, 0.3774, 0.2542,\n",
            "        0.4778, 0.2709, 0.2669, 0.3260, 0.3395, 0.3563, 0.3082, 0.3786, 0.3245,\n",
            "        0.2686, 0.3340, 0.3694, 0.2732, 0.3781, 0.3412, 0.4632, 0.3023, 0.3096,\n",
            "        0.2790, 0.4131, 0.3622, 0.3289, 0.2830, 0.3104, 0.2144, 0.3024, 0.3122,\n",
            "        0.4572, 0.2629, 0.2311, 0.3769, 0.3062, 0.4965, 0.2442, 0.3418, 0.3080,\n",
            "        0.3223, 0.2269, 0.3449, 0.2935, 0.2277, 0.2862, 0.2975, 0.3681, 0.2729,\n",
            "        0.2712, 0.5486, 0.2806, 0.3137, 0.3382, 0.2826, 0.3249, 0.3260, 0.3267,\n",
            "        0.3813, 0.2472, 0.4675, 0.3652, 0.2890, 0.4114, 0.3630, 0.3917, 0.2573,\n",
            "        0.2650, 0.3497, 0.2297, 0.3447, 0.3439, 0.3382, 0.3035, 0.3710, 0.3509,\n",
            "        0.2693, 0.3736, 0.2864, 0.2660, 0.3999, 0.3928, 0.5128, 0.3552, 0.3120,\n",
            "        0.3365, 0.4056, 0.3447, 0.4350, 0.2537, 0.2602, 0.2509, 0.4283, 0.3280,\n",
            "        0.2801, 0.3850, 0.4783, 0.3559, 0.2874, 0.2435, 0.2446, 0.3189, 0.3238,\n",
            "        0.2844, 0.2899, 0.3762, 0.3675, 0.3928, 0.2594, 0.4219, 0.4302, 0.3765,\n",
            "        0.2873, 0.3382, 0.2737, 0.3900, 0.1920, 0.4632, 0.2967, 0.2874, 0.2668,\n",
            "        0.3563, 0.3707, 0.3975, 0.3110, 0.3483, 0.3017, 0.3134, 0.3499, 0.2472,\n",
            "        0.3856, 0.2628, 0.3514, 0.2868, 0.2908, 0.3518, 0.3907, 0.2648, 0.2720,\n",
            "        0.4545, 0.3213, 0.3011, 0.2830, 0.3074, 0.3453, 0.2727, 0.2877, 0.3690,\n",
            "        0.3502, 0.3240, 0.2582, 0.2762, 0.3581, 0.3120, 0.4023, 0.2551, 0.3282,\n",
            "        0.3830, 0.3731, 0.3227, 0.3420, 0.4056, 0.3572, 0.2745, 0.4318, 0.4042,\n",
            "        0.3716, 0.2661, 0.2001, 0.3056, 0.2996, 0.3695, 0.3193, 0.2272, 0.3145,\n",
            "        0.2776, 0.3031, 0.3405, 0.3680, 0.3349, 0.5520, 0.3740, 0.3135, 0.2994,\n",
            "        0.2519, 0.3770, 0.4901, 0.3121, 0.3321, 0.2545, 0.3136, 0.2304, 0.4057,\n",
            "        0.3053, 0.2936, 0.3119, 0.2538, 0.3607, 0.2202, 0.3315, 0.2679, 0.3971,\n",
            "        0.3002, 0.3312, 0.4459, 0.4625, 0.4592, 0.3066, 0.2608, 0.3046, 0.2691,\n",
            "        0.4001, 0.2656, 0.3032, 0.3248, 0.3558, 0.3443, 0.4191, 0.2584, 0.3206,\n",
            "        0.3374, 0.2952, 0.2727, 0.2681, 0.3262, 0.2600, 0.2837, 0.3082, 0.3452,\n",
            "        0.2959, 0.2187, 0.2527, 0.2805, 0.3441, 0.3771, 0.3347, 0.3238, 0.3172,\n",
            "        0.2919, 0.2170, 0.2907, 0.3467, 0.2659, 0.2535, 0.4653, 0.2938, 0.2184,\n",
            "        0.3019, 0.2560, 0.3321, 0.4321, 0.2252, 0.3840, 0.3389, 0.3281, 0.2813,\n",
            "        0.2276, 0.2983, 0.3243, 0.2799, 0.4021, 0.2638, 0.2456, 0.2356, 0.2782,\n",
            "        0.3752, 0.3077, 0.2999, 0.3628, 0.3719, 0.3084, 0.2478, 0.2295, 0.3273,\n",
            "        0.3487, 0.2833, 0.3369, 0.3547, 0.2665, 0.3843, 0.2426, 0.2861, 0.2030,\n",
            "        0.4248, 0.3294, 0.2548, 0.3143, 0.3056], device='cuda:0')), ('inception_block_7.b2.4.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_7.b3.0.weight', tensor([[[[-2.4976e-02]],\n",
            "\n",
            "         [[ 4.2014e-02]],\n",
            "\n",
            "         [[-2.9331e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.2784e-02]],\n",
            "\n",
            "         [[ 1.9192e-02]],\n",
            "\n",
            "         [[ 1.8097e-05]]],\n",
            "\n",
            "\n",
            "        [[[-2.1018e-02]],\n",
            "\n",
            "         [[ 2.7346e-02]],\n",
            "\n",
            "         [[-1.0688e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0988e-02]],\n",
            "\n",
            "         [[-2.3900e-02]],\n",
            "\n",
            "         [[ 1.3589e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.2623e-02]],\n",
            "\n",
            "         [[-1.2984e-02]],\n",
            "\n",
            "         [[ 1.4263e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.9621e-03]],\n",
            "\n",
            "         [[-1.5182e-03]],\n",
            "\n",
            "         [[ 2.7159e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.3176e-02]],\n",
            "\n",
            "         [[-2.7513e-02]],\n",
            "\n",
            "         [[ 1.8687e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.2599e-03]],\n",
            "\n",
            "         [[ 1.7195e-04]],\n",
            "\n",
            "         [[-1.1381e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.9617e-02]],\n",
            "\n",
            "         [[-3.6582e-04]],\n",
            "\n",
            "         [[-1.7772e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0391e-02]],\n",
            "\n",
            "         [[-9.9142e-03]],\n",
            "\n",
            "         [[-2.1889e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4742e-02]],\n",
            "\n",
            "         [[-5.9941e-03]],\n",
            "\n",
            "         [[ 3.9532e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0642e-02]],\n",
            "\n",
            "         [[-2.8521e-02]],\n",
            "\n",
            "         [[-3.6801e-02]]]], device='cuda:0')), ('inception_block_7.b3.0.bias', tensor([-0.0242,  0.0362,  0.0386, -0.0146, -0.0176, -0.0234,  0.0207, -0.0197,\n",
            "         0.0327,  0.0042,  0.0035,  0.0188, -0.0249, -0.0277, -0.0389,  0.0330,\n",
            "        -0.0084,  0.0216,  0.0164, -0.0087,  0.0304,  0.0257,  0.0231,  0.0428,\n",
            "         0.0289, -0.0011, -0.0168,  0.0121,  0.0373, -0.0077,  0.0060,  0.0353],\n",
            "       device='cuda:0')), ('inception_block_7.b3.1.weight', tensor([1.0041, 1.0123, 0.9969, 1.0040, 0.9997, 0.9963, 0.9978, 1.0023, 1.0061,\n",
            "        0.9992, 0.9926, 0.9914, 0.9999, 0.9938, 0.9909, 0.9936, 1.0022, 1.0007,\n",
            "        1.0044, 1.0037, 0.9964, 1.0016, 0.9940, 0.9919, 1.0036, 1.0066, 0.9994,\n",
            "        1.0019, 1.0069, 1.0070, 1.0031, 0.9918], device='cuda:0')), ('inception_block_7.b3.1.bias', tensor([ 7.6815e-04,  5.6528e-04, -3.0032e-03, -4.2031e-03,  5.2160e-03,\n",
            "        -8.6589e-03, -5.6761e-03, -4.5428e-03,  6.9108e-03, -3.4910e-03,\n",
            "        -7.7792e-03,  2.5875e-03, -6.7492e-04, -7.2670e-05, -1.3048e-02,\n",
            "        -7.8460e-03, -8.0474e-03,  3.7531e-03,  4.0301e-03,  1.3668e-03,\n",
            "        -1.2551e-02, -6.1835e-03, -2.0558e-02, -1.0061e-02, -1.9019e-03,\n",
            "        -2.7969e-04, -1.2190e-02, -1.1939e-02,  4.7302e-03, -1.2123e-03,\n",
            "        -4.6592e-03, -1.6609e-02], device='cuda:0')), ('inception_block_7.b3.1.running_mean', tensor([-1.5380e-01,  4.0525e-01, -7.5163e-02,  9.0020e-02,  1.4078e-01,\n",
            "        -1.7862e-01, -4.8293e-01, -1.1741e-01,  3.2188e-01,  8.6513e-02,\n",
            "         3.7735e-01, -3.3732e-01, -1.7506e-01, -4.9379e-01, -7.4420e-02,\n",
            "        -1.4893e-01,  2.8864e-02,  3.4832e-01,  2.5266e-01,  3.7405e-01,\n",
            "         3.7307e-01, -2.7687e-01,  2.1979e-01,  1.3811e-01, -1.1468e-01,\n",
            "         1.4078e-02, -9.5522e-03, -2.7411e-04,  4.1337e-01,  3.0408e-01,\n",
            "        -3.8301e-01, -4.4775e-01], device='cuda:0')), ('inception_block_7.b3.1.running_var', tensor([0.3372, 0.2514, 0.3005, 0.2953, 0.3168, 0.1654, 0.2043, 0.2039, 0.2227,\n",
            "        0.1793, 0.2301, 0.1710, 0.2250, 0.2359, 0.2577, 0.2242, 0.2168, 0.2813,\n",
            "        0.2535, 0.2548, 0.2764, 0.1915, 0.1885, 0.2071, 0.2801, 0.2396, 0.2148,\n",
            "        0.1976, 0.3248, 0.2482, 0.2294, 0.2637], device='cuda:0')), ('inception_block_7.b3.1.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_7.b3.3.weight', tensor([[[[-0.0435,  0.0512,  0.0544],\n",
            "          [ 0.0366,  0.0503,  0.0295],\n",
            "          [ 0.0006, -0.0109,  0.0566]],\n",
            "\n",
            "         [[ 0.0056, -0.0510,  0.0211],\n",
            "          [-0.0512, -0.0073,  0.0141],\n",
            "          [ 0.0069, -0.0152, -0.0166]],\n",
            "\n",
            "         [[ 0.0300, -0.0472, -0.0524],\n",
            "          [-0.0122,  0.0032, -0.0188],\n",
            "          [-0.0113,  0.0342, -0.0325]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0417,  0.0461, -0.0176],\n",
            "          [ 0.0263, -0.0543, -0.0287],\n",
            "          [-0.0227, -0.0283, -0.0187]],\n",
            "\n",
            "         [[-0.0475,  0.0547,  0.0564],\n",
            "          [-0.0378, -0.0494, -0.0241],\n",
            "          [-0.0114,  0.0167, -0.0442]],\n",
            "\n",
            "         [[-0.0008,  0.0112, -0.0657],\n",
            "          [ 0.0276,  0.0459, -0.0474],\n",
            "          [ 0.0187,  0.0506,  0.0290]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0021, -0.0096,  0.0246],\n",
            "          [-0.0226, -0.0132,  0.0498],\n",
            "          [ 0.0489,  0.0377,  0.0565]],\n",
            "\n",
            "         [[ 0.0347, -0.0378, -0.0347],\n",
            "          [-0.0619,  0.0021, -0.0069],\n",
            "          [ 0.0451,  0.0020, -0.0373]],\n",
            "\n",
            "         [[-0.0220,  0.0070, -0.0440],\n",
            "          [ 0.0256, -0.0251,  0.0494],\n",
            "          [ 0.0623,  0.0523,  0.0036]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0495,  0.0137, -0.0009],\n",
            "          [ 0.0526,  0.0100, -0.0162],\n",
            "          [-0.0125, -0.0235, -0.0113]],\n",
            "\n",
            "         [[ 0.0451, -0.0485, -0.0108],\n",
            "          [ 0.0040,  0.0296, -0.0449],\n",
            "          [-0.0567, -0.0413,  0.0459]],\n",
            "\n",
            "         [[ 0.0263, -0.0052,  0.0534],\n",
            "          [-0.0226,  0.0195, -0.0155],\n",
            "          [-0.0413,  0.0530, -0.0010]]],\n",
            "\n",
            "\n",
            "        [[[-0.0193, -0.0412, -0.0479],\n",
            "          [ 0.0459, -0.0576,  0.0443],\n",
            "          [ 0.0551, -0.0379, -0.0558]],\n",
            "\n",
            "         [[ 0.0324, -0.0499,  0.0385],\n",
            "          [ 0.0486, -0.0309, -0.0077],\n",
            "          [ 0.0205, -0.0118,  0.0210]],\n",
            "\n",
            "         [[ 0.0397,  0.0169, -0.0310],\n",
            "          [-0.0379,  0.0186,  0.0295],\n",
            "          [-0.0356,  0.0310,  0.0190]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0304,  0.0115,  0.0474],\n",
            "          [ 0.0454,  0.0004, -0.0219],\n",
            "          [-0.0033, -0.0482, -0.0233]],\n",
            "\n",
            "         [[ 0.0241,  0.0296,  0.0255],\n",
            "          [ 0.0405, -0.0059, -0.0388],\n",
            "          [ 0.0444, -0.0200, -0.0378]],\n",
            "\n",
            "         [[-0.0366,  0.0372,  0.0405],\n",
            "          [-0.0053,  0.0258,  0.0518],\n",
            "          [ 0.0510, -0.0292, -0.0496]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0004, -0.0240,  0.0117],\n",
            "          [ 0.0447, -0.0288,  0.0143],\n",
            "          [-0.0227,  0.0545,  0.0440]],\n",
            "\n",
            "         [[-0.0534,  0.0030,  0.0089],\n",
            "          [ 0.0560, -0.0073,  0.0027],\n",
            "          [ 0.0518, -0.0239,  0.0227]],\n",
            "\n",
            "         [[-0.0371, -0.0413, -0.0425],\n",
            "          [ 0.0208, -0.0248, -0.0160],\n",
            "          [-0.0183,  0.0214, -0.0131]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0522, -0.0509, -0.0563],\n",
            "          [ 0.0585,  0.0552,  0.0260],\n",
            "          [ 0.0141,  0.0022, -0.0622]],\n",
            "\n",
            "         [[-0.0593, -0.0435,  0.0389],\n",
            "          [-0.0703, -0.0451, -0.0571],\n",
            "          [-0.0229, -0.0542, -0.0114]],\n",
            "\n",
            "         [[-0.0320,  0.0538,  0.0179],\n",
            "          [ 0.0135,  0.0527, -0.0553],\n",
            "          [ 0.0196,  0.0098, -0.0583]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0343,  0.0143,  0.0135],\n",
            "          [-0.0328,  0.0306,  0.0139],\n",
            "          [ 0.0145,  0.0210,  0.0122]],\n",
            "\n",
            "         [[-0.0005,  0.0511,  0.0278],\n",
            "          [ 0.0476,  0.0006, -0.0236],\n",
            "          [ 0.0358, -0.0162, -0.0220]],\n",
            "\n",
            "         [[ 0.0352, -0.0065, -0.0543],\n",
            "          [ 0.0315, -0.0197,  0.0115],\n",
            "          [ 0.0620,  0.0501, -0.0208]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0192,  0.0437, -0.0217],\n",
            "          [-0.0446, -0.0246, -0.0628],\n",
            "          [ 0.0569,  0.0441, -0.0597]],\n",
            "\n",
            "         [[ 0.0508, -0.0280, -0.0227],\n",
            "          [ 0.0533, -0.0212, -0.0483],\n",
            "          [-0.0418, -0.0401, -0.0051]],\n",
            "\n",
            "         [[ 0.0234, -0.0114, -0.0439],\n",
            "          [ 0.0243,  0.0452,  0.0118],\n",
            "          [-0.0465,  0.0375,  0.0348]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0410, -0.0385,  0.0401],\n",
            "          [ 0.0110, -0.0063,  0.0287],\n",
            "          [ 0.0141, -0.0393,  0.0318]],\n",
            "\n",
            "         [[ 0.0400, -0.0428,  0.0637],\n",
            "          [-0.0087, -0.0078, -0.0465],\n",
            "          [ 0.0474,  0.0556, -0.0168]],\n",
            "\n",
            "         [[ 0.0345,  0.0118,  0.0510],\n",
            "          [ 0.0453, -0.0159, -0.0045],\n",
            "          [ 0.0369,  0.0356,  0.0374]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0143, -0.0479, -0.0507],\n",
            "          [ 0.0016, -0.0473,  0.0433],\n",
            "          [ 0.0190,  0.0158, -0.0193]],\n",
            "\n",
            "         [[-0.0377,  0.0129,  0.0369],\n",
            "          [-0.0292,  0.0415,  0.0559],\n",
            "          [ 0.0410, -0.0059,  0.0483]],\n",
            "\n",
            "         [[ 0.0583,  0.0632,  0.0022],\n",
            "          [ 0.0233,  0.0437, -0.0411],\n",
            "          [ 0.0449,  0.0030, -0.0275]]]], device='cuda:0')), ('inception_block_7.b3.3.bias', tensor([-0.0201,  0.0508, -0.0385, -0.0133,  0.0012,  0.0022, -0.0571, -0.0291,\n",
            "        -0.0344,  0.0588,  0.0167, -0.0223, -0.0494, -0.0109,  0.0225,  0.0515,\n",
            "        -0.0251,  0.0504,  0.0126,  0.0567,  0.0302,  0.0155,  0.0225,  0.0592,\n",
            "        -0.0151, -0.0381,  0.0237,  0.0443, -0.0285, -0.0461,  0.0366,  0.0441,\n",
            "        -0.0323,  0.0282,  0.0166,  0.0281, -0.0140,  0.0255,  0.0358,  0.0216,\n",
            "         0.0539,  0.0154, -0.0502, -0.0075, -0.0039,  0.0155,  0.0485, -0.0140,\n",
            "         0.0353,  0.0351, -0.0208, -0.0403, -0.0137,  0.0173,  0.0222,  0.0008,\n",
            "         0.0176,  0.0412, -0.0481,  0.0369, -0.0224,  0.0077,  0.0143, -0.0459,\n",
            "        -0.0534, -0.0462,  0.0409,  0.0587,  0.0264, -0.0080,  0.0208,  0.0562,\n",
            "        -0.0401, -0.0016, -0.0471,  0.0313, -0.0189,  0.0273,  0.0565,  0.0300,\n",
            "        -0.0085,  0.0121,  0.0106, -0.0571,  0.0086, -0.0255,  0.0125, -0.0096,\n",
            "        -0.0409,  0.0287,  0.0405,  0.0002,  0.0252,  0.0573, -0.0452, -0.0110,\n",
            "        -0.0574,  0.0538,  0.0200,  0.0545,  0.0145, -0.0439, -0.0583, -0.0206,\n",
            "        -0.0122,  0.0339, -0.0458,  0.0063,  0.0539, -0.0040,  0.0386,  0.0222,\n",
            "        -0.0419, -0.0094,  0.0382,  0.0560,  0.0053, -0.0048, -0.0013, -0.0338,\n",
            "        -0.0077,  0.0086,  0.0461,  0.0342, -0.0364, -0.0190, -0.0045,  0.0074],\n",
            "       device='cuda:0')), ('inception_block_7.b3.4.weight', tensor([1.0005, 0.9956, 0.9928, 0.9898, 1.0128, 1.0092, 1.0039, 1.0048, 1.0069,\n",
            "        1.0067, 0.9920, 0.9889, 0.9988, 0.9855, 1.0033, 0.9985, 0.9954, 0.9996,\n",
            "        1.0084, 0.9947, 0.9984, 0.9918, 0.9976, 0.9950, 1.0027, 0.9983, 1.0035,\n",
            "        1.0064, 0.9978, 0.9986, 0.9980, 1.0013, 1.0073, 0.9898, 1.0061, 0.9934,\n",
            "        1.0056, 0.9980, 1.0069, 1.0028, 1.0065, 1.0074, 0.9952, 1.0132, 0.9882,\n",
            "        1.0081, 1.0106, 1.0024, 1.0112, 1.0009, 0.9982, 0.9977, 1.0044, 1.0016,\n",
            "        1.0093, 1.0019, 0.9969, 1.0078, 1.0051, 0.9856, 1.0103, 1.0032, 1.0066,\n",
            "        0.9895, 1.0015, 1.0073, 0.9980, 0.9921, 0.9960, 0.9963, 1.0000, 1.0000,\n",
            "        1.0121, 0.9991, 0.9939, 0.9969, 0.9959, 0.9873, 1.0004, 0.9973, 0.9981,\n",
            "        0.9948, 1.0038, 1.0120, 1.0062, 0.9980, 0.9983, 1.0072, 0.9925, 1.0072,\n",
            "        0.9932, 0.9902, 0.9985, 0.9904, 0.9930, 0.9874, 0.9879, 1.0029, 1.0023,\n",
            "        0.9969, 0.9869, 1.0049, 1.0119, 1.0024, 0.9958, 0.9848, 0.9951, 1.0073,\n",
            "        1.0039, 0.9933, 0.9930, 1.0117, 1.0194, 0.9838, 1.0026, 1.0012, 1.0102,\n",
            "        0.9876, 1.0052, 1.0047, 0.9991, 1.0052, 1.0002, 0.9960, 0.9970, 1.0000,\n",
            "        1.0113, 1.0046], device='cuda:0')), ('inception_block_7.b3.4.bias', tensor([-1.4571e-03, -8.2223e-03, -1.3984e-02, -8.1772e-03,  7.8343e-04,\n",
            "         1.0656e-03, -3.1601e-03,  5.0148e-03,  2.3990e-03,  2.6958e-03,\n",
            "        -7.3726e-03, -8.5350e-04, -6.7851e-03, -8.1463e-03, -5.7751e-03,\n",
            "        -2.0518e-03, -1.4519e-02, -5.8248e-03,  2.6333e-03, -1.7180e-02,\n",
            "        -1.4099e-02, -1.7372e-02,  3.1075e-03, -1.0566e-02, -1.5533e-03,\n",
            "        -1.0429e-03,  6.3650e-03, -9.1007e-05, -1.5827e-03,  9.6413e-04,\n",
            "        -8.9298e-03, -6.4228e-03, -8.7795e-03, -8.8512e-03, -9.8347e-03,\n",
            "        -8.2376e-03, -2.3824e-03, -1.1585e-02, -5.3355e-03,  1.7908e-03,\n",
            "        -3.8606e-04,  2.1598e-03, -8.0387e-03, -6.9339e-03, -1.3889e-02,\n",
            "         2.5528e-03,  9.3030e-03, -1.1167e-02, -4.3455e-03, -8.2774e-03,\n",
            "        -7.8908e-03, -6.4601e-03, -2.9685e-03, -4.7339e-03, -1.5977e-02,\n",
            "         1.7514e-03, -1.2326e-02,  2.0347e-03, -1.2070e-02, -2.0084e-02,\n",
            "         2.6946e-03, -3.2122e-03, -5.3729e-03, -2.0693e-03,  4.6563e-03,\n",
            "         5.3512e-03, -4.2351e-03, -1.1569e-03, -1.7862e-02, -5.2572e-03,\n",
            "         2.1980e-04, -8.2220e-03,  7.4913e-03, -7.4270e-03, -1.5970e-02,\n",
            "        -1.3537e-02, -2.3984e-03, -8.0213e-03,  1.7039e-04, -7.2700e-03,\n",
            "        -9.0365e-03, -1.2124e-02, -2.7180e-03,  9.0771e-03,  1.4763e-03,\n",
            "        -1.4515e-02,  6.0712e-03,  1.5000e-03, -1.8128e-02,  8.2011e-03,\n",
            "        -1.3020e-02, -1.9911e-02, -5.8608e-03, -7.7448e-03, -1.1329e-02,\n",
            "        -2.2252e-03, -2.5767e-02,  2.4938e-03, -6.1719e-03, -1.1263e-02,\n",
            "        -8.8023e-03, -2.9810e-03,  7.4761e-03, -4.3584e-03, -1.5892e-02,\n",
            "        -1.0257e-02, -3.4629e-03, -8.1692e-04, -1.6548e-02, -1.4343e-02,\n",
            "        -1.1407e-02, -3.3247e-04,  4.5004e-03, -1.7328e-02, -8.7806e-03,\n",
            "        -9.7175e-03,  3.8181e-03, -2.0776e-02, -3.0927e-04,  2.9071e-05,\n",
            "        -1.9781e-03, -1.5371e-02, -1.1444e-02, -1.6482e-02, -6.9781e-03,\n",
            "         3.9364e-03, -1.2989e-02, -1.9089e-02], device='cuda:0')), ('inception_block_7.b3.4.running_mean', tensor([-0.4286,  0.2891,  0.0095, -0.3619,  0.0338,  0.0169,  0.1679, -0.0428,\n",
            "        -0.0737,  0.0366, -0.5199, -0.2669,  0.1040, -0.3113, -0.1909,  0.2333,\n",
            "         0.1682, -0.4316, -0.2689, -0.0140, -0.0129, -0.3677,  0.2218,  0.1700,\n",
            "        -0.3698, -0.1412, -0.0499, -0.1660, -0.1514, -0.1592, -0.1458,  0.0074,\n",
            "        -0.0734,  0.0245, -0.0155,  0.2461, -0.3835,  0.2384, -0.2210,  0.4581,\n",
            "         0.0140,  0.0749,  0.1809, -0.0519,  0.2081, -0.4363, -0.2132,  0.2107,\n",
            "        -0.1039, -0.0056, -0.2796, -0.3161, -0.6430, -0.1616, -0.0904,  0.1828,\n",
            "         0.3201, -0.2213, -0.1142,  0.2352, -0.0380, -0.4767, -0.1757,  0.0963,\n",
            "        -0.2977, -0.2115, -0.3468, -0.1124,  0.0157,  0.0369, -0.3714, -0.0989,\n",
            "        -0.0017,  0.0357,  0.3515, -0.2376,  0.0859,  0.3130,  0.1566, -0.2302,\n",
            "         0.0732,  0.5018, -0.2569, -0.2642,  0.2312,  0.0171, -0.0470, -0.3401,\n",
            "         0.2030, -0.0947,  0.0190,  0.5241, -0.0008, -0.1533,  0.0054, -0.2931,\n",
            "         0.2806,  0.1044,  0.2057,  0.3699,  0.3784,  0.1265, -0.0731, -0.1749,\n",
            "        -0.0249, -0.2956, -0.2737,  0.0819, -0.0549,  0.1879, -0.1139,  0.0922,\n",
            "         0.0252,  0.1384, -0.0076, -0.2147, -0.1937, -0.0640, -0.0143, -0.2187,\n",
            "         0.3401, -0.0594,  0.0924,  0.2288, -0.3846,  0.0043,  0.0769,  0.0711],\n",
            "       device='cuda:0')), ('inception_block_7.b3.4.running_var', tensor([0.2464, 0.1268, 0.1694, 0.1471, 0.0980, 0.1059, 0.1077, 0.1165, 0.1180,\n",
            "        0.1635, 0.3006, 0.1772, 0.1319, 0.1192, 0.1075, 0.1097, 0.1300, 0.1572,\n",
            "        0.1219, 0.1356, 0.1761, 0.1923, 0.1497, 0.1469, 0.1504, 0.1443, 0.1292,\n",
            "        0.1343, 0.1788, 0.1699, 0.1606, 0.1326, 0.1178, 0.1399, 0.1594, 0.1190,\n",
            "        0.1548, 0.1974, 0.1208, 0.1624, 0.0857, 0.1346, 0.1104, 0.1611, 0.1586,\n",
            "        0.1719, 0.1443, 0.1076, 0.1345, 0.1470, 0.1286, 0.1959, 0.2810, 0.1299,\n",
            "        0.1761, 0.1185, 0.1577, 0.2348, 0.1899, 0.1102, 0.2087, 0.1671, 0.1226,\n",
            "        0.0983, 0.1397, 0.1144, 0.1446, 0.2011, 0.2073, 0.1250, 0.1671, 0.1219,\n",
            "        0.1470, 0.1277, 0.1812, 0.2042, 0.1206, 0.1649, 0.1360, 0.1054, 0.1287,\n",
            "        0.2251, 0.1481, 0.1786, 0.1450, 0.2056, 0.1199, 0.1818, 0.1549, 0.1391,\n",
            "        0.1442, 0.1992, 0.1728, 0.2917, 0.1707, 0.1825, 0.1422, 0.1299, 0.1698,\n",
            "        0.1349, 0.1562, 0.1163, 0.1349, 0.1317, 0.1531, 0.1518, 0.1532, 0.1384,\n",
            "        0.1079, 0.2223, 0.0949, 0.1252, 0.1183, 0.1077, 0.1433, 0.2009, 0.1306,\n",
            "        0.1342, 0.1348, 0.1454, 0.2823, 0.1372, 0.1409, 0.1678, 0.1468, 0.1495,\n",
            "        0.1872, 0.1540], device='cuda:0')), ('inception_block_7.b3.4.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_7.b3.6.weight', tensor([[[[ 0.0102, -0.0301,  0.0158],\n",
            "          [-0.0010,  0.0062,  0.0089],\n",
            "          [-0.0169, -0.0086,  0.0199]],\n",
            "\n",
            "         [[ 0.0211,  0.0109,  0.0182],\n",
            "          [ 0.0185, -0.0161,  0.0174],\n",
            "          [-0.0146,  0.0238, -0.0018]],\n",
            "\n",
            "         [[ 0.0014, -0.0206, -0.0106],\n",
            "          [ 0.0207, -0.0119,  0.0177],\n",
            "          [-0.0037,  0.0016,  0.0099]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0209, -0.0374,  0.0101],\n",
            "          [-0.0242,  0.0018, -0.0170],\n",
            "          [-0.0203, -0.0085,  0.0009]],\n",
            "\n",
            "         [[-0.0303, -0.0117, -0.0111],\n",
            "          [-0.0287,  0.0033,  0.0139],\n",
            "          [-0.0169, -0.0062,  0.0207]],\n",
            "\n",
            "         [[-0.0226, -0.0354, -0.0279],\n",
            "          [-0.0107, -0.0266, -0.0178],\n",
            "          [-0.0146,  0.0271,  0.0148]]],\n",
            "\n",
            "\n",
            "        [[[-0.0004, -0.0223,  0.0159],\n",
            "          [ 0.0008, -0.0356,  0.0240],\n",
            "          [-0.0182,  0.0112, -0.0247]],\n",
            "\n",
            "         [[-0.0292, -0.0191,  0.0268],\n",
            "          [-0.0231,  0.0037,  0.0244],\n",
            "          [ 0.0161,  0.0006, -0.0276]],\n",
            "\n",
            "         [[-0.0070, -0.0290,  0.0303],\n",
            "          [-0.0247,  0.0210,  0.0060],\n",
            "          [-0.0318, -0.0220,  0.0127]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0248, -0.0318,  0.0205],\n",
            "          [ 0.0159, -0.0019,  0.0239],\n",
            "          [ 0.0124, -0.0043, -0.0046]],\n",
            "\n",
            "         [[-0.0057,  0.0093, -0.0150],\n",
            "          [ 0.0018, -0.0348,  0.0137],\n",
            "          [-0.0388, -0.0193, -0.0249]],\n",
            "\n",
            "         [[ 0.0056,  0.0142,  0.0206],\n",
            "          [-0.0152, -0.0205,  0.0289],\n",
            "          [-0.0257, -0.0350,  0.0020]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0324, -0.0075, -0.0192],\n",
            "          [-0.0210,  0.0336,  0.0147],\n",
            "          [-0.0258,  0.0050, -0.0009]],\n",
            "\n",
            "         [[-0.0053,  0.0018,  0.0065],\n",
            "          [-0.0037,  0.0206, -0.0229],\n",
            "          [ 0.0190,  0.0221,  0.0037]],\n",
            "\n",
            "         [[-0.0055,  0.0227,  0.0148],\n",
            "          [-0.0211, -0.0254, -0.0037],\n",
            "          [-0.0255,  0.0123,  0.0035]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0049, -0.0105,  0.0133],\n",
            "          [-0.0081, -0.0116, -0.0110],\n",
            "          [ 0.0100,  0.0261,  0.0313]],\n",
            "\n",
            "         [[ 0.0142, -0.0247, -0.0105],\n",
            "          [ 0.0003, -0.0035, -0.0201],\n",
            "          [ 0.0355,  0.0155, -0.0008]],\n",
            "\n",
            "         [[-0.0277, -0.0245,  0.0235],\n",
            "          [ 0.0005, -0.0255, -0.0098],\n",
            "          [ 0.0250,  0.0199, -0.0228]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0112,  0.0136,  0.0224],\n",
            "          [ 0.0139, -0.0145, -0.0202],\n",
            "          [-0.0111,  0.0177, -0.0095]],\n",
            "\n",
            "         [[-0.0184,  0.0296, -0.0028],\n",
            "          [-0.0070, -0.0332, -0.0185],\n",
            "          [ 0.0199,  0.0130, -0.0302]],\n",
            "\n",
            "         [[ 0.0207,  0.0043,  0.0238],\n",
            "          [ 0.0122, -0.0092, -0.0057],\n",
            "          [ 0.0280,  0.0017,  0.0169]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0248, -0.0078, -0.0101],\n",
            "          [ 0.0116, -0.0295,  0.0011],\n",
            "          [-0.0214,  0.0088, -0.0008]],\n",
            "\n",
            "         [[ 0.0162, -0.0089, -0.0107],\n",
            "          [ 0.0029, -0.0099,  0.0141],\n",
            "          [-0.0168,  0.0117, -0.0050]],\n",
            "\n",
            "         [[ 0.0028,  0.0073, -0.0132],\n",
            "          [-0.0220, -0.0357, -0.0139],\n",
            "          [-0.0281,  0.0116, -0.0203]]],\n",
            "\n",
            "\n",
            "        [[[-0.0125, -0.0033, -0.0190],\n",
            "          [ 0.0249, -0.0046, -0.0006],\n",
            "          [-0.0049, -0.0084, -0.0265]],\n",
            "\n",
            "         [[-0.0063,  0.0076,  0.0237],\n",
            "          [ 0.0173, -0.0017, -0.0063],\n",
            "          [ 0.0039, -0.0114, -0.0032]],\n",
            "\n",
            "         [[-0.0063,  0.0005,  0.0012],\n",
            "          [-0.0318, -0.0232, -0.0279],\n",
            "          [-0.0006, -0.0214,  0.0040]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0273,  0.0257, -0.0196],\n",
            "          [-0.0434, -0.0058, -0.0161],\n",
            "          [ 0.0190,  0.0053, -0.0220]],\n",
            "\n",
            "         [[-0.0202,  0.0144,  0.0042],\n",
            "          [-0.0251, -0.0117, -0.0067],\n",
            "          [-0.0153, -0.0313, -0.0377]],\n",
            "\n",
            "         [[ 0.0088,  0.0100,  0.0100],\n",
            "          [-0.0111, -0.0324, -0.0149],\n",
            "          [ 0.0161, -0.0039, -0.0011]]],\n",
            "\n",
            "\n",
            "        [[[-0.0059, -0.0166, -0.0163],\n",
            "          [-0.0194,  0.0260, -0.0230],\n",
            "          [ 0.0319,  0.0122, -0.0038]],\n",
            "\n",
            "         [[ 0.0260, -0.0115, -0.0035],\n",
            "          [ 0.0281,  0.0252, -0.0035],\n",
            "          [ 0.0093,  0.0091,  0.0049]],\n",
            "\n",
            "         [[-0.0037, -0.0239,  0.0133],\n",
            "          [ 0.0322, -0.0007, -0.0142],\n",
            "          [ 0.0225,  0.0087, -0.0039]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0068, -0.0136,  0.0375],\n",
            "          [-0.0097, -0.0181,  0.0104],\n",
            "          [ 0.0053,  0.0035, -0.0334]],\n",
            "\n",
            "         [[ 0.0033,  0.0119, -0.0327],\n",
            "          [-0.0272, -0.0194,  0.0128],\n",
            "          [-0.0150,  0.0028, -0.0270]],\n",
            "\n",
            "         [[ 0.0057,  0.0133, -0.0043],\n",
            "          [-0.0127, -0.0132,  0.0064],\n",
            "          [ 0.0262, -0.0287,  0.0152]]]], device='cuda:0')), ('inception_block_7.b3.6.bias', tensor([ 2.6085e-02, -2.6179e-02,  1.6233e-02,  1.2840e-02, -3.5475e-03,\n",
            "        -2.3716e-02, -4.1507e-03,  2.6226e-02, -1.4810e-03, -2.7310e-03,\n",
            "        -3.4106e-03,  9.5000e-03, -2.6233e-02, -2.5568e-02,  1.3908e-02,\n",
            "         1.6960e-03,  2.6051e-02, -1.7199e-02, -2.0663e-02, -2.8043e-03,\n",
            "        -1.6056e-02,  2.7079e-03, -5.1305e-03,  2.0653e-02, -5.5311e-03,\n",
            "         2.8936e-02, -1.9752e-02, -2.8029e-02, -6.6974e-03, -1.2378e-02,\n",
            "         2.2988e-02,  1.0470e-02,  4.6608e-03, -2.4254e-02, -1.5522e-02,\n",
            "         1.6290e-02,  4.7425e-03, -2.2667e-02, -6.9683e-03,  1.0460e-02,\n",
            "        -2.6868e-02, -8.3359e-03, -1.8986e-02, -2.1593e-03, -2.5949e-02,\n",
            "         1.6023e-02, -1.8737e-02,  6.3369e-03, -3.1502e-03,  1.3424e-02,\n",
            "        -3.0676e-03,  1.1194e-02,  2.6185e-02,  2.4180e-02,  1.0955e-02,\n",
            "        -1.8726e-02,  1.2616e-02, -2.1957e-02,  1.9268e-02, -7.3807e-03,\n",
            "        -2.5522e-02,  2.2265e-02,  2.4435e-02,  1.9943e-02, -1.6694e-02,\n",
            "        -2.1632e-02, -2.2859e-02, -2.8679e-02, -1.0895e-02, -1.2611e-02,\n",
            "         2.6569e-02,  2.1444e-02, -1.6572e-02,  9.9918e-03, -1.8211e-02,\n",
            "         1.4732e-02, -2.2187e-02,  3.5741e-04,  3.9268e-05,  1.3176e-02,\n",
            "        -1.8833e-03,  1.3758e-03, -1.2476e-02,  1.4770e-02,  1.3038e-02,\n",
            "         2.7060e-02,  2.4935e-02,  2.6990e-02, -7.1388e-03,  1.6644e-02,\n",
            "         1.5669e-02,  7.2896e-03,  1.1113e-02, -2.0120e-02, -1.8628e-02,\n",
            "         1.0381e-02, -2.6620e-02,  1.6558e-02, -2.4139e-02, -3.4008e-03,\n",
            "         2.2383e-02,  2.9172e-02,  2.5343e-02, -1.0127e-02, -2.8586e-03,\n",
            "         1.3717e-02, -2.8094e-02, -2.8523e-02,  1.0157e-03, -1.7033e-02,\n",
            "         9.7381e-03, -2.4449e-02,  1.2034e-02, -2.0181e-02, -1.4310e-02,\n",
            "        -1.0207e-02,  1.3805e-04,  1.3874e-02,  2.3866e-02, -2.6692e-02,\n",
            "         4.9770e-03,  1.4112e-02,  5.6918e-03,  2.3491e-02, -9.7745e-03,\n",
            "         2.0557e-02, -5.3739e-03, -9.5139e-03], device='cuda:0')), ('inception_block_7.b3.7.weight', tensor([1.0059, 0.9922, 1.0074, 1.0013, 0.9990, 1.0064, 1.0053, 0.9944, 1.0052,\n",
            "        0.9958, 1.0012, 1.0135, 1.0033, 1.0053, 1.0160, 1.0001, 1.0085, 1.0073,\n",
            "        1.0006, 1.0000, 1.0004, 0.9959, 0.9957, 0.9985, 1.0028, 1.0000, 1.0116,\n",
            "        1.0031, 0.9960, 1.0057, 1.0095, 1.0032, 0.9985, 0.9942, 1.0022, 1.0057,\n",
            "        1.0026, 1.0021, 0.9951, 1.0036, 0.9966, 1.0000, 1.0037, 0.9958, 0.9980,\n",
            "        0.9975, 0.9932, 1.0052, 0.9967, 0.9963, 1.0024, 1.0075, 0.9864, 1.0063,\n",
            "        0.9974, 0.9924, 0.9938, 0.9893, 1.0100, 1.0005, 0.9933, 0.9953, 0.9994,\n",
            "        1.0048, 1.0024, 1.0070, 1.0028, 1.0009, 1.0018, 1.0048, 0.9939, 1.0088,\n",
            "        0.9964, 0.9904, 0.9992, 0.9989, 0.9947, 1.0026, 0.9973, 0.9958, 0.9944,\n",
            "        1.0070, 0.9970, 1.0037, 1.0129, 0.9973, 0.9993, 1.0150, 1.0188, 0.9991,\n",
            "        0.9899, 0.9956, 1.0020, 1.0020, 0.9982, 0.9981, 0.9937, 0.9949, 1.0065,\n",
            "        1.0033, 0.9998, 0.9988, 1.0008, 0.9969, 0.9930, 1.0085, 1.0071, 0.9958,\n",
            "        1.0005, 0.9911, 0.9918, 0.9985, 0.9952, 1.0032, 0.9966, 0.9957, 0.9938,\n",
            "        1.0109, 0.9993, 0.9987, 1.0053, 1.0112, 1.0017, 1.0069, 0.9942, 1.0027,\n",
            "        1.0074, 0.9973], device='cuda:0')), ('inception_block_7.b3.7.bias', tensor([-9.8876e-03,  3.8645e-03, -7.2895e-05, -1.1714e-03, -2.1856e-03,\n",
            "        -2.6204e-03,  3.8776e-04, -6.3915e-03, -1.4654e-02, -1.8716e-02,\n",
            "        -6.7537e-03, -3.9076e-03, -9.0659e-03, -1.0684e-02, -5.3755e-03,\n",
            "        -8.7440e-03, -2.6913e-03, -1.7931e-02, -4.4064e-03,  3.7966e-03,\n",
            "        -1.0932e-03, -3.6705e-04, -9.7741e-03, -1.4527e-02, -4.7553e-03,\n",
            "        -1.2150e-03, -2.3185e-02, -6.9397e-03, -9.6314e-03, -1.2749e-02,\n",
            "        -9.3498e-03, -1.7233e-02, -1.2453e-02, -1.1704e-02, -1.0679e-02,\n",
            "        -1.5739e-02,  4.1186e-03, -9.0553e-03,  1.2522e-03,  2.3302e-03,\n",
            "        -1.1454e-03, -1.6298e-02, -2.2128e-02, -5.8382e-03,  9.0038e-03,\n",
            "        -1.0297e-02, -1.6749e-02, -1.5635e-02, -1.6996e-02, -1.4475e-02,\n",
            "        -5.2685e-03, -1.1412e-02, -3.7978e-03, -7.1349e-03, -4.0571e-04,\n",
            "        -1.9362e-02, -3.7383e-03, -1.4853e-02, -9.7038e-04, -9.2047e-03,\n",
            "        -1.7218e-02, -9.2003e-04, -4.1578e-03, -1.1334e-02, -1.7070e-02,\n",
            "         4.2923e-03,  4.0941e-03,  3.5718e-03, -1.6412e-02,  5.3493e-04,\n",
            "        -1.7021e-02, -8.6783e-03, -1.0996e-02, -3.9712e-03, -2.3219e-03,\n",
            "        -1.1780e-02, -1.2271e-02, -1.1745e-02, -6.2738e-03, -1.0556e-02,\n",
            "        -1.3660e-02, -1.6159e-02, -1.3229e-03,  5.9979e-03, -1.1968e-02,\n",
            "         1.2825e-03, -3.0065e-03, -4.5789e-03, -4.4760e-03, -6.6128e-03,\n",
            "        -1.3848e-02,  1.4532e-03, -5.6764e-03, -9.3364e-03, -2.7516e-03,\n",
            "        -4.4069e-03, -5.2361e-03, -4.8934e-04, -5.5864e-03, -2.2449e-03,\n",
            "        -1.0396e-02,  1.1017e-03, -6.7296e-03, -7.5379e-03, -6.4402e-03,\n",
            "         3.3901e-03,  5.3705e-03, -3.9561e-03,  7.0671e-04, -4.6096e-03,\n",
            "        -7.2974e-03, -2.4356e-02, -1.5496e-02, -2.0206e-02, -1.0542e-03,\n",
            "         1.4471e-02, -4.3299e-03, -2.0778e-02,  1.8604e-04,  5.8999e-03,\n",
            "        -6.7468e-03, -1.1722e-02, -1.2483e-02,  2.4988e-03, -1.5309e-02,\n",
            "        -1.6966e-02, -9.8714e-03, -2.5648e-03], device='cuda:0')), ('inception_block_7.b3.7.running_mean', tensor([-4.0955e-01, -5.2181e-02,  1.0319e-02, -3.0871e-01, -7.6605e-02,\n",
            "        -2.7924e-01, -6.6944e-01, -3.4778e-01,  1.4345e-02,  2.3728e-01,\n",
            "        -4.3431e-01,  4.1424e-01, -1.9516e-01,  7.0954e-01, -6.8650e-01,\n",
            "        -2.2132e-01,  3.4240e-01,  2.0602e-01,  3.1620e-01, -3.5720e-01,\n",
            "        -1.1808e-03,  9.9216e-01, -1.0002e+00, -1.4538e-01,  6.6810e-01,\n",
            "        -1.0653e-01,  6.8202e-01, -7.5259e-01,  2.7493e-01, -2.0375e-01,\n",
            "        -2.2489e-01, -3.1849e-01,  1.8413e-01, -3.1459e-01, -3.6208e-01,\n",
            "        -6.5449e-01, -2.8011e-01, -8.1984e-01,  4.6128e-01,  1.9971e-01,\n",
            "        -5.1868e-01, -5.4329e-01, -1.6944e-02, -1.0125e+00, -6.0229e-01,\n",
            "        -1.0415e-01, -6.3309e-01, -2.6944e-01,  2.8367e-01,  1.4696e-01,\n",
            "        -2.9638e-01,  7.3006e-01, -9.1746e-01, -4.1457e-01, -1.3561e-01,\n",
            "         1.8020e-01, -3.0441e-01, -5.0398e-01, -2.0719e-01,  3.5340e-02,\n",
            "         7.4720e-01,  2.8703e-01,  4.7579e-01,  4.5728e-01, -3.5833e-02,\n",
            "        -4.3049e-01, -4.8453e-01, -1.4021e-01,  6.2840e-02,  1.6322e-02,\n",
            "         1.8593e-01,  1.0380e-01,  6.0994e-02, -4.0834e-01, -3.6032e-01,\n",
            "         3.6964e-02, -3.8794e-01, -3.6952e-04, -1.0931e+00,  2.2654e-01,\n",
            "         3.1088e-01, -3.8257e-01, -2.0688e-01, -1.9943e-01, -2.5196e-01,\n",
            "         2.9369e-01, -1.2189e-01, -1.1338e-01,  2.8173e-02,  6.0912e-01,\n",
            "        -5.7809e-01, -9.1581e-02, -8.0587e-01, -3.1976e-01, -4.2262e-01,\n",
            "         2.8497e-01, -2.6333e-01, -7.2945e-01, -8.2449e-02, -3.7584e-01,\n",
            "        -3.2734e-01, -4.9087e-01, -9.6005e-02, -3.6453e-01,  1.1585e+00,\n",
            "        -6.1346e-01, -3.5672e-01, -2.1185e-02, -3.8362e-01, -3.2612e-01,\n",
            "        -8.1720e-01, -7.2140e-01,  8.5805e-01,  2.2458e-01, -7.9095e-01,\n",
            "        -7.0497e-01, -3.6280e-01,  5.4891e-01, -1.1062e-01, -1.0257e-01,\n",
            "        -1.8610e-01,  3.0942e-02, -4.0936e-01, -4.7544e-01,  1.4330e-01,\n",
            "         6.7542e-02, -5.7698e-03,  2.3581e-01], device='cuda:0')), ('inception_block_7.b3.7.running_var', tensor([0.3642, 0.2938, 0.2796, 0.2833, 0.3672, 0.2820, 0.2573, 0.3193, 0.3180,\n",
            "        0.4025, 0.2970, 0.3488, 0.2923, 0.3770, 0.3111, 0.2714, 0.3189, 0.4463,\n",
            "        0.3092, 0.2667, 0.1973, 0.4265, 0.3491, 0.2968, 0.3215, 0.3542, 0.2858,\n",
            "        0.2791, 0.3049, 0.2446, 0.2111, 0.2562, 0.2120, 0.4500, 0.2518, 0.4838,\n",
            "        0.4247, 0.3317, 0.4932, 0.2483, 0.3055, 0.3713, 0.2545, 0.5641, 0.2941,\n",
            "        0.3007, 0.3883, 0.3000, 0.2653, 0.2901, 0.3524, 0.4253, 0.2771, 0.2821,\n",
            "        0.2361, 0.3223, 0.2174, 0.4050, 0.2986, 0.2958, 0.3480, 0.3830, 0.4027,\n",
            "        0.2527, 0.2577, 0.2943, 0.2928, 0.3117, 0.2661, 0.3189, 0.2651, 0.2997,\n",
            "        0.3415, 0.3492, 0.3735, 0.3111, 0.2893, 0.2207, 0.3458, 0.2913, 0.2949,\n",
            "        0.3296, 0.4134, 0.2136, 0.2691, 0.2794, 0.3122, 0.2488, 0.2973, 0.2660,\n",
            "        0.3966, 0.2678, 0.3139, 0.3803, 0.2633, 0.4309, 0.3958, 0.5570, 0.2929,\n",
            "        0.3678, 0.3215, 0.2162, 0.2522, 0.3672, 0.4549, 0.3383, 0.3110, 0.1961,\n",
            "        0.3511, 0.2409, 0.3342, 0.2871, 0.3162, 0.3493, 0.3182, 0.4937, 0.3054,\n",
            "        0.2258, 0.2444, 0.2266, 0.2714, 0.3314, 0.3489, 0.2934, 0.3732, 0.4462,\n",
            "        0.2234, 0.3650], device='cuda:0')), ('inception_block_7.b3.7.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_7.b4.1.weight', tensor([[[[ 0.0150]],\n",
            "\n",
            "         [[ 0.0285]],\n",
            "\n",
            "         [[-0.0195]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0190]],\n",
            "\n",
            "         [[-0.0187]],\n",
            "\n",
            "         [[-0.0006]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0219]],\n",
            "\n",
            "         [[-0.0190]],\n",
            "\n",
            "         [[-0.0225]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0491]],\n",
            "\n",
            "         [[ 0.0128]],\n",
            "\n",
            "         [[ 0.0254]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0100]],\n",
            "\n",
            "         [[-0.0068]],\n",
            "\n",
            "         [[-0.0104]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0014]],\n",
            "\n",
            "         [[ 0.0429]],\n",
            "\n",
            "         [[ 0.0126]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0207]],\n",
            "\n",
            "         [[ 0.0327]],\n",
            "\n",
            "         [[ 0.0206]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0293]],\n",
            "\n",
            "         [[ 0.0189]],\n",
            "\n",
            "         [[ 0.0143]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0113]],\n",
            "\n",
            "         [[-0.0348]],\n",
            "\n",
            "         [[ 0.0443]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0156]],\n",
            "\n",
            "         [[-0.0242]],\n",
            "\n",
            "         [[-0.0172]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0165]],\n",
            "\n",
            "         [[ 0.0055]],\n",
            "\n",
            "         [[-0.0102]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0246]],\n",
            "\n",
            "         [[-0.0436]],\n",
            "\n",
            "         [[-0.0164]]]], device='cuda:0')), ('inception_block_7.b4.1.bias', tensor([-0.0098, -0.0043, -0.0128,  0.0096,  0.0038,  0.0389,  0.0309,  0.0146,\n",
            "         0.0071,  0.0361, -0.0171,  0.0187, -0.0024,  0.0070, -0.0223,  0.0157,\n",
            "        -0.0025, -0.0059, -0.0370, -0.0259, -0.0065, -0.0331,  0.0408,  0.0042,\n",
            "        -0.0074,  0.0369, -0.0316, -0.0068,  0.0376,  0.0221,  0.0022,  0.0066,\n",
            "        -0.0367,  0.0190,  0.0084, -0.0088, -0.0083, -0.0170,  0.0314, -0.0099,\n",
            "         0.0236,  0.0221, -0.0290, -0.0135, -0.0339,  0.0275,  0.0254,  0.0390,\n",
            "         0.0385, -0.0365, -0.0349, -0.0183, -0.0020,  0.0025,  0.0391, -0.0338,\n",
            "         0.0064,  0.0238, -0.0289, -0.0210,  0.0001, -0.0236,  0.0388,  0.0052,\n",
            "         0.0077, -0.0244, -0.0318, -0.0240, -0.0133, -0.0050,  0.0352, -0.0118,\n",
            "        -0.0292,  0.0341, -0.0003, -0.0211,  0.0073,  0.0188, -0.0081,  0.0374,\n",
            "         0.0387,  0.0077,  0.0167, -0.0197, -0.0053,  0.0140,  0.0090,  0.0013,\n",
            "        -0.0091,  0.0143,  0.0188,  0.0251, -0.0204, -0.0038, -0.0264,  0.0037,\n",
            "        -0.0080,  0.0095, -0.0425,  0.0434, -0.0248, -0.0112,  0.0212, -0.0320,\n",
            "        -0.0253,  0.0322, -0.0392,  0.0340,  0.0299, -0.0112, -0.0004,  0.0393,\n",
            "         0.0142, -0.0280, -0.0317,  0.0143, -0.0008, -0.0296,  0.0318, -0.0113,\n",
            "         0.0373, -0.0103, -0.0371, -0.0276,  0.0099,  0.0147,  0.0291, -0.0019],\n",
            "       device='cuda:0')), ('inception_block_7.b4.2.weight', tensor([1.0015, 0.9924, 0.9947, 1.0005, 1.0013, 1.0083, 1.0073, 1.0031, 1.0019,\n",
            "        1.0010, 0.9958, 1.0082, 1.0024, 1.0064, 0.9904, 0.9929, 1.0002, 1.0038,\n",
            "        0.9989, 0.9948, 0.9891, 1.0017, 1.0005, 0.9953, 1.0022, 1.0050, 1.0111,\n",
            "        1.0037, 0.9952, 1.0058, 0.9979, 0.9990, 0.9954, 1.0070, 1.0066, 0.9979,\n",
            "        1.0124, 1.0102, 0.9996, 0.9860, 0.9977, 1.0115, 0.9994, 1.0066, 1.0086,\n",
            "        1.0122, 1.0004, 0.9993, 0.9956, 1.0096, 1.0011, 1.0041, 1.0081, 1.0013,\n",
            "        1.0003, 1.0019, 0.9983, 1.0051, 1.0049, 0.9902, 1.0062, 0.9907, 0.9952,\n",
            "        0.9900, 0.9958, 0.9920, 1.0055, 0.9929, 0.9985, 1.0020, 1.0044, 1.0047,\n",
            "        0.9850, 1.0014, 0.9960, 1.0115, 0.9982, 1.0005, 1.0033, 1.0091, 1.0033,\n",
            "        1.0049, 1.0037, 0.9931, 0.9956, 1.0045, 1.0020, 0.9929, 0.9907, 0.9970,\n",
            "        0.9968, 1.0035, 0.9962, 1.0136, 0.9938, 1.0037, 1.0142, 1.0026, 1.0048,\n",
            "        0.9969, 0.9952, 1.0076, 1.0013, 0.9995, 1.0035, 0.9892, 0.9970, 1.0008,\n",
            "        1.0064, 1.0037, 1.0073, 0.9935, 0.9835, 0.9940, 1.0082, 1.0004, 0.9972,\n",
            "        1.0054, 1.0116, 1.0011, 0.9970, 0.9907, 0.9978, 0.9982, 0.9955, 1.0059,\n",
            "        0.9988, 1.0003], device='cuda:0')), ('inception_block_7.b4.2.bias', tensor([-0.0122, -0.0043, -0.0088, -0.0032, -0.0147,  0.0028, -0.0084, -0.0112,\n",
            "         0.0106, -0.0058, -0.0170, -0.0041, -0.0039, -0.0113, -0.0066, -0.0109,\n",
            "        -0.0044, -0.0075,  0.0068, -0.0119, -0.0112, -0.0127,  0.0002, -0.0187,\n",
            "        -0.0095,  0.0025, -0.0020, -0.0172, -0.0055, -0.0035,  0.0025, -0.0069,\n",
            "        -0.0051, -0.0009, -0.0185,  0.0055,  0.0083,  0.0008, -0.0114, -0.0097,\n",
            "        -0.0007, -0.0103, -0.0068, -0.0053,  0.0046,  0.0031, -0.0123, -0.0045,\n",
            "         0.0017, -0.0118, -0.0034,  0.0054, -0.0044, -0.0097, -0.0112, -0.0149,\n",
            "         0.0039, -0.0016, -0.0165, -0.0109, -0.0035, -0.0121, -0.0011, -0.0110,\n",
            "        -0.0057,  0.0030, -0.0078, -0.0116, -0.0126, -0.0069,  0.0012, -0.0100,\n",
            "        -0.0222,  0.0002, -0.0043, -0.0121, -0.0056,  0.0015, -0.0126, -0.0226,\n",
            "        -0.0048, -0.0045,  0.0135, -0.0029, -0.0178, -0.0061, -0.0031, -0.0118,\n",
            "        -0.0070,  0.0002, -0.0069, -0.0110,  0.0002, -0.0062, -0.0053, -0.0066,\n",
            "        -0.0036, -0.0034, -0.0095, -0.0171, -0.0118, -0.0047, -0.0128, -0.0148,\n",
            "        -0.0105, -0.0037, -0.0103, -0.0051, -0.0140, -0.0058, -0.0035, -0.0079,\n",
            "        -0.0162, -0.0204,  0.0024, -0.0071, -0.0094, -0.0108, -0.0047, -0.0205,\n",
            "        -0.0103, -0.0130,  0.0053, -0.0060,  0.0028, -0.0050, -0.0058, -0.0080],\n",
            "       device='cuda:0')), ('inception_block_7.b4.2.running_mean', tensor([ 1.7164, -0.3058, -0.5699,  0.2613,  0.7862, -0.2472,  0.5856,  0.0450,\n",
            "        -0.4840,  0.8571,  0.3245,  0.1799, -0.3206,  1.2286, -0.7194,  0.6713,\n",
            "        -0.1557,  0.6896,  0.6276,  0.0505,  1.6482,  1.4278, -0.1327,  0.5481,\n",
            "         0.3679, -1.8012,  0.5750, -0.8513,  0.0370,  0.3209, -0.5668,  0.5551,\n",
            "         0.6316, -1.1682,  0.6448,  0.3651,  0.5841,  1.4153,  0.6395, -0.0593,\n",
            "        -0.0778,  0.1852,  1.4118,  0.5240, -0.4889,  0.0401,  1.1210,  0.5250,\n",
            "         0.0411,  0.7778,  1.8116,  0.6795,  1.1763, -1.6247,  0.0851,  0.0991,\n",
            "        -0.3148, -0.1347,  0.1791,  1.2647, -0.0690,  0.6690,  0.8647, -0.6307,\n",
            "         1.0630,  0.8561,  1.2073,  0.3300,  0.4163,  1.6245,  1.1455,  1.2278,\n",
            "        -1.1796, -0.7547,  0.6665,  0.6086,  0.1561,  0.4349, -0.8574,  0.9770,\n",
            "        -0.4146,  0.3775, -0.0918, -1.8138,  0.3011,  1.2072,  0.1453,  1.6001,\n",
            "         1.5781, -1.5429,  0.3482,  1.1884, -0.3399,  0.1591,  1.3689, -1.0096,\n",
            "        -0.5643,  1.4089,  1.0930, -1.4284, -0.2266,  0.0841, -0.5090,  0.8618,\n",
            "         0.0078, -0.6890,  0.0102,  0.7729,  0.7206,  1.0430,  1.7467, -0.1917,\n",
            "        -0.9907,  0.4329,  0.4857,  1.0545, -0.0603,  0.3878,  1.1509, -0.0472,\n",
            "         1.0463, -0.0469,  0.0660, -0.2514, -1.1274,  0.7866,  0.0211, -0.1337],\n",
            "       device='cuda:0')), ('inception_block_7.b4.2.running_var', tensor([0.5487, 0.4376, 0.3268, 0.3345, 0.3517, 0.3120, 0.2460, 0.6058, 0.5501,\n",
            "        0.4476, 0.4619, 0.3068, 0.3383, 0.4057, 0.5490, 0.3881, 0.2850, 0.3079,\n",
            "        0.3618, 0.3555, 0.2851, 0.4581, 0.3574, 0.4003, 0.3106, 0.8853, 0.2885,\n",
            "        0.2875, 0.3044, 0.2233, 0.3426, 0.5105, 0.4086, 0.3444, 0.4120, 0.4356,\n",
            "        0.3250, 0.2599, 0.3491, 0.3459, 0.3298, 0.4505, 0.5016, 0.4190, 0.2733,\n",
            "        0.3840, 0.2625, 0.3286, 0.2780, 0.4753, 0.3699, 0.2795, 0.6465, 0.3594,\n",
            "        0.3066, 0.3432, 0.3693, 0.3617, 0.3592, 0.4411, 0.4016, 0.4018, 0.2303,\n",
            "        0.2367, 0.3604, 0.4503, 0.3803, 0.3159, 0.5625, 0.4107, 0.3442, 0.6200,\n",
            "        0.8039, 0.4226, 0.5442, 0.3705, 0.5622, 0.2337, 0.2398, 0.3836, 0.2631,\n",
            "        0.3078, 0.3783, 0.4769, 0.3039, 0.3134, 0.2497, 0.4743, 0.5875, 0.4090,\n",
            "        0.3422, 0.5160, 0.3829, 0.2952, 0.3017, 0.6804, 0.4394, 0.7329, 0.4903,\n",
            "        0.4639, 0.2976, 0.3431, 0.2609, 0.3649, 0.3950, 0.2656, 0.2964, 0.2966,\n",
            "        0.5935, 0.4106, 0.5344, 0.3766, 0.6008, 0.4142, 0.4594, 0.3052, 0.3724,\n",
            "        0.3173, 0.4252, 0.5509, 0.4227, 0.4263, 0.2948, 0.2689, 0.5042, 0.2973,\n",
            "        0.2494, 0.3129], device='cuda:0')), ('inception_block_7.b4.2.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_8.b1.0.weight', tensor([[[[-0.0069]],\n",
            "\n",
            "         [[ 0.0002]],\n",
            "\n",
            "         [[ 0.0011]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0345]],\n",
            "\n",
            "         [[ 0.0354]],\n",
            "\n",
            "         [[ 0.0205]]],\n",
            "\n",
            "\n",
            "        [[[-0.0037]],\n",
            "\n",
            "         [[ 0.0026]],\n",
            "\n",
            "         [[ 0.0023]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0403]],\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[ 0.0305]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0252]],\n",
            "\n",
            "         [[ 0.0276]],\n",
            "\n",
            "         [[ 0.0256]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0371]],\n",
            "\n",
            "         [[-0.0189]],\n",
            "\n",
            "         [[-0.0146]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0147]],\n",
            "\n",
            "         [[-0.0104]],\n",
            "\n",
            "         [[ 0.0054]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0121]],\n",
            "\n",
            "         [[-0.0127]],\n",
            "\n",
            "         [[-0.0097]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004]],\n",
            "\n",
            "         [[-0.0063]],\n",
            "\n",
            "         [[ 0.0157]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0305]],\n",
            "\n",
            "         [[ 0.0062]],\n",
            "\n",
            "         [[ 0.0019]]],\n",
            "\n",
            "\n",
            "        [[[-0.0358]],\n",
            "\n",
            "         [[ 0.0109]],\n",
            "\n",
            "         [[-0.0304]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0101]],\n",
            "\n",
            "         [[-0.0055]],\n",
            "\n",
            "         [[ 0.0402]]]], device='cuda:0')), ('inception_block_8.b1.0.bias', tensor([ 0.0099, -0.0186, -0.0074,  0.0192, -0.0272,  0.0076,  0.0320,  0.0268,\n",
            "         0.0092,  0.0040,  0.0014, -0.0336,  0.0270, -0.0326,  0.0281, -0.0188,\n",
            "        -0.0266,  0.0178, -0.0048, -0.0115,  0.0184,  0.0253, -0.0144, -0.0183,\n",
            "         0.0253, -0.0043,  0.0221, -0.0074,  0.0082,  0.0034, -0.0303,  0.0198,\n",
            "        -0.0239, -0.0274, -0.0045,  0.0278,  0.0028, -0.0243,  0.0215,  0.0218,\n",
            "         0.0129, -0.0096, -0.0333, -0.0009, -0.0139,  0.0100,  0.0135, -0.0152,\n",
            "        -0.0129, -0.0305,  0.0030,  0.0149,  0.0344, -0.0130, -0.0169, -0.0219,\n",
            "         0.0194, -0.0185,  0.0202,  0.0279,  0.0091, -0.0250,  0.0283, -0.0084,\n",
            "         0.0331, -0.0260, -0.0011, -0.0064, -0.0231, -0.0113,  0.0238,  0.0071,\n",
            "         0.0042,  0.0042, -0.0217,  0.0128, -0.0141, -0.0297, -0.0272,  0.0096,\n",
            "        -0.0246, -0.0331, -0.0221,  0.0245,  0.0290,  0.0015, -0.0298, -0.0199,\n",
            "        -0.0187, -0.0301,  0.0047, -0.0289, -0.0045, -0.0108, -0.0071, -0.0069,\n",
            "         0.0236,  0.0114, -0.0137, -0.0065, -0.0062, -0.0144,  0.0314,  0.0040,\n",
            "         0.0150, -0.0217, -0.0086, -0.0240,  0.0198,  0.0251,  0.0226, -0.0055,\n",
            "        -0.0047,  0.0334, -0.0255, -0.0296, -0.0129,  0.0236, -0.0240, -0.0053,\n",
            "         0.0176, -0.0132, -0.0160, -0.0086,  0.0055, -0.0086,  0.0016,  0.0175,\n",
            "         0.0276, -0.0038, -0.0145,  0.0064,  0.0077,  0.0213, -0.0133,  0.0194,\n",
            "         0.0250, -0.0196, -0.0036, -0.0244,  0.0306,  0.0198,  0.0297, -0.0168,\n",
            "         0.0269, -0.0289,  0.0079,  0.0139,  0.0245,  0.0176,  0.0340, -0.0251,\n",
            "         0.0186,  0.0140, -0.0343,  0.0251, -0.0110,  0.0027, -0.0121,  0.0133,\n",
            "        -0.0193,  0.0220, -0.0173, -0.0139,  0.0232,  0.0262, -0.0235,  0.0135,\n",
            "        -0.0132,  0.0106,  0.0184, -0.0246,  0.0017, -0.0302,  0.0327,  0.0053,\n",
            "         0.0116, -0.0255, -0.0302, -0.0022,  0.0184, -0.0183,  0.0287, -0.0220,\n",
            "         0.0213, -0.0261, -0.0342, -0.0083, -0.0080,  0.0160, -0.0114, -0.0337,\n",
            "        -0.0246,  0.0124,  0.0193, -0.0219, -0.0318,  0.0206,  0.0151, -0.0105,\n",
            "         0.0246,  0.0297,  0.0277, -0.0115, -0.0027, -0.0338,  0.0208,  0.0093,\n",
            "         0.0288,  0.0024, -0.0327,  0.0151, -0.0198, -0.0196,  0.0267, -0.0255,\n",
            "        -0.0032,  0.0076, -0.0119,  0.0026, -0.0130,  0.0319, -0.0021,  0.0059,\n",
            "         0.0068, -0.0254, -0.0314, -0.0038,  0.0216,  0.0331, -0.0121,  0.0345,\n",
            "        -0.0008, -0.0031, -0.0140,  0.0252,  0.0341, -0.0156,  0.0072, -0.0056,\n",
            "         0.0023,  0.0189,  0.0152,  0.0063,  0.0010, -0.0204, -0.0015,  0.0284,\n",
            "         0.0246, -0.0099,  0.0203, -0.0082, -0.0067, -0.0046,  0.0330, -0.0112],\n",
            "       device='cuda:0')), ('inception_block_8.b1.1.weight', tensor([0.9855, 0.9914, 0.9686, 0.9815, 0.9933, 0.9929, 0.9847, 0.9819, 0.9742,\n",
            "        0.9953, 0.9889, 0.9846, 0.9870, 0.9809, 0.9822, 0.9942, 0.9876, 0.9792,\n",
            "        0.9826, 0.9852, 0.9787, 0.9730, 1.0021, 0.9863, 0.9846, 0.9876, 0.9911,\n",
            "        0.9960, 0.9909, 0.9859, 0.9852, 0.9712, 0.9769, 0.9908, 0.9844, 0.9845,\n",
            "        0.9807, 0.9936, 0.9906, 0.9783, 0.9841, 0.9985, 0.9766, 0.9874, 0.9802,\n",
            "        0.9837, 0.9905, 0.9885, 0.9890, 0.9847, 0.9888, 0.9815, 0.9868, 0.9815,\n",
            "        0.9740, 0.9830, 0.9784, 0.9764, 0.9808, 0.9846, 0.9928, 0.9774, 0.9885,\n",
            "        0.9912, 0.9832, 0.9804, 0.9903, 0.9852, 0.9808, 0.9797, 0.9902, 0.9819,\n",
            "        0.9826, 0.9857, 0.9894, 0.9887, 0.9851, 0.9813, 0.9897, 0.9972, 0.9925,\n",
            "        0.9887, 0.9869, 0.9732, 0.9719, 0.9782, 0.9937, 0.9853, 0.9748, 0.9789,\n",
            "        0.9795, 0.9984, 0.9872, 0.9902, 0.9819, 0.9827, 0.9889, 0.9889, 0.9795,\n",
            "        0.9909, 0.9784, 0.9944, 0.9813, 0.9921, 0.9909, 0.9820, 0.9873, 0.9816,\n",
            "        0.9876, 0.9874, 0.9655, 0.9817, 0.9833, 0.9680, 0.9901, 0.9764, 0.9981,\n",
            "        0.9950, 0.9848, 0.9887, 0.9914, 0.9784, 0.9925, 0.9914, 0.9863, 0.9789,\n",
            "        0.9759, 0.9933, 0.9884, 0.9851, 0.9887, 0.9696, 0.9824, 0.9929, 0.9758,\n",
            "        0.9749, 0.9849, 0.9852, 0.9836, 0.9887, 0.9824, 0.9812, 0.9837, 0.9898,\n",
            "        0.9824, 0.9846, 0.9786, 0.9725, 0.9790, 0.9897, 0.9838, 0.9844, 0.9856,\n",
            "        0.9895, 0.9922, 0.9939, 0.9828, 0.9657, 0.9851, 0.9903, 0.9863, 0.9920,\n",
            "        0.9791, 0.9848, 0.9871, 0.9777, 1.0000, 0.9917, 0.9891, 0.9844, 0.9859,\n",
            "        0.9759, 0.9775, 0.9833, 0.9888, 0.9835, 0.9738, 0.9811, 0.9708, 0.9899,\n",
            "        0.9870, 0.9806, 0.9880, 0.9944, 0.9894, 0.9884, 0.9871, 0.9769, 0.9796,\n",
            "        0.9860, 0.9964, 0.9926, 0.9956, 0.9789, 0.9783, 0.9856, 0.9838, 0.9820,\n",
            "        0.9886, 0.9813, 0.9963, 0.9921, 0.9993, 0.9879, 0.9915, 0.9907, 0.9877,\n",
            "        0.9885, 0.9865, 0.9898, 0.9901, 0.9910, 0.9838, 1.0006, 0.9926, 0.9821,\n",
            "        0.9901, 0.9860, 0.9945, 0.9897, 0.9843, 0.9822, 0.9830, 0.9805, 1.0011,\n",
            "        0.9838, 0.9836, 0.9782, 0.9940, 0.9951, 0.9772, 0.9849, 0.9883, 0.9859,\n",
            "        0.9794, 0.9774, 0.9975, 0.9866, 0.9837, 0.9819, 0.9811, 0.9860, 0.9773,\n",
            "        0.9763, 0.9767, 0.9762, 0.9945, 0.9780, 0.9838, 0.9959, 0.9739, 0.9875,\n",
            "        0.9846, 0.9997, 0.9820, 0.9847], device='cuda:0')), ('inception_block_8.b1.1.bias', tensor([-0.0219, -0.0083, -0.0174, -0.0183, -0.0087, -0.0104, -0.0122, -0.0170,\n",
            "        -0.0160, -0.0022, -0.0116, -0.0130, -0.0157, -0.0173, -0.0144, -0.0140,\n",
            "        -0.0157, -0.0192, -0.0154, -0.0149, -0.0201, -0.0206, -0.0075, -0.0115,\n",
            "        -0.0162, -0.0196, -0.0020, -0.0076, -0.0048, -0.0173, -0.0137, -0.0329,\n",
            "        -0.0179, -0.0239, -0.0209, -0.0107, -0.0259, -0.0013, -0.0079, -0.0117,\n",
            "        -0.0066,  0.0023, -0.0153, -0.0194, -0.0241, -0.0200, -0.0157, -0.0132,\n",
            "        -0.0132, -0.0071, -0.0132, -0.0100, -0.0144, -0.0185, -0.0269, -0.0164,\n",
            "        -0.0146, -0.0214, -0.0140, -0.0149, -0.0088, -0.0235, -0.0132, -0.0054,\n",
            "        -0.0113, -0.0174, -0.0091, -0.0231, -0.0133, -0.0231, -0.0093, -0.0177,\n",
            "        -0.0191, -0.0152, -0.0138, -0.0121, -0.0090, -0.0177, -0.0089, -0.0054,\n",
            "        -0.0031, -0.0220, -0.0028, -0.0234, -0.0175, -0.0139, -0.0043, -0.0081,\n",
            "        -0.0181, -0.0126, -0.0106, -0.0191, -0.0207, -0.0164, -0.0179, -0.0140,\n",
            "        -0.0111, -0.0122, -0.0185, -0.0054, -0.0121, -0.0093, -0.0124, -0.0230,\n",
            "        -0.0011, -0.0133, -0.0153, -0.0136, -0.0181, -0.0194, -0.0242, -0.0118,\n",
            "        -0.0088, -0.0234, -0.0060, -0.0239,  0.0027, -0.0125, -0.0147, -0.0107,\n",
            "        -0.0069, -0.0196, -0.0092, -0.0124, -0.0113, -0.0250, -0.0181, -0.0075,\n",
            "        -0.0182, -0.0126, -0.0134, -0.0233, -0.0165, -0.0083, -0.0309, -0.0176,\n",
            "        -0.0158, -0.0100, -0.0177, -0.0103, -0.0149, -0.0246, -0.0140, -0.0107,\n",
            "        -0.0259, -0.0159, -0.0114, -0.0137, -0.0174, -0.0134, -0.0252, -0.0172,\n",
            "        -0.0119, -0.0141, -0.0016, -0.0057, -0.0201, -0.0265, -0.0155, -0.0205,\n",
            "        -0.0164, -0.0064, -0.0189, -0.0144, -0.0142, -0.0117,  0.0026, -0.0058,\n",
            "        -0.0148, -0.0268, -0.0189, -0.0239, -0.0204, -0.0126, -0.0161, -0.0146,\n",
            "        -0.0198, -0.0233, -0.0222, -0.0147, -0.0091, -0.0244, -0.0114, -0.0070,\n",
            "        -0.0199, -0.0121, -0.0160, -0.0240, -0.0174, -0.0284,  0.0013, -0.0112,\n",
            "        -0.0047, -0.0208, -0.0257, -0.0210, -0.0235, -0.0257, -0.0129, -0.0163,\n",
            "        -0.0084, -0.0207,  0.0029, -0.0075, -0.0094, -0.0139, -0.0162, -0.0188,\n",
            "        -0.0085, -0.0037, -0.0172, -0.0192, -0.0158,  0.0014, -0.0050, -0.0207,\n",
            "        -0.0143, -0.0135, -0.0096, -0.0204, -0.0176, -0.0097, -0.0050, -0.0240,\n",
            "        -0.0059, -0.0221, -0.0121, -0.0206, -0.0081, -0.0106, -0.0203, -0.0130,\n",
            "        -0.0169, -0.0128, -0.0210, -0.0187, -0.0055, -0.0130, -0.0202, -0.0114,\n",
            "        -0.0219, -0.0068, -0.0151, -0.0280, -0.0191, -0.0205, -0.0050, -0.0208,\n",
            "        -0.0153, -0.0080, -0.0178, -0.0097, -0.0180, -0.0039, -0.0184, -0.0185],\n",
            "       device='cuda:0')), ('inception_block_8.b1.1.running_mean', tensor([ 1.2218, -0.5903, -0.8761, -1.6268,  0.0042,  0.8205, -0.5311, -0.3434,\n",
            "        -0.8700, -0.5129, -0.6968,  0.4908,  0.7058, -0.9122, -0.6499,  1.3024,\n",
            "        -1.4848,  0.7438,  0.4516,  1.0533,  1.0620, -1.2100, -1.4092,  0.3526,\n",
            "        -1.9693,  1.0359, -2.3126, -1.6497, -1.5784,  0.1564, -1.0731,  1.7418,\n",
            "         0.8562,  1.5639,  1.8716, -0.9385,  1.5162, -0.0212, -1.6413,  1.7447,\n",
            "        -0.3950, -1.5115,  0.4871,  0.3503, -0.5138,  0.2150, -1.5578,  0.2398,\n",
            "         0.5957, -2.5170, -1.4077, -1.5982, -1.1564,  0.5280,  2.0008, -1.7197,\n",
            "         0.6707,  0.3701,  1.7982,  0.6236, -0.8126, -0.5433,  0.0514, -0.6131,\n",
            "        -0.9528, -0.7155, -2.3512,  0.5127,  1.3701,  0.7899, -1.1779,  0.6603,\n",
            "         0.8450, -0.6848,  0.8692, -0.0896, -1.3464, -1.5215, -1.0028, -0.2786,\n",
            "        -2.7514,  0.3731, -2.1625,  0.2429,  1.7857,  0.6801, -0.7454, -0.7510,\n",
            "         1.8772,  2.6437, -1.2021,  0.9740,  0.5917, -0.5878,  0.7515,  1.3315,\n",
            "        -1.0738,  0.5784, -1.0666,  0.1350,  1.1811,  0.3647,  1.7123,  0.0605,\n",
            "        -1.0252, -0.0391,  2.3343, -0.6197, -0.6850, -0.6160,  0.6694, -2.1602,\n",
            "         1.0274,  1.7823, -0.5486, -1.4741, -0.6787, -0.0484,  1.3877,  0.4171,\n",
            "        -0.4795, -1.2054, -0.9628, -2.4106,  0.5236, -0.2942,  1.9822, -1.0379,\n",
            "        -1.1638,  0.4838,  0.0505, -0.5279, -0.3630, -0.1065,  1.5459, -0.7413,\n",
            "         0.7208,  1.4501, -0.3260, -0.4131, -0.2844,  1.9470, -1.3341, -0.7442,\n",
            "         1.7922, -0.2558,  1.1597,  1.6986, -0.9264, -0.0037,  1.0575,  0.3112,\n",
            "        -1.5355, -2.4014, -2.3999, -1.3748,  0.2684,  1.0758,  0.3204,  1.1971,\n",
            "        -0.9999, -2.2488,  1.4738, -0.4901,  0.3373,  0.6724, -2.3659, -0.8688,\n",
            "        -0.1123,  0.5325, -0.4829,  2.1697, -0.5186, -1.5925,  0.6271,  1.0953,\n",
            "         1.4118, -0.5215,  1.9282,  0.5586, -1.4635,  1.0943, -0.5011, -1.9910,\n",
            "         0.7803, -0.3542, -0.7011, -1.0489,  1.1057,  0.5535, -2.9118, -2.2685,\n",
            "        -2.2213,  2.3965,  0.5257, -0.0849,  0.7903, -0.9257, -0.5286, -1.5038,\n",
            "        -1.4598, -0.4764, -2.0210, -1.1479, -0.7044,  0.5485,  0.3630,  0.5650,\n",
            "         0.9051, -1.4227, -0.8915,  0.1382, -0.8060, -2.5155, -0.9159,  0.0610,\n",
            "         0.6182, -1.2961, -1.4322,  0.9636,  2.6729, -1.6560,  1.1778,  1.3015,\n",
            "        -0.3371,  0.4777, -1.2133, -2.2660, -0.1847, -0.3833, -0.4788, -1.1631,\n",
            "        -0.7177, -1.3783, -0.0672,  0.9309, -1.5083,  0.0443,  0.1238, -1.2074,\n",
            "         1.3323, -0.9702, -0.8209,  0.1350,  0.7524,  1.7335, -1.4741,  0.1639,\n",
            "        -1.3306,  1.0944, -0.7400,  0.5032, -0.5728, -1.1490, -0.8362,  0.4197],\n",
            "       device='cuda:0')), ('inception_block_8.b1.1.running_var', tensor([0.5502, 0.5265, 0.6177, 0.6789, 0.4856, 0.5219, 0.5176, 0.5050, 0.7900,\n",
            "        0.6157, 0.5560, 0.6935, 0.4168, 0.7080, 0.6357, 0.8687, 0.5623, 0.2889,\n",
            "        0.6157, 0.6694, 0.7306, 0.5758, 0.3104, 0.6853, 0.8985, 0.5018, 1.2928,\n",
            "        0.7188, 1.2402, 0.7961, 0.7102, 0.6062, 1.2444, 0.4857, 0.9230, 0.8214,\n",
            "        0.6508, 0.6017, 0.7659, 1.4260, 0.5824, 0.7271, 0.2979, 0.4164, 0.3578,\n",
            "        0.4693, 1.4646, 1.0666, 0.5653, 1.0705, 0.4743, 0.7815, 0.6227, 0.6375,\n",
            "        1.1447, 0.8896, 0.4585, 0.3562, 1.0188, 0.9179, 0.3778, 0.6178, 0.4966,\n",
            "        0.5316, 0.8912, 0.4645, 1.1427, 0.4154, 1.0547, 0.9040, 0.8479, 1.0749,\n",
            "        0.7516, 0.5903, 0.4926, 0.9788, 1.1018, 1.1833, 0.7605, 0.5877, 1.6550,\n",
            "        0.2895, 0.8309, 0.6747, 1.0204, 0.5292, 0.3708, 0.6067, 0.9878, 1.3568,\n",
            "        1.0302, 0.4923, 0.4278, 0.3392, 0.4018, 0.8006, 0.5331, 0.3466, 0.5345,\n",
            "        0.7522, 0.5053, 0.6952, 1.0171, 0.4902, 1.2038, 0.8182, 1.0249, 0.3744,\n",
            "        0.6573, 0.6013, 0.8154, 1.1977, 0.4942, 0.7885, 0.6301, 0.7221, 0.4616,\n",
            "        0.4379, 0.7259, 0.6336, 0.4502, 0.7699, 0.5239, 1.3029, 0.3563, 0.4031,\n",
            "        0.9869, 0.3808, 0.8275, 0.3273, 0.3283, 0.5790, 0.6173, 0.6759, 1.2151,\n",
            "        0.6318, 0.5530, 0.8201, 0.3935, 0.3883, 0.3071, 0.9512, 1.4089, 0.7071,\n",
            "        0.3606, 0.3581, 0.7623, 1.1182, 0.7972, 0.3916, 0.3414, 0.4270, 0.4807,\n",
            "        0.6284, 0.9162, 0.8199, 0.4178, 0.6269, 0.6474, 0.4565, 0.5980, 0.9465,\n",
            "        0.8840, 0.5307, 0.3758, 1.0408, 1.1742, 1.0348, 0.3879, 0.3120, 0.5726,\n",
            "        0.8874, 0.6475, 0.8100, 0.5484, 0.5511, 0.5440, 0.5542, 0.7763, 0.3950,\n",
            "        0.7588, 0.4832, 0.5380, 0.7270, 0.5229, 0.4151, 0.9185, 0.3876, 0.5484,\n",
            "        0.3347, 1.1396, 0.9805, 1.1069, 1.4285, 0.3386, 0.5416, 0.3736, 0.6364,\n",
            "        0.4411, 0.8629, 0.7009, 0.4014, 1.3362, 0.5519, 0.5804, 0.6373, 0.3776,\n",
            "        0.7027, 0.7562, 1.1368, 0.6480, 0.3381, 0.4371, 0.9178, 0.5056, 0.3896,\n",
            "        0.5544, 0.5334, 0.7031, 0.5719, 0.9853, 1.3593, 0.8983, 1.1073, 0.4707,\n",
            "        0.3722, 0.7594, 1.1709, 0.5336, 0.9082, 0.6218, 0.7466, 0.6274, 0.6084,\n",
            "        0.3764, 0.7033, 0.9080, 0.4057, 0.3366, 0.8614, 0.9729, 0.7274, 0.6659,\n",
            "        0.3593, 0.6690, 0.8473, 1.0245, 0.4230, 1.2803, 0.8160, 0.6982, 0.5908,\n",
            "        1.0975, 0.9925, 0.9649, 0.5000], device='cuda:0')), ('inception_block_8.b1.1.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_8.b2.0.weight', tensor([[[[ 3.1434e-02]],\n",
            "\n",
            "         [[-2.0306e-02]],\n",
            "\n",
            "         [[-1.1031e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.3883e-03]],\n",
            "\n",
            "         [[ 3.1653e-02]],\n",
            "\n",
            "         [[-3.9211e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2361e-03]],\n",
            "\n",
            "         [[-3.2501e-02]],\n",
            "\n",
            "         [[ 3.5987e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6530e-02]],\n",
            "\n",
            "         [[-1.3826e-02]],\n",
            "\n",
            "         [[-3.4445e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0957e-02]],\n",
            "\n",
            "         [[-2.7691e-02]],\n",
            "\n",
            "         [[-2.8360e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2660e-02]],\n",
            "\n",
            "         [[-2.4094e-02]],\n",
            "\n",
            "         [[ 4.0840e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.0501e-02]],\n",
            "\n",
            "         [[ 1.9427e-02]],\n",
            "\n",
            "         [[ 3.4801e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7776e-02]],\n",
            "\n",
            "         [[-4.2138e-05]],\n",
            "\n",
            "         [[ 2.4167e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.4648e-03]],\n",
            "\n",
            "         [[ 2.8412e-02]],\n",
            "\n",
            "         [[-1.8334e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.0636e-02]],\n",
            "\n",
            "         [[ 2.2576e-02]],\n",
            "\n",
            "         [[ 1.0203e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7950e-02]],\n",
            "\n",
            "         [[ 2.3090e-02]],\n",
            "\n",
            "         [[ 2.4217e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2591e-02]],\n",
            "\n",
            "         [[-2.4856e-02]],\n",
            "\n",
            "         [[-2.6866e-02]]]], device='cuda:0')), ('inception_block_8.b2.0.bias', tensor([-4.5880e-03,  2.3947e-02,  2.8218e-03, -1.9207e-02, -9.2709e-03,\n",
            "         2.1515e-02, -2.2411e-02, -2.8767e-02, -6.6692e-04, -1.3040e-02,\n",
            "        -2.3291e-03,  1.3276e-02,  2.8413e-02,  2.5593e-02,  1.7613e-02,\n",
            "         1.7634e-02, -2.7303e-02, -4.7064e-03, -1.3835e-02,  2.7509e-02,\n",
            "         1.5215e-02,  8.0749e-03, -1.1513e-02,  3.4521e-02, -1.3567e-02,\n",
            "         3.4090e-02, -4.1933e-03,  2.4792e-02, -1.4492e-02, -1.2781e-02,\n",
            "        -2.0802e-02,  2.2273e-02, -1.8779e-02,  6.9980e-03,  1.0934e-02,\n",
            "        -1.8820e-02,  1.4813e-02, -2.1466e-02,  1.7746e-02, -1.0963e-02,\n",
            "         3.3400e-02,  1.7536e-02, -7.2158e-03, -1.6954e-02,  5.5907e-04,\n",
            "         2.1984e-02,  9.8532e-04, -2.4552e-02,  2.2087e-02,  1.6082e-03,\n",
            "        -1.1052e-02, -3.1034e-02,  2.1370e-02, -2.5148e-02,  3.2301e-02,\n",
            "        -2.2513e-02, -2.4726e-02,  1.7873e-02, -2.6522e-02, -8.8459e-03,\n",
            "         2.2844e-02, -1.2773e-02,  6.3986e-03,  1.7259e-02, -1.6899e-02,\n",
            "         2.3177e-03,  9.5309e-03,  1.0752e-02,  1.4906e-02,  3.1666e-02,\n",
            "         1.9976e-03, -1.3127e-02,  3.3799e-02,  2.1514e-02, -5.9248e-03,\n",
            "         3.1466e-02, -2.5734e-02,  2.4385e-03,  1.9611e-02, -2.6363e-02,\n",
            "        -1.7614e-02, -7.6507e-03, -1.8069e-02,  3.3317e-02, -1.4265e-02,\n",
            "         1.4313e-02,  3.1589e-02,  1.8230e-02, -4.8092e-03,  1.7428e-02,\n",
            "         1.9970e-02,  7.8955e-03,  2.3311e-03, -5.1616e-03,  2.0641e-02,\n",
            "        -7.2562e-03,  3.6126e-03, -2.8805e-02, -2.8286e-02,  2.1347e-02,\n",
            "        -6.8545e-03, -2.6643e-02,  1.6296e-02, -2.0172e-02, -1.3737e-02,\n",
            "         2.1038e-02, -1.1491e-02, -7.8086e-03, -1.9018e-02, -2.0862e-02,\n",
            "         1.3247e-02, -1.2626e-02, -3.1806e-02,  3.4064e-02,  2.8563e-02,\n",
            "         2.7296e-02,  9.7978e-03,  1.5375e-02, -2.5292e-02,  8.4919e-03,\n",
            "        -1.9312e-02,  2.6042e-03,  9.8666e-03, -4.2518e-03, -1.6198e-02,\n",
            "        -3.1239e-02,  3.4536e-02, -1.0513e-02, -2.9333e-02, -1.9270e-02,\n",
            "         3.0589e-02,  2.9319e-02,  1.1078e-02,  1.5034e-02,  2.3872e-02,\n",
            "         2.0975e-02, -2.5227e-02, -1.0675e-02,  3.0464e-02,  2.1378e-02,\n",
            "         3.5285e-03,  2.4419e-02, -3.0545e-02,  1.5870e-02, -1.7547e-02,\n",
            "        -3.6114e-03,  3.1177e-02, -1.7190e-02,  1.6320e-02, -3.0542e-03,\n",
            "        -2.4526e-02,  3.1125e-02,  5.1279e-05,  3.3553e-02,  3.8974e-03,\n",
            "         2.0497e-02,  1.8322e-02, -1.9805e-02, -2.9749e-02, -1.2427e-02],\n",
            "       device='cuda:0')), ('inception_block_8.b2.1.weight', tensor([0.9950, 0.9958, 0.9983, 1.0016, 1.0001, 0.9862, 1.0067, 0.9995, 1.0064,\n",
            "        1.0035, 0.9906, 0.9992, 0.9876, 1.0055, 0.9933, 1.0017, 1.0013, 0.9954,\n",
            "        0.9992, 1.0048, 1.0041, 1.0084, 0.9984, 0.9982, 1.0085, 1.0088, 0.9962,\n",
            "        0.9995, 0.9889, 1.0044, 1.0039, 1.0042, 0.9918, 0.9936, 0.9855, 0.9941,\n",
            "        0.9963, 1.0072, 0.9943, 1.0047, 0.9891, 1.0045, 0.9915, 1.0032, 1.0093,\n",
            "        1.0036, 0.9950, 1.0006, 1.0022, 1.0012, 1.0006, 1.0022, 0.9968, 1.0026,\n",
            "        1.0061, 1.0070, 0.9963, 0.9983, 0.9969, 0.9974, 0.9885, 0.9910, 0.9961,\n",
            "        0.9986, 1.0065, 1.0057, 1.0021, 1.0031, 1.0021, 0.9995, 0.9943, 0.9964,\n",
            "        1.0083, 1.0026, 1.0038, 0.9933, 1.0013, 0.9953, 1.0013, 1.0020, 0.9965,\n",
            "        1.0047, 1.0092, 0.9999, 1.0010, 1.0025, 0.9889, 0.9964, 1.0036, 1.0021,\n",
            "        1.0072, 0.9966, 0.9914, 1.0136, 1.0005, 1.0024, 0.9965, 0.9932, 1.0021,\n",
            "        0.9968, 0.9910, 0.9950, 0.9963, 0.9962, 0.9923, 1.0009, 0.9873, 0.9945,\n",
            "        1.0057, 0.9996, 1.0025, 0.9913, 0.9979, 1.0115, 0.9935, 0.9966, 1.0065,\n",
            "        1.0084, 0.9955, 1.0007, 1.0162, 0.9943, 1.0051, 1.0020, 0.9994, 1.0009,\n",
            "        0.9972, 0.9967, 1.0070, 0.9982, 0.9952, 1.0032, 0.9941, 0.9978, 0.9968,\n",
            "        0.9977, 0.9922, 0.9998, 0.9999, 1.0017, 1.0105, 0.9968, 1.0065, 1.0056,\n",
            "        0.9939, 0.9890, 1.0050, 1.0076, 1.0031, 1.0034, 1.0006, 0.9981, 1.0021,\n",
            "        1.0015, 1.0007, 1.0051, 0.9920, 0.9903, 1.0009, 0.9989],\n",
            "       device='cuda:0')), ('inception_block_8.b2.1.bias', tensor([-0.0077, -0.0053, -0.0038, -0.0030, -0.0127, -0.0067, -0.0067, -0.0090,\n",
            "        -0.0092, -0.0111, -0.0112, -0.0115, -0.0112, -0.0029, -0.0124, -0.0083,\n",
            "        -0.0157, -0.0085, -0.0036, -0.0038, -0.0102, -0.0114, -0.0102, -0.0010,\n",
            "        -0.0025,  0.0019, -0.0047, -0.0140, -0.0246, -0.0045,  0.0023, -0.0016,\n",
            "        -0.0181, -0.0099, -0.0074, -0.0091, -0.0163, -0.0030, -0.0120, -0.0064,\n",
            "        -0.0183, -0.0107, -0.0126, -0.0076, -0.0084, -0.0168, -0.0105, -0.0060,\n",
            "        -0.0116, -0.0077, -0.0140, -0.0047, -0.0101, -0.0022, -0.0040, -0.0019,\n",
            "        -0.0182, -0.0100, -0.0061, -0.0105, -0.0144, -0.0128, -0.0030, -0.0209,\n",
            "        -0.0157, -0.0109, -0.0022, -0.0121, -0.0032, -0.0064, -0.0105, -0.0067,\n",
            "        -0.0094, -0.0018, -0.0069, -0.0143, -0.0020, -0.0137, -0.0064, -0.0107,\n",
            "        -0.0132, -0.0106, -0.0040, -0.0116, -0.0034, -0.0057, -0.0184, -0.0073,\n",
            "        -0.0131, -0.0140, -0.0062, -0.0078, -0.0143,  0.0065, -0.0057, -0.0097,\n",
            "        -0.0025, -0.0200, -0.0114, -0.0157, -0.0151, -0.0191, -0.0020, -0.0073,\n",
            "        -0.0148, -0.0088, -0.0195, -0.0231, -0.0132, -0.0109, -0.0122, -0.0151,\n",
            "        -0.0081, -0.0017, -0.0193, -0.0171, -0.0077, -0.0026, -0.0070, -0.0045,\n",
            "        -0.0045, -0.0017, -0.0113, -0.0090, -0.0095, -0.0089, -0.0020, -0.0038,\n",
            "        -0.0098, -0.0150, -0.0158,  0.0057, -0.0076, -0.0050, -0.0128, -0.0055,\n",
            "        -0.0113, -0.0129, -0.0087, -0.0023, -0.0002, -0.0137,  0.0070, -0.0077,\n",
            "        -0.0044, -0.0085, -0.0007,  0.0016, -0.0075, -0.0107, -0.0047, -0.0116,\n",
            "        -0.0067, -0.0021, -0.0075,  0.0032, -0.0143, -0.0139, -0.0146, -0.0077],\n",
            "       device='cuda:0')), ('inception_block_8.b2.1.running_mean', tensor([ 0.1804, -1.1253, -1.2029, -1.0548, -1.2602, -0.5820, -0.1568,  0.5879,\n",
            "        -0.1909,  1.5437, -0.1923,  0.6889, -0.8975, -0.7510,  0.0668,  0.3447,\n",
            "         0.9649, -1.5651, -0.4095,  1.9604,  0.5421,  0.2753,  1.6294, -0.0249,\n",
            "        -2.2081, -2.1437,  0.5373,  0.7286, -0.6901,  0.4879,  1.5976, -1.3483,\n",
            "        -0.1743,  1.8351, -1.5790, -0.7607,  0.8719,  0.7885,  0.2109, -1.8190,\n",
            "        -0.0907,  0.3764, -0.2250,  0.2184,  0.5782,  0.6312,  0.1127,  0.3005,\n",
            "         0.7401, -0.8762,  0.6984, -0.0428, -0.6836, -0.1661,  0.3225,  0.9477,\n",
            "         0.4208, -0.4263, -1.2797, -0.1339, -1.1438,  1.6846,  0.2938,  0.6628,\n",
            "         0.8560, -0.0298,  0.1730,  0.4360,  0.7184, -0.0134,  0.2172, -0.8362,\n",
            "         1.6972, -0.2036,  0.5806, -0.7600, -0.6844,  0.9789, -0.5523,  0.3786,\n",
            "        -1.3822, -1.2241, -0.5965,  2.2271,  0.7545, -1.6989,  1.8420,  1.2925,\n",
            "         1.6823,  1.2904,  0.4611,  0.3230, -1.6780, -0.3859, -1.4525,  1.4299,\n",
            "        -0.9542,  1.5028,  0.5233,  0.9671, -0.8761,  1.5482, -1.6135,  0.1270,\n",
            "        -0.0473,  0.9975, -0.5389,  1.3152,  1.4958,  0.6369, -0.7777, -0.6392,\n",
            "        -0.6423,  0.3357,  0.3108,  1.4057,  1.2137,  0.1232, -0.3801,  0.9848,\n",
            "         0.3667, -0.0785,  0.0546,  1.2721,  0.9546, -0.7319, -1.3717, -0.3441,\n",
            "         0.7959,  1.2525,  0.4048, -0.8443, -0.3042, -0.9118,  0.1366, -0.5328,\n",
            "         0.3987,  1.1661, -0.0489,  0.4761, -0.1431, -0.6362, -0.1646,  0.9121,\n",
            "        -1.6595, -0.3051, -0.4493, -0.6296, -0.1386,  0.7896, -0.9324,  1.4306,\n",
            "        -0.1340,  0.4818,  1.1696, -1.0404,  0.0486,  0.7897,  0.5242, -0.5424],\n",
            "       device='cuda:0')), ('inception_block_8.b2.1.running_var', tensor([0.5856, 0.3344, 0.6244, 0.4281, 0.3090, 0.4156, 0.4297, 0.3608, 0.4050,\n",
            "        0.5060, 0.4335, 0.6817, 0.7374, 0.4891, 0.3093, 0.3016, 0.4812, 0.7833,\n",
            "        0.6515, 0.4805, 0.2872, 0.4292, 0.4221, 0.5236, 0.4746, 0.5203, 0.3460,\n",
            "        0.3579, 0.4642, 0.4592, 0.3478, 0.4389, 0.4151, 0.8801, 0.6457, 0.3706,\n",
            "        0.5801, 0.3819, 0.4788, 0.5760, 0.3584, 0.3033, 0.3206, 0.5044, 0.3520,\n",
            "        0.3960, 0.3629, 0.5274, 0.5364, 0.2536, 0.3355, 0.3819, 0.4575, 0.3940,\n",
            "        0.4081, 0.5465, 0.4060, 0.4482, 0.5070, 0.3992, 0.3446, 0.9144, 0.2932,\n",
            "        0.4132, 0.2803, 0.4232, 0.5401, 0.4104, 0.3723, 0.5177, 0.4344, 0.4291,\n",
            "        0.6169, 0.5138, 0.5212, 0.2865, 0.3717, 0.6220, 0.4313, 0.4542, 0.3229,\n",
            "        0.4158, 0.3700, 0.6109, 0.5296, 0.5832, 0.6165, 0.3527, 0.3000, 0.4760,\n",
            "        0.4089, 0.3549, 0.5308, 0.3598, 0.5171, 0.3269, 0.4786, 0.3847, 0.5177,\n",
            "        0.4682, 0.5156, 0.4873, 0.6293, 0.3788, 0.4240, 0.4335, 0.4499, 0.3842,\n",
            "        0.2637, 0.4864, 0.3455, 0.5583, 0.5259, 0.4597, 0.4855, 0.4458, 0.3407,\n",
            "        0.4081, 0.4277, 0.3773, 0.4676, 0.3669, 0.4730, 0.4249, 0.4462, 0.3472,\n",
            "        1.0161, 0.4762, 0.3627, 0.3614, 0.2972, 0.5724, 0.4566, 0.3442, 0.3202,\n",
            "        0.4522, 0.4265, 0.3377, 0.4669, 0.4211, 0.3918, 0.4103, 0.5070, 0.4889,\n",
            "        0.5888, 0.3347, 0.3722, 0.3634, 0.3873, 0.9032, 0.4600, 0.3445, 0.4083,\n",
            "        0.3494, 0.4875, 0.6177, 0.3610, 1.1041, 0.5398, 0.3456],\n",
            "       device='cuda:0')), ('inception_block_8.b2.1.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_8.b2.3.weight', tensor([[[[-2.0731e-02,  1.7332e-02,  1.4238e-02],\n",
            "          [ 1.5146e-02,  4.9072e-03, -1.1525e-02],\n",
            "          [ 1.3987e-02, -8.4534e-03, -1.1491e-02]],\n",
            "\n",
            "         [[ 1.0864e-02, -1.2845e-02, -1.0961e-02],\n",
            "          [-3.3924e-03,  4.9561e-03, -2.7658e-03],\n",
            "          [ 1.9813e-02,  1.6773e-02, -2.2483e-02]],\n",
            "\n",
            "         [[ 9.6907e-03,  2.3029e-02,  5.7646e-03],\n",
            "          [ 9.0279e-03,  2.0588e-02,  8.7556e-03],\n",
            "          [ 1.1291e-03, -2.2560e-02, -2.2163e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8156e-02,  2.6366e-02, -6.1426e-03],\n",
            "          [ 2.0636e-02, -1.8154e-02, -1.7160e-02],\n",
            "          [ 3.3505e-02,  1.7930e-02,  2.6208e-02]],\n",
            "\n",
            "         [[ 1.3305e-02, -2.3952e-02, -3.1786e-02],\n",
            "          [ 1.1655e-02,  1.6655e-02,  1.5142e-02],\n",
            "          [ 1.3331e-02, -2.8766e-03, -1.5271e-04]],\n",
            "\n",
            "         [[ 5.2084e-03,  6.3105e-03, -2.8710e-02],\n",
            "          [ 5.7574e-03,  2.2451e-03, -1.6206e-02],\n",
            "          [ 1.9402e-02, -2.7041e-02,  2.1742e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.9766e-03, -7.6627e-03,  2.6192e-03],\n",
            "          [-1.8356e-02, -2.8582e-02, -2.7857e-02],\n",
            "          [ 8.1950e-03, -2.1342e-02,  1.5384e-02]],\n",
            "\n",
            "         [[ 1.9577e-02,  1.9928e-02, -1.7318e-02],\n",
            "          [-6.0730e-03, -1.6960e-02, -9.3029e-05],\n",
            "          [ 1.7698e-02,  1.2453e-02, -2.1024e-02]],\n",
            "\n",
            "         [[-1.4750e-02,  1.8474e-03,  7.6897e-03],\n",
            "          [ 1.8888e-02, -2.3869e-02, -2.4940e-02],\n",
            "          [ 2.0114e-02,  4.8069e-03,  2.1529e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2217e-02,  1.3342e-02, -2.3863e-02],\n",
            "          [ 8.4761e-03, -3.1000e-02, -3.9387e-03],\n",
            "          [-2.4071e-02,  1.4859e-02, -1.4156e-04]],\n",
            "\n",
            "         [[-1.6252e-02,  1.6930e-02, -9.9231e-03],\n",
            "          [ 1.8071e-02,  5.1037e-03, -3.3628e-03],\n",
            "          [ 6.0443e-03,  8.2866e-03, -5.8790e-03]],\n",
            "\n",
            "         [[ 9.0648e-03, -1.2374e-03, -2.9142e-03],\n",
            "          [ 9.2614e-03, -1.6043e-03,  7.2319e-03],\n",
            "          [ 1.2472e-02, -1.6874e-02,  9.7880e-03]]],\n",
            "\n",
            "\n",
            "        [[[-8.0989e-03, -2.0886e-02,  1.1209e-02],\n",
            "          [ 3.4550e-03,  1.4711e-02,  2.6358e-02],\n",
            "          [ 1.8763e-03, -1.2519e-02,  3.3260e-03]],\n",
            "\n",
            "         [[ 8.6181e-03,  3.0352e-04, -2.1552e-02],\n",
            "          [ 3.4449e-03,  8.6415e-03,  6.9526e-03],\n",
            "          [ 9.8048e-03, -4.6361e-03, -1.4328e-02]],\n",
            "\n",
            "         [[-2.6508e-02, -3.1098e-02, -1.0998e-02],\n",
            "          [ 2.4410e-02,  7.9478e-03, -1.7504e-03],\n",
            "          [ 9.1364e-03,  1.7260e-02, -1.4933e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3608e-02,  1.8859e-02,  1.8200e-02],\n",
            "          [ 1.5343e-02,  5.1982e-03, -3.1475e-03],\n",
            "          [-2.3183e-02, -2.3926e-02,  1.8364e-02]],\n",
            "\n",
            "         [[ 2.6443e-02,  2.4461e-02, -2.3986e-02],\n",
            "          [ 7.9396e-03, -2.7377e-02, -3.1582e-02],\n",
            "          [-3.0283e-02, -1.9616e-02, -2.6204e-02]],\n",
            "\n",
            "         [[-1.1191e-02,  6.8281e-03, -9.0538e-03],\n",
            "          [ 1.7211e-02,  3.6505e-03, -8.4318e-04],\n",
            "          [ 4.3013e-03,  1.6186e-02, -1.1778e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.8116e-02, -1.4953e-02, -2.1025e-02],\n",
            "          [-1.5837e-02, -1.2432e-02,  1.6151e-02],\n",
            "          [ 2.6090e-02, -6.8851e-03, -1.3085e-02]],\n",
            "\n",
            "         [[-1.8841e-02, -1.6353e-02,  1.4066e-02],\n",
            "          [ 1.2216e-02, -5.4430e-03, -2.3874e-02],\n",
            "          [ 2.9548e-03, -2.2329e-02,  6.2907e-03]],\n",
            "\n",
            "         [[ 1.8252e-02, -4.6946e-03, -2.7952e-02],\n",
            "          [ 1.2523e-02, -2.7862e-02,  1.1175e-02],\n",
            "          [-9.3862e-03,  3.5239e-03, -2.6478e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.4893e-02, -1.4594e-02, -1.4736e-02],\n",
            "          [ 2.2663e-02, -1.3612e-03, -1.5417e-02],\n",
            "          [-2.1414e-03,  5.7233e-03, -6.2587e-03]],\n",
            "\n",
            "         [[ 6.8144e-04,  3.2020e-03,  2.1550e-02],\n",
            "          [-2.0304e-02,  2.7467e-02, -9.2932e-03],\n",
            "          [ 7.6652e-03,  5.8020e-03,  2.8623e-02]],\n",
            "\n",
            "         [[-1.0709e-02, -1.2852e-02, -6.2323e-03],\n",
            "          [ 1.5606e-02, -5.3225e-03, -2.1492e-02],\n",
            "          [-2.1094e-02, -5.2713e-03,  6.9978e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1022e-03,  1.2302e-02, -9.6817e-03],\n",
            "          [ 1.1820e-02, -2.8849e-02, -3.3387e-02],\n",
            "          [ 2.2238e-02, -1.5117e-02,  9.9064e-04]],\n",
            "\n",
            "         [[-1.2017e-02,  2.2000e-02,  1.7513e-04],\n",
            "          [-6.4435e-04, -2.3323e-02, -2.3372e-02],\n",
            "          [ 3.0402e-03,  3.4560e-03,  2.9089e-02]],\n",
            "\n",
            "         [[-2.0906e-02, -1.5551e-02,  2.0293e-02],\n",
            "          [ 2.9727e-03, -1.7701e-02,  1.9856e-03],\n",
            "          [-2.3520e-02,  1.6972e-02,  2.2660e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0049e-02,  1.2993e-02, -5.4123e-03],\n",
            "          [-7.0760e-03, -3.0236e-03,  1.0653e-02],\n",
            "          [ 1.0195e-02, -1.5081e-02,  1.1409e-02]],\n",
            "\n",
            "         [[ 9.6063e-05, -1.7877e-02, -1.6253e-02],\n",
            "          [-1.0599e-02, -1.1333e-02, -1.6874e-02],\n",
            "          [ 1.4031e-02, -1.9649e-03, -1.4279e-03]],\n",
            "\n",
            "         [[-2.8576e-03,  1.5036e-02, -2.2803e-02],\n",
            "          [ 1.9350e-02, -1.4679e-02, -9.7905e-03],\n",
            "          [ 5.3056e-03, -1.2102e-04, -1.1571e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0967e-02, -2.5092e-02, -1.9138e-02],\n",
            "          [ 1.7953e-02, -1.0553e-02,  4.1356e-03],\n",
            "          [-2.6573e-03,  4.1825e-03,  8.3332e-04]],\n",
            "\n",
            "         [[ 1.8003e-02,  1.2364e-02, -1.0883e-02],\n",
            "          [ 1.4314e-02,  1.8006e-02, -7.5692e-03],\n",
            "          [-5.1115e-03,  9.2412e-03, -1.5172e-02]],\n",
            "\n",
            "         [[-2.8027e-03, -8.9726e-03,  2.0910e-04],\n",
            "          [-1.5863e-02, -1.9949e-02,  5.2753e-03],\n",
            "          [ 4.3257e-04, -2.6983e-02, -3.2350e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1624e-02, -2.0651e-02,  1.2770e-02],\n",
            "          [ 1.8881e-02, -2.1420e-02, -1.8957e-02],\n",
            "          [-9.1146e-03,  1.9449e-03,  1.7033e-02]],\n",
            "\n",
            "         [[-1.9055e-02, -3.4761e-02,  2.1040e-02],\n",
            "          [-6.5758e-03,  1.9175e-02, -9.1262e-03],\n",
            "          [-2.2076e-04,  1.6675e-02, -1.4010e-02]],\n",
            "\n",
            "         [[-1.9710e-02,  1.2411e-02, -2.3701e-02],\n",
            "          [-1.2986e-02, -2.0622e-02, -1.8863e-02],\n",
            "          [ 9.9700e-03, -1.6596e-02, -2.0379e-02]]]], device='cuda:0')), ('inception_block_8.b2.3.bias', tensor([ 1.0057e-02, -2.4590e-02,  2.0156e-02, -1.6977e-02,  1.6727e-02,\n",
            "         8.1288e-03,  2.4355e-02, -1.5593e-02, -6.1665e-03, -1.8019e-02,\n",
            "         9.3718e-03,  8.6658e-03,  1.4719e-02,  1.5178e-02, -7.4524e-04,\n",
            "        -4.6044e-03, -1.7123e-02,  1.7687e-02, -5.7918e-03,  7.7893e-03,\n",
            "        -1.9702e-02, -2.2408e-02, -1.1151e-02,  2.3751e-02, -1.8941e-02,\n",
            "         1.9245e-02,  8.2600e-03,  1.7012e-02, -1.0931e-02,  2.6236e-02,\n",
            "         2.2770e-02,  8.0047e-04, -1.4661e-02, -1.7005e-02, -9.0966e-03,\n",
            "         1.1564e-02, -7.0795e-03,  1.0648e-02, -5.8135e-03, -1.2613e-04,\n",
            "        -2.2138e-02, -1.6167e-02, -1.8803e-02,  1.9348e-02, -2.5712e-02,\n",
            "        -1.3907e-02, -2.4789e-02,  1.5666e-02, -2.5384e-03, -7.1291e-03,\n",
            "        -2.5969e-02,  2.5722e-02,  1.4868e-02, -3.5288e-03, -2.5800e-03,\n",
            "        -6.4744e-03, -1.4169e-02,  7.2510e-03,  5.1170e-05,  3.6936e-03,\n",
            "         9.8879e-03, -5.0804e-03,  2.5785e-02, -9.3947e-03, -2.3515e-02,\n",
            "         1.3977e-02,  2.1434e-02, -1.8752e-02,  1.4344e-02, -1.7658e-02,\n",
            "        -1.3473e-02,  8.3440e-03, -2.0802e-06, -2.2994e-02, -2.3373e-02,\n",
            "         3.7170e-03,  3.8232e-03, -9.4886e-03,  9.2406e-03,  2.4482e-02,\n",
            "         1.5316e-02, -1.1843e-02,  5.3961e-03, -2.2924e-02, -1.9054e-03,\n",
            "        -1.0931e-02, -6.5327e-03, -1.3759e-02,  1.3873e-03,  6.8917e-03,\n",
            "         1.9707e-02, -9.4191e-03, -2.1028e-02,  9.8137e-03, -1.8085e-02,\n",
            "        -4.4157e-03, -2.4708e-02,  2.0498e-02,  2.9906e-03,  1.7829e-03,\n",
            "        -2.9855e-03,  1.1065e-02, -2.2017e-02, -9.2313e-04,  9.6494e-03,\n",
            "        -1.2137e-02, -1.1668e-03, -1.3201e-02,  1.6267e-02,  1.3186e-02,\n",
            "        -2.2553e-02, -9.7273e-03, -3.5153e-03, -1.1831e-02, -1.1894e-02,\n",
            "         1.2834e-02, -2.2105e-02,  2.4562e-02, -2.1348e-02,  9.1954e-03,\n",
            "        -2.1575e-02,  1.2380e-02, -2.1055e-03,  2.2030e-02, -9.1045e-03,\n",
            "         1.7347e-02,  1.5247e-02, -2.3614e-02,  1.9258e-02,  2.9221e-03,\n",
            "        -1.5248e-02,  1.7714e-02, -6.0181e-03,  2.4860e-02,  1.0199e-02,\n",
            "         1.7988e-02, -5.8886e-03,  4.1528e-03,  2.0449e-02, -4.5355e-03,\n",
            "         1.1849e-02,  1.5626e-02,  2.0426e-02, -7.8117e-03,  7.3337e-03,\n",
            "        -1.1861e-02, -2.2448e-02,  2.0611e-02, -2.4601e-02, -2.3412e-03,\n",
            "        -9.1887e-04, -1.9603e-02,  1.5098e-02,  1.5725e-02, -1.2666e-02,\n",
            "         2.5358e-03, -1.2359e-02,  1.3514e-02,  2.6195e-02,  8.5879e-03,\n",
            "        -1.7003e-02, -1.9192e-02, -1.9742e-02, -4.3804e-03, -2.3388e-02,\n",
            "         1.2043e-02,  2.3681e-02, -1.6482e-02,  2.2513e-02, -2.4561e-02,\n",
            "        -1.2308e-02, -1.4420e-02,  6.9407e-03,  2.5148e-02,  1.4740e-02,\n",
            "         2.0811e-02,  8.1870e-03, -2.4126e-02, -1.0767e-02, -5.3507e-03,\n",
            "        -9.4948e-03, -2.2498e-02, -7.7930e-03,  9.8043e-03, -1.9086e-02,\n",
            "         1.2516e-02, -4.0819e-03, -4.7309e-03,  1.1321e-02,  1.1577e-02,\n",
            "         1.7105e-02, -2.4966e-02, -3.9104e-03, -1.2095e-02, -1.8103e-02,\n",
            "        -9.6721e-03, -1.6556e-02, -9.6990e-03,  7.2728e-03, -1.7240e-02,\n",
            "         3.3417e-03,  7.0814e-03,  1.1888e-02, -2.4214e-02, -1.2182e-02,\n",
            "         2.5193e-02,  1.6618e-02, -2.1986e-02,  2.5617e-02,  2.1286e-02,\n",
            "         1.1266e-02,  1.8188e-02, -1.7291e-02,  1.9811e-02, -7.2632e-03,\n",
            "        -8.4431e-03, -1.0841e-03,  1.4591e-02, -9.8984e-03,  9.2861e-03,\n",
            "        -9.9484e-03, -2.2698e-02, -2.2515e-02,  1.2116e-02, -2.0852e-02,\n",
            "        -2.4729e-02, -1.2244e-02, -8.4132e-03, -7.2741e-03,  1.1874e-02,\n",
            "         1.3851e-02, -1.7056e-02, -9.6719e-03,  2.1338e-02, -1.2253e-02,\n",
            "        -2.5541e-02,  1.0455e-03,  9.3827e-03,  2.2574e-03, -4.1042e-03,\n",
            "        -7.3844e-03, -1.6553e-02, -7.8902e-03,  2.0280e-02,  1.5503e-02,\n",
            "         6.1568e-03,  1.6862e-02,  3.3851e-03,  2.2033e-02,  2.1565e-02,\n",
            "        -7.2185e-03, -2.2773e-02,  1.7096e-02, -1.1304e-02,  7.8977e-03,\n",
            "        -1.5649e-03, -1.8892e-02,  9.6888e-03,  2.5990e-02,  2.1062e-03,\n",
            "        -1.1390e-02, -1.6794e-02, -1.9293e-02,  2.4171e-02, -3.7842e-03,\n",
            "         9.0410e-03,  4.7947e-03, -2.4160e-02,  4.8790e-03,  3.9119e-03,\n",
            "        -3.1502e-03,  5.0338e-03,  7.4386e-03,  9.7547e-04, -1.6728e-02,\n",
            "         6.3230e-03,  2.4387e-02,  2.2215e-02, -1.2475e-02,  1.2385e-02,\n",
            "         1.5306e-02, -1.5252e-02, -1.8415e-03, -3.0292e-03,  6.2686e-03,\n",
            "         1.3836e-02, -1.9653e-02, -1.2769e-02,  8.5601e-03,  1.6968e-02,\n",
            "        -1.2720e-02,  5.8381e-04,  6.2482e-03,  7.2305e-03, -8.4541e-03,\n",
            "         1.5120e-02,  1.4432e-02, -2.4397e-02, -1.3437e-02,  1.2073e-02,\n",
            "        -4.8236e-04, -1.4627e-03, -1.2771e-02,  1.7452e-02, -6.3654e-03,\n",
            "        -3.9255e-03, -2.4253e-02, -1.3684e-02, -2.4167e-02,  1.9931e-02,\n",
            "         1.1163e-02, -1.7678e-02,  9.8652e-03,  6.1484e-03, -8.0509e-03,\n",
            "         2.2689e-02,  2.2936e-02,  1.9273e-03, -9.5632e-03, -1.5939e-02],\n",
            "       device='cuda:0')), ('inception_block_8.b2.4.weight', tensor([0.9903, 0.9906, 0.9880, 0.9798, 0.9896, 0.9906, 0.9921, 0.9899, 0.9911,\n",
            "        0.9943, 0.9918, 0.9973, 0.9886, 0.9927, 0.9808, 0.9950, 0.9916, 0.9886,\n",
            "        1.0103, 0.9841, 1.0086, 0.9876, 0.9913, 0.9931, 0.9974, 0.9932, 1.0004,\n",
            "        0.9915, 0.9987, 0.9934, 0.9933, 0.9978, 0.9875, 1.0015, 1.0017, 0.9897,\n",
            "        1.0004, 1.0019, 0.9945, 0.9898, 0.9952, 0.9997, 0.9955, 0.9909, 0.9878,\n",
            "        0.9852, 0.9869, 0.9985, 0.9833, 0.9933, 0.9949, 0.9837, 0.9964, 0.9893,\n",
            "        0.9952, 0.9880, 0.9904, 0.9825, 1.0015, 0.9868, 0.9974, 0.9953, 0.9923,\n",
            "        0.9936, 0.9952, 0.9864, 0.9918, 0.9910, 0.9847, 0.9818, 0.9917, 0.9918,\n",
            "        0.9971, 0.9972, 0.9952, 0.9817, 0.9887, 0.9849, 0.9912, 0.9847, 0.9882,\n",
            "        0.9812, 0.9933, 0.9884, 0.9897, 0.9942, 0.9893, 0.9917, 0.9921, 0.9841,\n",
            "        0.9865, 0.9957, 0.9893, 1.0002, 0.9971, 0.9915, 0.9915, 0.9892, 0.9901,\n",
            "        0.9955, 0.9948, 0.9827, 0.9858, 0.9949, 0.9838, 0.9894, 0.9893, 0.9902,\n",
            "        0.9983, 0.9920, 0.9943, 0.9834, 0.9960, 0.9915, 0.9816, 0.9931, 0.9978,\n",
            "        0.9973, 0.9968, 0.9944, 0.9970, 0.9893, 0.9973, 0.9921, 0.9897, 0.9940,\n",
            "        0.9950, 0.9855, 0.9794, 0.9796, 0.9988, 0.9888, 0.9997, 0.9842, 0.9953,\n",
            "        0.9878, 0.9926, 0.9888, 0.9978, 0.9873, 0.9972, 0.9826, 0.9902, 0.9890,\n",
            "        1.0017, 0.9936, 0.9869, 0.9869, 0.9822, 0.9944, 0.9992, 0.9906, 0.9867,\n",
            "        1.0051, 0.9881, 0.9984, 0.9845, 0.9937, 0.9849, 0.9888, 0.9860, 0.9915,\n",
            "        0.9870, 0.9858, 0.9978, 0.9935, 0.9992, 0.9994, 1.0001, 0.9929, 0.9806,\n",
            "        0.9933, 0.9922, 0.9938, 0.9941, 0.9983, 0.9896, 0.9953, 1.0020, 1.0001,\n",
            "        0.9921, 0.9927, 0.9846, 0.9944, 0.9937, 0.9802, 0.9963, 0.9932, 0.9964,\n",
            "        0.9959, 0.9924, 0.9860, 0.9923, 0.9984, 0.9824, 1.0007, 0.9929, 0.9910,\n",
            "        0.9861, 0.9828, 0.9922, 0.9895, 0.9956, 0.9916, 0.9959, 0.9963, 0.9955,\n",
            "        0.9917, 0.9952, 0.9951, 0.9927, 0.9878, 0.9858, 0.9862, 0.9876, 0.9913,\n",
            "        0.9984, 0.9928, 0.9809, 0.9860, 0.9986, 0.9905, 0.9980, 0.9846, 0.9926,\n",
            "        0.9868, 0.9777, 0.9910, 0.9854, 0.9893, 0.9879, 0.9941, 0.9920, 0.9861,\n",
            "        0.9885, 0.9882, 0.9902, 0.9937, 0.9864, 0.9912, 0.9972, 0.9921, 0.9868,\n",
            "        0.9923, 0.9924, 0.9935, 0.9939, 0.9926, 0.9855, 0.9920, 0.9958, 0.9878,\n",
            "        0.9881, 1.0017, 0.9879, 1.0027, 1.0020, 0.9878, 0.9889, 0.9906, 0.9922,\n",
            "        0.9916, 0.9899, 0.9933, 0.9951, 0.9856, 0.9880, 0.9851, 1.0086, 0.9928,\n",
            "        0.9960, 0.9923, 1.0002, 0.9820, 0.9919, 0.9812, 1.0021, 0.9877, 0.9892,\n",
            "        0.9978, 0.9998, 0.9852, 0.9909, 0.9906, 0.9910, 1.0084, 1.0055, 0.9924,\n",
            "        0.9900, 0.9869, 0.9894, 0.9886, 0.9961, 0.9931, 0.9862, 0.9795, 0.9890,\n",
            "        0.9845, 0.9988, 0.9943, 0.9942, 0.9855, 0.9855, 0.9960, 0.9935, 0.9949,\n",
            "        0.9928, 0.9847, 0.9993, 0.9857, 0.9945, 1.0014, 0.9930, 0.9848, 0.9925,\n",
            "        0.9894, 0.9910, 0.9992, 0.9852, 0.9846], device='cuda:0')), ('inception_block_8.b2.4.bias', tensor([-0.0198, -0.0040, -0.0159, -0.0169, -0.0036, -0.0198, -0.0057, -0.0237,\n",
            "        -0.0114, -0.0069, -0.0046, -0.0016, -0.0159, -0.0119, -0.0214, -0.0228,\n",
            "        -0.0126, -0.0130, -0.0233, -0.0221, -0.0096, -0.0205, -0.0217, -0.0060,\n",
            "        -0.0098, -0.0004, -0.0123, -0.0145, -0.0117, -0.0123, -0.0193, -0.0105,\n",
            "        -0.0266, -0.0108, -0.0113, -0.0257, -0.0075, -0.0146, -0.0146, -0.0269,\n",
            "        -0.0171, -0.0092, -0.0119, -0.0064, -0.0132, -0.0253, -0.0123, -0.0142,\n",
            "        -0.0193, -0.0113, -0.0142, -0.0222, -0.0173, -0.0227, -0.0093, -0.0091,\n",
            "        -0.0150, -0.0128, -0.0254, -0.0160, -0.0098, -0.0129, -0.0215, -0.0018,\n",
            "        -0.0148, -0.0103, -0.0168, -0.0152, -0.0182, -0.0174, -0.0205, -0.0102,\n",
            "        -0.0071, -0.0152, -0.0185, -0.0178, -0.0049, -0.0244, -0.0154, -0.0216,\n",
            "        -0.0150, -0.0246, -0.0204, -0.0111, -0.0146, -0.0188, -0.0185, -0.0086,\n",
            "        -0.0062, -0.0151, -0.0192, -0.0175, -0.0100, -0.0269, -0.0130, -0.0115,\n",
            "        -0.0191, -0.0047, -0.0208, -0.0228, -0.0059, -0.0281, -0.0298, -0.0160,\n",
            "        -0.0285, -0.0155, -0.0116, -0.0254, -0.0229, -0.0067, -0.0143, -0.0198,\n",
            "        -0.0080, -0.0039, -0.0144, -0.0116, -0.0084, -0.0115, -0.0102, -0.0051,\n",
            "        -0.0100, -0.0137, -0.0116, -0.0123, -0.0186, -0.0120, -0.0040, -0.0160,\n",
            "        -0.0144, -0.0197, -0.0132, -0.0192, -0.0222, -0.0243, -0.0072, -0.0193,\n",
            "        -0.0123, -0.0186, -0.0127, -0.0262, -0.0022, -0.0176, -0.0094, -0.0130,\n",
            "        -0.0031, -0.0166, -0.0260, -0.0229, -0.0139, -0.0124, -0.0134, -0.0236,\n",
            "        -0.0124, -0.0215, -0.0099, -0.0212, -0.0125, -0.0150, -0.0145, -0.0143,\n",
            "        -0.0172, -0.0144, -0.0127, -0.0124, -0.0265, -0.0226, -0.0074, -0.0115,\n",
            "        -0.0070, -0.0115, -0.0157, -0.0124, -0.0082, -0.0125, -0.0089, -0.0085,\n",
            "        -0.0129, -0.0124, -0.0148, -0.0183, -0.0108, -0.0148, -0.0172, -0.0144,\n",
            "        -0.0143, -0.0220, -0.0110, -0.0121, -0.0059, -0.0118, -0.0171, -0.0180,\n",
            "        -0.0179, -0.0219, -0.0268, -0.0061, -0.0042, -0.0167, -0.0156, -0.0221,\n",
            "        -0.0106, -0.0123, -0.0129, -0.0175, -0.0015, -0.0098, -0.0064, -0.0109,\n",
            "        -0.0096, -0.0131, -0.0163, -0.0237, -0.0132, -0.0174, -0.0097, -0.0214,\n",
            "        -0.0060, -0.0087, -0.0154, -0.0136, -0.0081, -0.0182, -0.0148, -0.0145,\n",
            "        -0.0094, -0.0078, -0.0179, -0.0237, -0.0146, -0.0081, -0.0189, -0.0094,\n",
            "        -0.0194, -0.0239, -0.0114, -0.0132, -0.0109, -0.0096, -0.0166, -0.0087,\n",
            "        -0.0176, -0.0092, -0.0191, -0.0138, -0.0215, -0.0036, -0.0045, -0.0234,\n",
            "        -0.0150, -0.0204, -0.0042, -0.0143, -0.0157, -0.0129, -0.0172, -0.0086,\n",
            "        -0.0051, -0.0265, -0.0120, -0.0211, -0.0145, -0.0146, -0.0181, -0.0120,\n",
            "        -0.0096, -0.0175, -0.0115, -0.0183, -0.0093, -0.0127, -0.0112, -0.0211,\n",
            "        -0.0059, -0.0210, -0.0021, -0.0213, -0.0196, -0.0167, -0.0072, -0.0078,\n",
            "        -0.0060, -0.0227, -0.0084, -0.0089, -0.0146, -0.0152, -0.0146, -0.0151,\n",
            "        -0.0230, -0.0141, -0.0138, -0.0184, -0.0112, -0.0075, -0.0047, -0.0238,\n",
            "        -0.0089, -0.0181, -0.0099,  0.0004, -0.0157, -0.0196, -0.0199, -0.0034,\n",
            "        -0.0088, -0.0272, -0.0130, -0.0175, -0.0093, -0.0230, -0.0070, -0.0016,\n",
            "        -0.0305, -0.0108, -0.0031, -0.0107, -0.0054, -0.0071, -0.0156, -0.0256],\n",
            "       device='cuda:0')), ('inception_block_8.b2.4.running_mean', tensor([-8.0611e-04, -6.8213e-01, -1.6490e-01,  1.9346e-01, -8.3142e-01,\n",
            "        -4.8351e-01,  2.9325e-01, -7.9303e-01, -6.6725e-01, -1.0247e+00,\n",
            "        -1.0695e+00, -7.8228e-01, -6.2783e-01,  6.0479e-02, -2.2305e-01,\n",
            "         2.2754e-01, -1.0456e+00, -5.9891e-01, -4.9226e-01,  6.7068e-02,\n",
            "         1.8441e-01, -4.3235e-01, -5.3537e-01, -4.0316e-01, -3.4787e-01,\n",
            "        -4.4313e-01, -6.1057e-01,  3.2538e-02, -1.6057e-01,  5.3960e-03,\n",
            "        -3.7948e-01,  2.8607e-01, -6.0980e-01, -3.4261e-01, -3.1435e-01,\n",
            "        -1.1172e-01, -3.2808e-01, -2.1747e-01, -4.7894e-01, -3.5344e-01,\n",
            "        -7.9371e-01, -6.0421e-01, -8.7839e-01, -7.7081e-01, -4.3667e-01,\n",
            "        -3.9336e-01, -4.4911e-01, -8.7031e-01,  2.6540e-01, -4.7412e-01,\n",
            "         4.2684e-01, -7.6275e-01,  6.4518e-02,  4.2026e-01,  1.2898e-01,\n",
            "        -9.2883e-01, -2.0747e-01, -6.1083e-01, -6.1726e-01, -8.5533e-01,\n",
            "         5.6860e-01, -7.0170e-01, -6.7656e-01, -2.0572e+00, -1.0684e+00,\n",
            "        -9.5518e-01, -2.0617e-01,  5.8162e-02, -1.1219e+00, -6.2333e-01,\n",
            "        -3.3107e-01,  7.5012e-01, -6.7730e-01, -4.1445e-01, -7.5833e-01,\n",
            "        -8.4015e-01, -4.3889e-01, -5.4896e-01,  5.6213e-01, -2.7193e-01,\n",
            "         5.5434e-01,  3.2267e-01, -3.7535e-01, -1.8180e-01,  1.2844e-01,\n",
            "        -6.4320e-02,  2.2975e-01, -5.6697e-02, -7.8373e-01, -8.5997e-01,\n",
            "         1.2499e+00, -9.8862e-01, -8.5828e-01, -8.8053e-01, -2.3784e-01,\n",
            "        -6.3371e-01,  2.2207e-01, -8.2293e-01, -1.8435e-01, -1.0496e-01,\n",
            "        -5.6178e-01,  8.7998e-02, -6.4329e-01,  4.4559e-01,  2.2543e-01,\n",
            "        -9.3294e-01, -1.2339e+00, -1.0136e-01,  3.3808e-02, -2.8590e-01,\n",
            "        -5.5794e-01, -3.7300e-01, -1.2832e-01, -6.5907e-01, -3.3152e-01,\n",
            "        -4.6926e-01, -1.0235e+00, -5.4187e-01, -1.4469e+00, -7.8282e-01,\n",
            "        -4.4456e-01,  5.5893e-01, -4.6904e-01, -6.8631e-01, -3.9330e-01,\n",
            "         1.6706e-01, -8.0440e-01, -7.8034e-01, -4.7902e-01, -6.2039e-01,\n",
            "        -7.2468e-01,  1.7471e-01, -3.6258e-01,  1.5631e-01, -2.9019e-01,\n",
            "        -8.2153e-01, -8.6072e-01,  6.3556e-04, -2.2015e-01,  4.2917e-01,\n",
            "        -1.5374e+00, -2.5475e-01, -7.9984e-01, -1.2684e+00, -8.4643e-01,\n",
            "        -2.3994e-01, -8.5655e-01,  5.2102e-01, -1.3979e+00,  4.0397e-01,\n",
            "        -1.3889e-01, -2.0761e-01, -3.8881e-01, -7.5622e-01, -1.1008e+00,\n",
            "        -6.2153e-01, -1.3564e-01, -5.8686e-02, -3.6553e-01, -6.2896e-01,\n",
            "        -2.6368e-01, -6.8154e-01, -5.2888e-01, -1.1370e-02,  1.2645e-01,\n",
            "         6.2976e-01, -5.0944e-01, -6.0883e-01,  1.8198e-01, -5.8183e-01,\n",
            "         6.3728e-01,  5.3835e-01, -3.4571e-01, -6.7649e-02, -6.1606e-01,\n",
            "        -8.2924e-01, -6.4347e-01, -2.7153e-01,  2.3054e-01, -2.9261e-01,\n",
            "        -4.8542e-01, -7.0368e-01,  8.4856e-01, -2.4750e-02, -3.6607e-01,\n",
            "        -7.8506e-01, -1.0994e+00, -9.1450e-01,  2.2769e-02, -7.7702e-01,\n",
            "         6.3451e-02, -3.2114e-01, -1.1597e+00,  1.7683e-01, -1.8203e-01,\n",
            "        -1.1331e+00, -8.4097e-01, -7.4968e-01, -8.0686e-01, -4.7420e-01,\n",
            "        -1.0531e+00, -7.1271e-01, -6.2525e-01,  2.2752e-01, -9.7076e-01,\n",
            "        -6.2167e-01, -4.4372e-01, -6.4414e-01, -1.0146e+00,  5.8847e-01,\n",
            "        -5.9513e-01, -1.7626e-01, -1.0791e+00, -7.3886e-01, -9.0812e-01,\n",
            "        -2.6963e-01, -4.3799e-02, -2.3653e-01, -1.3806e+00, -8.1989e-01,\n",
            "         1.0618e+00, -1.0619e-01,  2.1942e-01, -1.2699e+00,  6.7487e-01,\n",
            "        -8.5171e-01, -6.1582e-01, -5.8284e-02, -8.2210e-01, -9.1111e-01,\n",
            "        -3.4765e-01, -7.1723e-01, -5.5002e-01, -5.2880e-01, -8.6635e-01,\n",
            "        -4.6829e-01,  1.1980e-02, -3.4091e-01, -9.2318e-01, -1.1384e-01,\n",
            "         1.1398e-02, -4.7751e-01, -3.6345e-01, -9.2133e-01, -6.2515e-01,\n",
            "        -9.3854e-01, -5.0005e-02, -1.0498e+00, -7.3389e-01, -5.3408e-01,\n",
            "        -8.2797e-01, -2.7575e-01, -2.0691e-02, -6.5641e-01, -6.0763e-01,\n",
            "        -4.2909e-01, -8.2368e-04,  5.5313e-01, -9.3753e-01,  1.0704e-01,\n",
            "        -6.6109e-01, -6.0147e-01, -8.0227e-01, -2.5195e-01, -1.0071e+00,\n",
            "        -7.8619e-01, -4.4586e-01, -2.9200e-01, -1.7550e-01, -4.6564e-01,\n",
            "        -5.9590e-01,  2.7639e-02, -5.0548e-01, -2.7568e-02, -1.1359e+00,\n",
            "        -6.1003e-01,  4.2309e-02, -5.4985e-01, -4.4647e-01, -6.6001e-01,\n",
            "         2.9833e-01,  7.5344e-01, -7.1624e-01, -7.3630e-01, -2.1770e-01,\n",
            "        -1.1630e-02, -6.4513e-01, -7.5022e-01, -8.5824e-01, -4.9338e-01,\n",
            "        -6.9127e-01, -3.8555e-01, -6.4591e-01, -9.6864e-01, -1.3906e+00,\n",
            "        -1.0892e+00, -7.4351e-01, -1.7180e-01,  3.8129e-01, -8.0583e-01,\n",
            "        -4.4021e-01, -4.8235e-01, -1.1017e+00, -3.5106e-01, -1.1108e+00,\n",
            "        -6.5682e-01, -5.8795e-01, -3.3002e-01, -1.1386e-01, -2.5854e-01,\n",
            "        -5.9049e-01, -6.7267e-01, -2.6216e-01,  1.2461e+00, -7.5806e-01,\n",
            "         2.4138e-01, -1.1306e+00, -6.2947e-01, -4.5051e-01, -8.5616e-01],\n",
            "       device='cuda:0')), ('inception_block_8.b2.4.running_var', tensor([0.6591, 0.7568, 0.4982, 0.8201, 0.6509, 0.3524, 0.3826, 0.4459, 0.5923,\n",
            "        0.8636, 0.9345, 0.4567, 0.4625, 0.3457, 0.3057, 0.3305, 0.4743, 0.6050,\n",
            "        0.4580, 0.4307, 0.3614, 0.3402, 0.2980, 0.5735, 0.6644, 0.5787, 0.4248,\n",
            "        0.3536, 0.4417, 0.6150, 0.4327, 0.5219, 0.5853, 0.4109, 0.3159, 0.3564,\n",
            "        0.4750, 0.4175, 0.3641, 0.4618, 0.8413, 0.4583, 0.6502, 0.6889, 0.6329,\n",
            "        0.3786, 0.4081, 0.4427, 0.3649, 0.4334, 0.6906, 1.1033, 0.4778, 0.5012,\n",
            "        0.4745, 0.5667, 0.5087, 0.4761, 0.5063, 0.5145, 0.4367, 0.4121, 0.4307,\n",
            "        0.7755, 0.6054, 0.8623, 0.4957, 0.4425, 0.4417, 0.5366, 0.4392, 0.5641,\n",
            "        0.4236, 0.3735, 0.4161, 0.7639, 0.6278, 0.2894, 0.4782, 0.6224, 0.5703,\n",
            "        0.4434, 0.5292, 0.5325, 0.3960, 0.3199, 0.5173, 0.4409, 0.6556, 0.4612,\n",
            "        0.7612, 0.4880, 0.8000, 0.4938, 0.5116, 0.3696, 0.3174, 0.6047, 0.3389,\n",
            "        0.3889, 0.4112, 0.3415, 0.3507, 0.3635, 0.5289, 0.5093, 0.9280, 0.4687,\n",
            "        0.3948, 0.3902, 0.4440, 0.3558, 0.4184, 0.4415, 0.3985, 0.5454, 0.7012,\n",
            "        0.5641, 0.7008, 0.5049, 0.3591, 0.5567, 0.5330, 0.5703, 0.4449, 0.3969,\n",
            "        0.7974, 0.4490, 0.5323, 0.3368, 0.5281, 0.3921, 0.4949, 0.4594, 0.5350,\n",
            "        0.4969, 0.4572, 0.4250, 0.4173, 0.3853, 0.6729, 0.4576, 0.4339, 0.4272,\n",
            "        0.6830, 0.3989, 0.4489, 0.6107, 0.7200, 0.4350, 0.4025, 0.3459, 0.4743,\n",
            "        0.4979, 0.7275, 0.4999, 0.2950, 0.3698, 0.4854, 0.6594, 0.4412, 0.6741,\n",
            "        0.5244, 0.5207, 0.6229, 0.4716, 0.3662, 0.4789, 0.5481, 0.6010, 0.7258,\n",
            "        0.5198, 0.4791, 0.4469, 0.4892, 0.5598, 0.3774, 0.5719, 0.5999, 0.3980,\n",
            "        0.3777, 0.3575, 0.4705, 0.5603, 0.3963, 0.4916, 0.5594, 0.4946, 0.4311,\n",
            "        0.4783, 0.5103, 0.3188, 0.6279, 0.3605, 0.3403, 0.6920, 0.4349, 0.3343,\n",
            "        0.7039, 0.3535, 0.5082, 0.4890, 0.5633, 0.3944, 0.8345, 0.7569, 0.3648,\n",
            "        0.5357, 0.3549, 0.6573, 0.8082, 0.3823, 0.5669, 0.4873, 1.0561, 0.5181,\n",
            "        0.4901, 0.5016, 0.9615, 0.4714, 0.4301, 0.3194, 0.3448, 0.5026, 0.5688,\n",
            "        0.5136, 0.5292, 0.3352, 0.4830, 0.7947, 0.3804, 0.4875, 0.5903, 0.4170,\n",
            "        0.5790, 0.3991, 0.4817, 0.5218, 0.8654, 0.4273, 0.4641, 0.6437, 0.4446,\n",
            "        0.8553, 0.4403, 0.4997, 0.6065, 0.4755, 0.4089, 0.4312, 0.5287, 0.4625,\n",
            "        0.4531, 0.3730, 0.5043, 0.6508, 0.4031, 0.4275, 0.9941, 0.4126, 0.7349,\n",
            "        0.8058, 0.2947, 0.4203, 0.4678, 0.3746, 0.6011, 0.3526, 0.6382, 0.7735,\n",
            "        0.9108, 0.3518, 0.5049, 0.3534, 0.5155, 0.4745, 0.4286, 0.4771, 0.5350,\n",
            "        0.3507, 0.6352, 0.5853, 0.4356, 0.5075, 0.5923, 0.4113, 0.3902, 0.3384,\n",
            "        0.3026, 0.7670, 0.4514, 0.4661, 0.6390, 0.5864, 0.7924, 0.4801, 0.5701,\n",
            "        0.4631, 0.5020, 0.4843, 0.3834, 0.2815, 0.4062, 0.6256, 0.3869, 0.5520,\n",
            "        0.6082, 0.4970, 0.4068, 0.3968, 0.4111, 0.5957, 0.4169, 0.8840, 0.8897,\n",
            "        0.4416, 0.4856, 0.4872, 0.3366, 0.5297], device='cuda:0')), ('inception_block_8.b2.4.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_8.b3.0.weight', tensor([[[[ 0.0096]],\n",
            "\n",
            "         [[-0.0351]],\n",
            "\n",
            "         [[-0.0037]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0309]],\n",
            "\n",
            "         [[ 0.0288]],\n",
            "\n",
            "         [[ 0.0330]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0469]],\n",
            "\n",
            "         [[-0.0317]],\n",
            "\n",
            "         [[-0.0351]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0336]],\n",
            "\n",
            "         [[-0.0318]],\n",
            "\n",
            "         [[-0.0250]]],\n",
            "\n",
            "\n",
            "        [[[-0.0153]],\n",
            "\n",
            "         [[ 0.0230]],\n",
            "\n",
            "         [[-0.0164]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0129]],\n",
            "\n",
            "         [[-0.0194]],\n",
            "\n",
            "         [[ 0.0125]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0003]],\n",
            "\n",
            "         [[-0.0316]],\n",
            "\n",
            "         [[ 0.0064]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0293]],\n",
            "\n",
            "         [[ 0.0226]],\n",
            "\n",
            "         [[-0.0248]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0158]],\n",
            "\n",
            "         [[ 0.0042]],\n",
            "\n",
            "         [[-0.0211]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0404]],\n",
            "\n",
            "         [[ 0.0152]],\n",
            "\n",
            "         [[ 0.0094]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0121]],\n",
            "\n",
            "         [[ 0.0304]],\n",
            "\n",
            "         [[ 0.0333]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0155]],\n",
            "\n",
            "         [[ 0.0383]],\n",
            "\n",
            "         [[ 0.0028]]]], device='cuda:0')), ('inception_block_8.b3.0.bias', tensor([ 0.0250, -0.0089, -0.0106, -0.0160, -0.0162,  0.0123, -0.0242,  0.0061,\n",
            "         0.0255,  0.0006,  0.0185, -0.0103, -0.0089,  0.0300, -0.0293, -0.0166,\n",
            "         0.0047, -0.0277, -0.0064,  0.0068, -0.0107,  0.0125,  0.0128, -0.0088,\n",
            "         0.0052, -0.0177, -0.0263, -0.0010, -0.0322,  0.0279, -0.0171, -0.0034],\n",
            "       device='cuda:0')), ('inception_block_8.b3.1.weight', tensor([1.0011, 0.9988, 0.9981, 0.9938, 0.9959, 1.0013, 0.9987, 0.9975, 0.9961,\n",
            "        1.0060, 1.0045, 0.9988, 1.0160, 0.9976, 0.9930, 1.0036, 1.0030, 1.0041,\n",
            "        0.9868, 1.0062, 0.9993, 0.9978, 1.0099, 1.0093, 0.9928, 0.9934, 1.0018,\n",
            "        1.0064, 0.9960, 1.0161, 0.9868, 0.9962], device='cuda:0')), ('inception_block_8.b3.1.bias', tensor([-0.0097, -0.0073, -0.0067, -0.0141, -0.0077, -0.0081, -0.0135, -0.0174,\n",
            "        -0.0091,  0.0077,  0.0016, -0.0110,  0.0031, -0.0056, -0.0078, -0.0097,\n",
            "         0.0016, -0.0183, -0.0171, -0.0014, -0.0083, -0.0094, -0.0036, -0.0074,\n",
            "        -0.0040, -0.0096, -0.0002, -0.0025, -0.0062,  0.0029, -0.0146, -0.0117],\n",
            "       device='cuda:0')), ('inception_block_8.b3.1.running_mean', tensor([ 0.4828,  1.0299,  0.1458,  1.4687,  1.4075,  0.5382, -1.2651, -0.3975,\n",
            "         0.1420, -1.3986, -0.2906,  1.2517,  0.0131, -0.3303,  0.3911,  2.2805,\n",
            "         0.7657, -0.0236,  0.3552, -1.6808, -0.1175, -0.8368, -0.0798,  0.3515,\n",
            "         0.6128,  0.7641, -0.2152,  0.8015, -1.5664,  0.5279,  0.4633,  0.6460],\n",
            "       device='cuda:0')), ('inception_block_8.b3.1.running_var', tensor([0.6884, 0.5888, 0.6045, 0.7457, 0.9868, 0.6804, 0.5147, 0.5905, 1.0497,\n",
            "        0.8619, 0.4778, 0.5552, 0.8146, 0.5781, 0.6335, 1.1471, 0.6003, 0.5979,\n",
            "        0.7033, 1.1900, 0.4749, 0.6372, 0.8194, 0.6942, 0.5480, 0.7332, 1.0052,\n",
            "        0.7415, 0.6528, 0.5271, 0.7225, 0.9606], device='cuda:0')), ('inception_block_8.b3.1.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_8.b3.3.weight', tensor([[[[ 0.0135, -0.0131,  0.0162],\n",
            "          [ 0.0545, -0.0079,  0.0222],\n",
            "          [-0.0086, -0.0463, -0.0091]],\n",
            "\n",
            "         [[ 0.0469,  0.0538, -0.0314],\n",
            "          [ 0.0658,  0.0048, -0.0030],\n",
            "          [ 0.0265, -0.0167, -0.0364]],\n",
            "\n",
            "         [[ 0.0119, -0.0174, -0.0209],\n",
            "          [-0.0241, -0.0316,  0.0254],\n",
            "          [-0.0510,  0.0302, -0.0411]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0189, -0.0508,  0.0420],\n",
            "          [-0.0128, -0.0322,  0.0240],\n",
            "          [ 0.0083, -0.0056,  0.0360]],\n",
            "\n",
            "         [[ 0.0040, -0.0317,  0.0076],\n",
            "          [ 0.0573, -0.0391,  0.0544],\n",
            "          [ 0.0171, -0.0440, -0.0341]],\n",
            "\n",
            "         [[ 0.0241,  0.0407,  0.0034],\n",
            "          [ 0.0374, -0.0441, -0.0200],\n",
            "          [-0.0544, -0.0254, -0.0026]]],\n",
            "\n",
            "\n",
            "        [[[-0.0421,  0.0515, -0.0135],\n",
            "          [-0.0224, -0.0137,  0.0204],\n",
            "          [-0.0171,  0.0438, -0.0504]],\n",
            "\n",
            "         [[ 0.0012, -0.0269,  0.0078],\n",
            "          [ 0.0317, -0.0232, -0.0100],\n",
            "          [-0.0526,  0.0270, -0.0423]],\n",
            "\n",
            "         [[-0.0021, -0.0352, -0.0532],\n",
            "          [-0.0478, -0.0408,  0.0415],\n",
            "          [-0.0094,  0.0026, -0.0419]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0122, -0.0544,  0.0427],\n",
            "          [ 0.0278,  0.0128,  0.0520],\n",
            "          [ 0.0180, -0.0383,  0.0355]],\n",
            "\n",
            "         [[-0.0412, -0.0274,  0.0336],\n",
            "          [ 0.0515,  0.0280, -0.0091],\n",
            "          [ 0.0365,  0.0197,  0.0049]],\n",
            "\n",
            "         [[-0.0395, -0.0507,  0.0150],\n",
            "          [ 0.0482,  0.0392,  0.0460],\n",
            "          [ 0.0303,  0.0261,  0.0281]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0721, -0.0469, -0.0544],\n",
            "          [-0.0234, -0.0129, -0.0074],\n",
            "          [-0.0344,  0.0278, -0.0378]],\n",
            "\n",
            "         [[ 0.0226, -0.0489,  0.0463],\n",
            "          [ 0.0178, -0.0507, -0.0234],\n",
            "          [-0.0222,  0.0314,  0.0467]],\n",
            "\n",
            "         [[ 0.0380, -0.0083,  0.0384],\n",
            "          [ 0.0187, -0.0120, -0.0343],\n",
            "          [ 0.0275, -0.0022, -0.0107]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0628,  0.0605,  0.0029],\n",
            "          [ 0.0013, -0.0227,  0.0161],\n",
            "          [ 0.0033, -0.0406, -0.0633]],\n",
            "\n",
            "         [[ 0.0380,  0.0129, -0.0603],\n",
            "          [ 0.0121, -0.0546,  0.0245],\n",
            "          [ 0.0506,  0.0173, -0.0015]],\n",
            "\n",
            "         [[ 0.0471,  0.0170, -0.0471],\n",
            "          [-0.0071,  0.0296,  0.0098],\n",
            "          [ 0.0357,  0.0496, -0.0313]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0039,  0.0001, -0.0177],\n",
            "          [-0.0077,  0.0472,  0.0106],\n",
            "          [ 0.0011,  0.0430,  0.0020]],\n",
            "\n",
            "         [[-0.0419, -0.0196,  0.0428],\n",
            "          [ 0.0169,  0.0568,  0.0555],\n",
            "          [ 0.0398,  0.0050,  0.0164]],\n",
            "\n",
            "         [[ 0.0239,  0.0142, -0.0029],\n",
            "          [-0.0317,  0.0082,  0.0159],\n",
            "          [-0.0052, -0.0390,  0.0353]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0365, -0.0028,  0.0384],\n",
            "          [ 0.0228, -0.0485, -0.0276],\n",
            "          [-0.0030,  0.0224, -0.0199]],\n",
            "\n",
            "         [[-0.0455,  0.0060, -0.0171],\n",
            "          [-0.0408, -0.0412, -0.0245],\n",
            "          [-0.0427,  0.0118,  0.0411]],\n",
            "\n",
            "         [[ 0.0564, -0.0066,  0.0113],\n",
            "          [-0.0343, -0.0217, -0.0134],\n",
            "          [-0.0187,  0.0588,  0.0248]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0101,  0.0024,  0.0511],\n",
            "          [ 0.0274,  0.0471,  0.0480],\n",
            "          [-0.0327,  0.0086,  0.0170]],\n",
            "\n",
            "         [[-0.0335, -0.0489,  0.0074],\n",
            "          [ 0.0501, -0.0356, -0.0109],\n",
            "          [ 0.0557,  0.0234,  0.0326]],\n",
            "\n",
            "         [[-0.0290,  0.0291,  0.0028],\n",
            "          [-0.0211,  0.0560, -0.0060],\n",
            "          [-0.0239,  0.0466, -0.0294]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0365,  0.0274,  0.0395],\n",
            "          [-0.0067,  0.0312,  0.0522],\n",
            "          [-0.0093,  0.0189,  0.0464]],\n",
            "\n",
            "         [[-0.0198, -0.0058, -0.0428],\n",
            "          [-0.0328, -0.0457,  0.0403],\n",
            "          [ 0.0450, -0.0042, -0.0302]],\n",
            "\n",
            "         [[-0.0381, -0.0558,  0.0032],\n",
            "          [-0.0551, -0.0466,  0.0044],\n",
            "          [ 0.0372,  0.0502,  0.0632]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0192,  0.0543, -0.0034],\n",
            "          [-0.0306, -0.0257,  0.0253],\n",
            "          [-0.0553, -0.0489, -0.0049]],\n",
            "\n",
            "         [[-0.0031,  0.0138, -0.0234],\n",
            "          [ 0.0234, -0.0237,  0.0135],\n",
            "          [-0.0062, -0.0377,  0.0120]],\n",
            "\n",
            "         [[-0.0259, -0.0464,  0.0322],\n",
            "          [-0.0357, -0.0519,  0.0505],\n",
            "          [-0.0161,  0.0494, -0.0013]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0317,  0.0481,  0.0076],\n",
            "          [-0.0428,  0.0332,  0.0212],\n",
            "          [-0.0456, -0.0332, -0.0374]],\n",
            "\n",
            "         [[ 0.0266, -0.0200, -0.0372],\n",
            "          [ 0.0324, -0.0011,  0.0005],\n",
            "          [-0.0108, -0.0148, -0.0560]],\n",
            "\n",
            "         [[ 0.0554, -0.0305, -0.0061],\n",
            "          [-0.0532, -0.0312,  0.0257],\n",
            "          [-0.0569, -0.0249,  0.0343]]]], device='cuda:0')), ('inception_block_8.b3.3.bias', tensor([-0.0436,  0.0182, -0.0226, -0.0201, -0.0307,  0.0248,  0.0307,  0.0102,\n",
            "        -0.0487, -0.0090, -0.0089, -0.0330, -0.0120,  0.0504,  0.0455, -0.0077,\n",
            "         0.0011,  0.0142, -0.0017,  0.0355, -0.0533,  0.0297,  0.0436,  0.0524,\n",
            "        -0.0067,  0.0288, -0.0119,  0.0191, -0.0332, -0.0561,  0.0194, -0.0049,\n",
            "         0.0385, -0.0020,  0.0260,  0.0258,  0.0456, -0.0522, -0.0162,  0.0305,\n",
            "         0.0377, -0.0331, -0.0361,  0.0556, -0.0267,  0.0484, -0.0075,  0.0108,\n",
            "         0.0352, -0.0115, -0.0485, -0.0260, -0.0094,  0.0323, -0.0046,  0.0240,\n",
            "        -0.0373,  0.0410, -0.0224,  0.0452,  0.0236,  0.0049, -0.0365,  0.0404,\n",
            "        -0.0409,  0.0523,  0.0432,  0.0146,  0.0271,  0.0018, -0.0553,  0.0191,\n",
            "        -0.0329, -0.0477, -0.0501,  0.0589, -0.0454, -0.0329, -0.0005, -0.0371,\n",
            "         0.0026,  0.0274,  0.0365,  0.0348,  0.0207,  0.0203,  0.0475,  0.0094,\n",
            "        -0.0081,  0.0297,  0.0425, -0.0217,  0.0406, -0.0058,  0.0442,  0.0161,\n",
            "         0.0169,  0.0007,  0.0067,  0.0318,  0.0222, -0.0556, -0.0417,  0.0025,\n",
            "        -0.0504,  0.0504,  0.0304,  0.0042,  0.0057,  0.0432,  0.0561,  0.0349,\n",
            "         0.0139,  0.0499,  0.0046,  0.0516,  0.0115, -0.0553, -0.0122, -0.0377,\n",
            "         0.0202, -0.0434, -0.0582,  0.0341, -0.0018, -0.0141,  0.0589, -0.0043],\n",
            "       device='cuda:0')), ('inception_block_8.b3.4.weight', tensor([1.0163, 0.9929, 1.0007, 0.9943, 1.0040, 0.9911, 0.9953, 1.0092, 1.0002,\n",
            "        1.0054, 1.0046, 0.9994, 0.9970, 1.0076, 1.0019, 1.0051, 1.0009, 1.0030,\n",
            "        1.0018, 1.0069, 0.9937, 1.0018, 1.0040, 0.9922, 0.9976, 1.0131, 1.0049,\n",
            "        1.0057, 0.9935, 0.9938, 0.9830, 0.9957, 0.9993, 0.9921, 1.0021, 0.9961,\n",
            "        1.0032, 0.9954, 1.0039, 0.9892, 1.0042, 0.9872, 1.0108, 0.9889, 0.9945,\n",
            "        1.0073, 0.9991, 1.0012, 0.9959, 1.0071, 1.0074, 1.0070, 0.9998, 1.0098,\n",
            "        0.9984, 1.0001, 1.0079, 0.9943, 1.0012, 1.0041, 1.0013, 1.0092, 0.9895,\n",
            "        1.0035, 0.9981, 1.0009, 0.9834, 0.9954, 0.9945, 1.0028, 1.0035, 0.9935,\n",
            "        0.9978, 0.9982, 1.0055, 0.9863, 0.9963, 1.0103, 1.0040, 1.0082, 1.0075,\n",
            "        0.9871, 1.0032, 0.9977, 1.0041, 0.9964, 0.9924, 0.9901, 1.0146, 1.0013,\n",
            "        1.0005, 1.0037, 1.0013, 0.9851, 1.0103, 1.0007, 1.0131, 0.9916, 0.9859,\n",
            "        0.9951, 0.9857, 0.9952, 0.9983, 0.9975, 1.0041, 0.9894, 0.9971, 0.9925,\n",
            "        0.9898, 0.9935, 0.9903, 1.0010, 1.0158, 1.0125, 0.9920, 0.9933, 0.9998,\n",
            "        0.9928, 1.0051, 0.9941, 1.0164, 0.9980, 0.9992, 0.9975, 1.0026, 0.9924,\n",
            "        0.9994, 1.0064], device='cuda:0')), ('inception_block_8.b3.4.bias', tensor([ 0.0059, -0.0125, -0.0010, -0.0081,  0.0089, -0.0067, -0.0170, -0.0315,\n",
            "        -0.0042,  0.0040, -0.0077, -0.0078, -0.0035, -0.0075, -0.0131, -0.0085,\n",
            "        -0.0225, -0.0143, -0.0060, -0.0078,  0.0064, -0.0056, -0.0023, -0.0238,\n",
            "        -0.0095, -0.0082, -0.0024, -0.0080, -0.0131, -0.0124, -0.0093,  0.0012,\n",
            "         0.0001, -0.0041, -0.0039, -0.0011, -0.0075, -0.0028, -0.0045, -0.0139,\n",
            "        -0.0020, -0.0135, -0.0120, -0.0198, -0.0168,  0.0014, -0.0071, -0.0159,\n",
            "        -0.0187, -0.0089, -0.0012, -0.0078,  0.0015, -0.0090, -0.0087, -0.0165,\n",
            "        -0.0124, -0.0165, -0.0155, -0.0001, -0.0125, -0.0025, -0.0237, -0.0073,\n",
            "        -0.0096, -0.0232, -0.0106, -0.0106, -0.0138, -0.0130,  0.0006, -0.0126,\n",
            "        -0.0186, -0.0068, -0.0056, -0.0185, -0.0069,  0.0020, -0.0086, -0.0021,\n",
            "         0.0044, -0.0236, -0.0141, -0.0136, -0.0041, -0.0078, -0.0074, -0.0092,\n",
            "        -0.0037, -0.0147, -0.0121, -0.0043,  0.0051, -0.0124, -0.0161, -0.0205,\n",
            "         0.0047, -0.0104, -0.0157, -0.0157, -0.0161, -0.0156, -0.0092, -0.0020,\n",
            "        -0.0081, -0.0085, -0.0062, -0.0092, -0.0119, -0.0031, -0.0037, -0.0089,\n",
            "         0.0010, -0.0088, -0.0231, -0.0128, -0.0079, -0.0043, -0.0082, -0.0053,\n",
            "        -0.0118, -0.0065, -0.0133, -0.0156, -0.0043, -0.0176, -0.0213, -0.0037],\n",
            "       device='cuda:0')), ('inception_block_8.b3.4.running_mean', tensor([-0.1632,  0.0571,  0.0551,  0.1360, -0.1458, -0.3502, -0.0408,  0.0851,\n",
            "        -0.3631, -0.1636, -0.1581, -0.0445, -0.4718, -0.1954, -0.1838, -0.0494,\n",
            "         0.0569,  0.0180,  0.1636, -0.1161, -0.2109, -0.2036, -0.0558,  0.2966,\n",
            "         0.0392, -0.0445, -0.0566, -0.0032, -0.0443,  0.2457, -0.2590, -0.6670,\n",
            "         0.1347, -0.3765, -0.0582,  0.0675, -0.0124, -0.1591, -0.2692, -0.4038,\n",
            "         0.1447, -0.3646, -0.1813, -0.0957,  0.3372,  0.0112, -0.0916,  0.3071,\n",
            "         0.0253,  0.2605, -0.1661, -0.1341, -0.1801, -0.1617, -0.3963, -0.1360,\n",
            "        -0.0901,  0.3908, -0.0341,  0.0595, -0.3456,  0.2944,  0.3247,  0.0297,\n",
            "        -0.0655,  0.5878, -0.0656, -0.1789,  0.1003,  0.0675, -0.0659, -0.2068,\n",
            "        -0.1699, -0.1468, -0.1248,  0.0164,  0.0978, -0.3508,  0.0147, -0.0544,\n",
            "         0.2085,  0.1475, -0.1794, -0.0377, -0.1373, -0.0912, -0.3252,  0.3418,\n",
            "        -0.0948,  0.2451, -0.2150, -0.1415, -0.2954, -0.1279,  0.0438, -0.0287,\n",
            "        -0.2381, -0.4004,  0.1152,  0.4159,  0.0217,  0.0537, -0.1017, -0.0422,\n",
            "        -0.3746, -0.2261, -0.2076, -0.0298,  0.1284, -0.0947, -0.2550, -0.0434,\n",
            "         0.0302,  0.2672,  0.2712, -0.3227, -0.0482, -0.3121, -0.2077, -0.0951,\n",
            "        -0.0679,  0.2034, -0.0311,  0.3334, -0.0716,  0.3430,  0.1549, -0.1555],\n",
            "       device='cuda:0')), ('inception_block_8.b3.4.running_var', tensor([0.1688, 0.1346, 0.1439, 0.2348, 0.1186, 0.1495, 0.1917, 0.1223, 0.1579,\n",
            "        0.1510, 0.2001, 0.1332, 0.2787, 0.1293, 0.1312, 0.1541, 0.0899, 0.1346,\n",
            "        0.1005, 0.1294, 0.2324, 0.1331, 0.1070, 0.1625, 0.1462, 0.1646, 0.1196,\n",
            "        0.1257, 0.1697, 0.1732, 0.2354, 0.2343, 0.2078, 0.1379, 0.1784, 0.1726,\n",
            "        0.1529, 0.1429, 0.1746, 0.2273, 0.1666, 0.1414, 0.1405, 0.1485, 0.2095,\n",
            "        0.1230, 0.1449, 0.1346, 0.2591, 0.1546, 0.1283, 0.1248, 0.2153, 0.1327,\n",
            "        0.2358, 0.1347, 0.1898, 0.1853, 0.1553, 0.1029, 0.1596, 0.1593, 0.2462,\n",
            "        0.1037, 0.1394, 0.2581, 0.1255, 0.1068, 0.1502, 0.1388, 0.2294, 0.1945,\n",
            "        0.2066, 0.1230, 0.1447, 0.1318, 0.1402, 0.2399, 0.1550, 0.1659, 0.1437,\n",
            "        0.1811, 0.1669, 0.1613, 0.2289, 0.1101, 0.1781, 0.2011, 0.1893, 0.1194,\n",
            "        0.1505, 0.1109, 0.1541, 0.2072, 0.1471, 0.1488, 0.1758, 0.2453, 0.1440,\n",
            "        0.1385, 0.1184, 0.1433, 0.1772, 0.1708, 0.1266, 0.2165, 0.2184, 0.1570,\n",
            "        0.1310, 0.1137, 0.1611, 0.1273, 0.1951, 0.1126, 0.1900, 0.2421, 0.1545,\n",
            "        0.2114, 0.0818, 0.1432, 0.1602, 0.1172, 0.1713, 0.1595, 0.1332, 0.1391,\n",
            "        0.2668, 0.1709], device='cuda:0')), ('inception_block_8.b3.4.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_8.b3.6.weight', tensor([[[[ 0.0050, -0.0072, -0.0044],\n",
            "          [ 0.0092,  0.0245,  0.0312],\n",
            "          [ 0.0340,  0.0372,  0.0017]],\n",
            "\n",
            "         [[-0.0072, -0.0207, -0.0088],\n",
            "          [-0.0147,  0.0189,  0.0244],\n",
            "          [ 0.0281,  0.0123, -0.0079]],\n",
            "\n",
            "         [[ 0.0145,  0.0382,  0.0429],\n",
            "          [-0.0027,  0.0360,  0.0251],\n",
            "          [-0.0109, -0.0011,  0.0338]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0219, -0.0103,  0.0222],\n",
            "          [ 0.0300,  0.0161, -0.0171],\n",
            "          [ 0.0012,  0.0271, -0.0271]],\n",
            "\n",
            "         [[ 0.0246, -0.0229, -0.0180],\n",
            "          [ 0.0257, -0.0071,  0.0100],\n",
            "          [ 0.0148,  0.0161,  0.0002]],\n",
            "\n",
            "         [[-0.0222,  0.0318, -0.0183],\n",
            "          [ 0.0216, -0.0205,  0.0116],\n",
            "          [ 0.0201,  0.0317,  0.0399]]],\n",
            "\n",
            "\n",
            "        [[[-0.0020, -0.0177, -0.0046],\n",
            "          [ 0.0020,  0.0041, -0.0354],\n",
            "          [-0.0174,  0.0250, -0.0119]],\n",
            "\n",
            "         [[-0.0298,  0.0198,  0.0164],\n",
            "          [ 0.0051,  0.0222, -0.0077],\n",
            "          [-0.0177,  0.0021, -0.0305]],\n",
            "\n",
            "         [[-0.0028,  0.0191,  0.0309],\n",
            "          [-0.0162,  0.0314, -0.0264],\n",
            "          [ 0.0273,  0.0174,  0.0046]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0164,  0.0324, -0.0232],\n",
            "          [-0.0231, -0.0228,  0.0040],\n",
            "          [-0.0240, -0.0218, -0.0114]],\n",
            "\n",
            "         [[-0.0322, -0.0189, -0.0100],\n",
            "          [-0.0095, -0.0248, -0.0323],\n",
            "          [ 0.0197,  0.0072, -0.0004]],\n",
            "\n",
            "         [[-0.0169,  0.0138,  0.0305],\n",
            "          [-0.0097,  0.0154, -0.0147],\n",
            "          [-0.0095,  0.0007,  0.0290]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0407,  0.0178,  0.0035],\n",
            "          [ 0.0226, -0.0099,  0.0437],\n",
            "          [-0.0143,  0.0129,  0.0418]],\n",
            "\n",
            "         [[-0.0334, -0.0203, -0.0174],\n",
            "          [-0.0298,  0.0191, -0.0265],\n",
            "          [-0.0375, -0.0334, -0.0235]],\n",
            "\n",
            "         [[-0.0074, -0.0073,  0.0163],\n",
            "          [ 0.0025, -0.0096,  0.0179],\n",
            "          [-0.0086, -0.0084, -0.0012]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0029,  0.0033, -0.0204],\n",
            "          [-0.0147,  0.0138, -0.0088],\n",
            "          [ 0.0113, -0.0247, -0.0103]],\n",
            "\n",
            "         [[ 0.0069, -0.0055, -0.0151],\n",
            "          [ 0.0019, -0.0187,  0.0090],\n",
            "          [-0.0173, -0.0006,  0.0068]],\n",
            "\n",
            "         [[ 0.0133, -0.0261,  0.0308],\n",
            "          [ 0.0180,  0.0146,  0.0217],\n",
            "          [-0.0076,  0.0118,  0.0108]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0138, -0.0011, -0.0214],\n",
            "          [-0.0262,  0.0013, -0.0167],\n",
            "          [-0.0091, -0.0002, -0.0181]],\n",
            "\n",
            "         [[ 0.0186,  0.0006,  0.0292],\n",
            "          [ 0.0242, -0.0007, -0.0299],\n",
            "          [-0.0131,  0.0134,  0.0058]],\n",
            "\n",
            "         [[ 0.0031, -0.0106, -0.0161],\n",
            "          [-0.0164, -0.0313, -0.0236],\n",
            "          [-0.0252, -0.0223, -0.0124]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0009,  0.0087, -0.0152],\n",
            "          [ 0.0047, -0.0108,  0.0209],\n",
            "          [-0.0177, -0.0146, -0.0118]],\n",
            "\n",
            "         [[ 0.0047, -0.0046, -0.0051],\n",
            "          [ 0.0316, -0.0167, -0.0029],\n",
            "          [ 0.0336,  0.0281,  0.0150]],\n",
            "\n",
            "         [[ 0.0076,  0.0141,  0.0046],\n",
            "          [ 0.0244, -0.0087,  0.0057],\n",
            "          [ 0.0170,  0.0132,  0.0059]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0116, -0.0377, -0.0136],\n",
            "          [ 0.0116, -0.0052,  0.0135],\n",
            "          [-0.0003, -0.0331,  0.0031]],\n",
            "\n",
            "         [[ 0.0144, -0.0199,  0.0016],\n",
            "          [ 0.0282,  0.0198,  0.0026],\n",
            "          [ 0.0101,  0.0206,  0.0378]],\n",
            "\n",
            "         [[-0.0025, -0.0008,  0.0196],\n",
            "          [-0.0218, -0.0003,  0.0139],\n",
            "          [-0.0358,  0.0088, -0.0043]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0130,  0.0146,  0.0183],\n",
            "          [-0.0160,  0.0070,  0.0091],\n",
            "          [-0.0349, -0.0100,  0.0004]],\n",
            "\n",
            "         [[-0.0353,  0.0164,  0.0167],\n",
            "          [-0.0265, -0.0295,  0.0241],\n",
            "          [ 0.0140, -0.0259, -0.0149]],\n",
            "\n",
            "         [[ 0.0171, -0.0084, -0.0366],\n",
            "          [-0.0385, -0.0223, -0.0010],\n",
            "          [-0.0133, -0.0271, -0.0328]]],\n",
            "\n",
            "\n",
            "        [[[-0.0338, -0.0177, -0.0205],\n",
            "          [-0.0184, -0.0334, -0.0173],\n",
            "          [-0.0149, -0.0060,  0.0066]],\n",
            "\n",
            "         [[ 0.0134, -0.0201, -0.0170],\n",
            "          [-0.0254, -0.0081, -0.0304],\n",
            "          [-0.0279,  0.0054,  0.0175]],\n",
            "\n",
            "         [[ 0.0201, -0.0102, -0.0185],\n",
            "          [-0.0045,  0.0233, -0.0245],\n",
            "          [-0.0127,  0.0147,  0.0048]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0206,  0.0033, -0.0225],\n",
            "          [ 0.0254, -0.0211, -0.0272],\n",
            "          [ 0.0011,  0.0149,  0.0150]],\n",
            "\n",
            "         [[-0.0124, -0.0096, -0.0041],\n",
            "          [ 0.0179,  0.0209,  0.0181],\n",
            "          [ 0.0065, -0.0079, -0.0066]],\n",
            "\n",
            "         [[ 0.0104,  0.0023,  0.0263],\n",
            "          [-0.0027,  0.0151, -0.0031],\n",
            "          [ 0.0294,  0.0222, -0.0146]]]], device='cuda:0')), ('inception_block_8.b3.6.bias', tensor([-0.0235,  0.0163, -0.0294,  0.0277, -0.0026, -0.0149,  0.0038,  0.0274,\n",
            "         0.0205,  0.0086,  0.0101, -0.0079, -0.0125, -0.0063,  0.0254,  0.0034,\n",
            "        -0.0126,  0.0278, -0.0231, -0.0255,  0.0056, -0.0097,  0.0282,  0.0137,\n",
            "        -0.0080,  0.0276, -0.0148,  0.0268,  0.0151, -0.0117, -0.0197, -0.0235,\n",
            "         0.0145, -0.0265,  0.0056, -0.0147, -0.0217,  0.0293, -0.0191,  0.0062,\n",
            "         0.0082,  0.0122,  0.0212,  0.0159,  0.0040, -0.0294, -0.0085,  0.0183,\n",
            "        -0.0155,  0.0067, -0.0290, -0.0260,  0.0130,  0.0285,  0.0075,  0.0181,\n",
            "         0.0210,  0.0294, -0.0051,  0.0252,  0.0083,  0.0275, -0.0050, -0.0175,\n",
            "        -0.0050,  0.0239, -0.0025, -0.0167, -0.0286, -0.0168, -0.0071,  0.0226,\n",
            "         0.0012, -0.0286,  0.0126, -0.0058,  0.0078,  0.0264, -0.0279,  0.0154,\n",
            "        -0.0203, -0.0167, -0.0264, -0.0027,  0.0158,  0.0094,  0.0046,  0.0272,\n",
            "         0.0081,  0.0091, -0.0266, -0.0225,  0.0066, -0.0218,  0.0177, -0.0177,\n",
            "         0.0197,  0.0094,  0.0083, -0.0085,  0.0030,  0.0066,  0.0164,  0.0002,\n",
            "         0.0195,  0.0166, -0.0258,  0.0105,  0.0094, -0.0141, -0.0278,  0.0148,\n",
            "        -0.0264,  0.0013,  0.0022,  0.0055, -0.0100,  0.0290,  0.0046, -0.0250,\n",
            "        -0.0022,  0.0170,  0.0236,  0.0107,  0.0120,  0.0037, -0.0170,  0.0161],\n",
            "       device='cuda:0')), ('inception_block_8.b3.7.weight', tensor([1.0035, 1.0147, 0.9983, 1.0008, 0.9860, 1.0034, 1.0146, 1.0037, 0.9990,\n",
            "        0.9976, 1.0036, 0.9974, 1.0091, 0.9947, 1.0030, 0.9975, 1.0013, 1.0159,\n",
            "        1.0098, 1.0116, 1.0048, 0.9875, 0.9819, 1.0026, 1.0121, 1.0076, 1.0166,\n",
            "        1.0176, 1.0058, 0.9984, 0.9978, 0.9955, 1.0003, 1.0068, 1.0082, 0.9963,\n",
            "        1.0061, 1.0065, 1.0020, 1.0058, 1.0047, 1.0061, 0.9997, 1.0108, 0.9951,\n",
            "        0.9904, 1.0032, 0.9961, 1.0051, 1.0086, 1.0018, 1.0036, 1.0089, 1.0107,\n",
            "        1.0075, 0.9976, 1.0012, 1.0073, 1.0110, 1.0096, 1.0048, 1.0016, 0.9893,\n",
            "        1.0012, 1.0131, 0.9955, 0.9975, 1.0071, 1.0022, 1.0021, 1.0066, 0.9989,\n",
            "        0.9980, 1.0082, 1.0039, 1.0074, 1.0098, 0.9896, 0.9996, 0.9979, 0.9981,\n",
            "        1.0054, 0.9914, 0.9897, 1.0009, 1.0153, 1.0003, 1.0062, 0.9938, 0.9980,\n",
            "        1.0017, 1.0082, 0.9940, 0.9953, 1.0155, 1.0116, 0.9971, 1.0087, 1.0209,\n",
            "        1.0088, 0.9971, 1.0127, 0.9942, 0.9982, 0.9959, 0.9923, 1.0132, 0.9990,\n",
            "        1.0114, 1.0126, 0.9937, 0.9950, 1.0129, 1.0077, 1.0056, 1.0109, 1.0030,\n",
            "        1.0000, 1.0059, 1.0027, 1.0014, 1.0067, 1.0068, 1.0161, 1.0171, 0.9887,\n",
            "        1.0039, 1.0036], device='cuda:0')), ('inception_block_8.b3.7.bias', tensor([-0.0149, -0.0136, -0.0080, -0.0047, -0.0211, -0.0071, -0.0161, -0.0063,\n",
            "        -0.0134, -0.0115, -0.0101,  0.0004, -0.0065, -0.0083,  0.0097, -0.0125,\n",
            "        -0.0131, -0.0154, -0.0048, -0.0147, -0.0067, -0.0129, -0.0148, -0.0144,\n",
            "         0.0044, -0.0172, -0.0044, -0.0145, -0.0099, -0.0128, -0.0022, -0.0115,\n",
            "        -0.0100, -0.0087, -0.0050, -0.0107, -0.0119, -0.0238, -0.0146, -0.0103,\n",
            "        -0.0005, -0.0158, -0.0084, -0.0120, -0.0070, -0.0082, -0.0088, -0.0002,\n",
            "        -0.0119, -0.0163, -0.0116, -0.0017, -0.0059, -0.0138, -0.0024, -0.0149,\n",
            "        -0.0079,  0.0062, -0.0095,  0.0010, -0.0043, -0.0108, -0.0164, -0.0118,\n",
            "        -0.0174, -0.0147, -0.0160, -0.0149,  0.0022, -0.0125, -0.0178, -0.0076,\n",
            "        -0.0067, -0.0129, -0.0170, -0.0005, -0.0175, -0.0174, -0.0056, -0.0172,\n",
            "        -0.0275, -0.0123, -0.0154, -0.0140, -0.0143,  0.0005, -0.0157, -0.0094,\n",
            "        -0.0171, -0.0064, -0.0093, -0.0062, -0.0146, -0.0006, -0.0165, -0.0159,\n",
            "        -0.0113, -0.0023, -0.0081,  0.0004, -0.0054, -0.0071, -0.0067, -0.0180,\n",
            "        -0.0183, -0.0078, -0.0068, -0.0109, -0.0151, -0.0161, -0.0233, -0.0174,\n",
            "        -0.0146, -0.0160,  0.0049, -0.0047,  0.0011, -0.0183, -0.0099, -0.0042,\n",
            "        -0.0208, -0.0061, -0.0018, -0.0010, -0.0047, -0.0200,  0.0013, -0.0022],\n",
            "       device='cuda:0')), ('inception_block_8.b3.7.running_mean', tensor([ 0.3590, -0.2410, -0.1752, -0.8249,  0.0269, -0.7831, -0.1739, -0.6693,\n",
            "         0.0529, -0.6886, -0.6598, -0.8120,  0.1626, -0.3378, -0.1548,  0.5575,\n",
            "        -0.5326,  0.0180, -0.1237, -0.2737, -0.2598, -0.3557, -0.5176, -0.3920,\n",
            "         0.6181,  0.1735, -0.5761,  0.0660,  0.1676,  0.1674, -0.4796,  0.5575,\n",
            "        -0.1665, -0.3288, -0.0654, -0.8026, -0.2513, -0.1669,  0.0287, -0.1756,\n",
            "         0.2721, -0.3127, -0.0941, -0.2046, -0.0729, -0.5581, -0.3509, -1.2527,\n",
            "         0.6954,  0.0347, -0.0716, -0.6458, -0.2724, -0.3331, -0.4447, -0.8617,\n",
            "         0.1143,  0.2409,  0.0369, -0.8224, -0.0051, -0.0223, -0.5315,  0.0161,\n",
            "         0.2415, -0.2350,  0.0311, -0.4931,  0.2451, -0.2301, -0.3326, -0.3538,\n",
            "        -0.5161,  0.0440,  0.4777, -0.4148,  0.0310, -0.6629,  0.0874, -0.3034,\n",
            "        -0.0290, -0.6216, -0.2844, -0.2524, -0.1026, -0.5257, -0.2252, -0.4227,\n",
            "        -0.6573, -0.2906, -0.1868, -0.4572, -0.1880, -0.4545, -0.6884, -0.5180,\n",
            "        -0.4324, -0.1252, -0.6689, -0.7754, -0.7099, -0.3067, -0.1469, -0.6647,\n",
            "        -0.4224, -0.4080, -0.5267,  1.0408, -0.2362, -0.4193,  0.4885,  0.2334,\n",
            "         0.3990,  0.0462, -1.0847, -0.6558, -0.2101, -0.3501, -0.0167, -0.4645,\n",
            "        -0.1909, -0.2271, -0.5465, -0.4441, -0.1458,  0.1918,  0.1902, -0.3273],\n",
            "       device='cuda:0')), ('inception_block_8.b3.7.running_var', tensor([0.3896, 0.2252, 0.5775, 0.2676, 0.2549, 0.3994, 0.2707, 0.1946, 0.3423,\n",
            "        0.4246, 0.2847, 0.5731, 0.2203, 0.2844, 0.2577, 0.2892, 0.3754, 0.3427,\n",
            "        0.3445, 0.3465, 0.3094, 0.3688, 0.2711, 0.3098, 0.3043, 0.2917, 0.3543,\n",
            "        0.3266, 0.3724, 0.3506, 0.3023, 0.3250, 0.2593, 0.2398, 0.4107, 0.2511,\n",
            "        0.2032, 0.2299, 0.2405, 0.1956, 0.3074, 0.2988, 0.3054, 0.2752, 0.4283,\n",
            "        0.3727, 0.2588, 0.3334, 0.2956, 0.2421, 0.2864, 0.3957, 0.2241, 0.2963,\n",
            "        0.3473, 0.2914, 0.3161, 0.4200, 0.2712, 0.5455, 0.2747, 0.4599, 0.2884,\n",
            "        0.2763, 0.2768, 0.3950, 0.2638, 0.2698, 0.3672, 0.2276, 0.2592, 0.2389,\n",
            "        0.3166, 0.2853, 0.2606, 0.2828, 0.3652, 0.4251, 0.2453, 0.2458, 0.2264,\n",
            "        0.2644, 0.3583, 0.3007, 0.3385, 0.2203, 0.3098, 0.2689, 0.3713, 0.3695,\n",
            "        0.2732, 0.4768, 0.2697, 0.4123, 0.3709, 0.4059, 0.4625, 0.3447, 0.2887,\n",
            "        0.4419, 0.4647, 0.2415, 0.3897, 0.3632, 0.2661, 0.3852, 0.3763, 0.3547,\n",
            "        0.3108, 0.4548, 0.4970, 0.3702, 0.2739, 0.4103, 0.3631, 0.2152, 0.3140,\n",
            "        0.2805, 0.3655, 0.2905, 0.2403, 0.3391, 0.4507, 0.2581, 0.3100, 0.3185,\n",
            "        0.5790, 0.3937], device='cuda:0')), ('inception_block_8.b3.7.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_8.b4.1.weight', tensor([[[[-7.2298e-03]],\n",
            "\n",
            "         [[ 2.1975e-02]],\n",
            "\n",
            "         [[ 1.7258e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.1607e-03]],\n",
            "\n",
            "         [[-1.4875e-02]],\n",
            "\n",
            "         [[-2.9553e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.2229e-02]],\n",
            "\n",
            "         [[-2.6658e-02]],\n",
            "\n",
            "         [[ 2.9194e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0629e-02]],\n",
            "\n",
            "         [[-1.9425e-03]],\n",
            "\n",
            "         [[ 1.2021e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4234e-02]],\n",
            "\n",
            "         [[ 1.8458e-03]],\n",
            "\n",
            "         [[-3.1106e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.8802e-03]],\n",
            "\n",
            "         [[-4.6556e-03]],\n",
            "\n",
            "         [[ 1.8839e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.9826e-02]],\n",
            "\n",
            "         [[ 1.4320e-02]],\n",
            "\n",
            "         [[ 3.2320e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4252e-02]],\n",
            "\n",
            "         [[ 1.1709e-02]],\n",
            "\n",
            "         [[-2.8241e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0059e-02]],\n",
            "\n",
            "         [[-1.7981e-02]],\n",
            "\n",
            "         [[-2.3781e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.8877e-03]],\n",
            "\n",
            "         [[ 3.2206e-02]],\n",
            "\n",
            "         [[ 3.5041e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.1055e-03]],\n",
            "\n",
            "         [[-1.7271e-02]],\n",
            "\n",
            "         [[-2.1262e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3878e-02]],\n",
            "\n",
            "         [[ 7.7339e-03]],\n",
            "\n",
            "         [[ 1.2496e-02]]]], device='cuda:0')), ('inception_block_8.b4.1.bias', tensor([ 0.0227,  0.0195,  0.0074, -0.0126, -0.0020, -0.0189, -0.0052, -0.0231,\n",
            "        -0.0174,  0.0163,  0.0141, -0.0232, -0.0164, -0.0154, -0.0297, -0.0115,\n",
            "        -0.0142, -0.0218,  0.0028, -0.0312,  0.0129, -0.0051, -0.0306,  0.0103,\n",
            "        -0.0154, -0.0340, -0.0148, -0.0171, -0.0205,  0.0062, -0.0216, -0.0203,\n",
            "        -0.0045, -0.0099,  0.0032,  0.0096,  0.0018, -0.0021,  0.0292, -0.0175,\n",
            "        -0.0286,  0.0153,  0.0185,  0.0282, -0.0202,  0.0206, -0.0257,  0.0067,\n",
            "         0.0126,  0.0002, -0.0212,  0.0125, -0.0277,  0.0126,  0.0261, -0.0036,\n",
            "        -0.0330,  0.0306, -0.0260, -0.0297, -0.0117, -0.0255,  0.0062, -0.0144,\n",
            "        -0.0036,  0.0300,  0.0214, -0.0181,  0.0177,  0.0198, -0.0302, -0.0106,\n",
            "        -0.0044,  0.0187,  0.0316,  0.0239, -0.0163,  0.0037, -0.0336,  0.0213,\n",
            "        -0.0235,  0.0137,  0.0011, -0.0211,  0.0292,  0.0338, -0.0217, -0.0285,\n",
            "         0.0234, -0.0327,  0.0178, -0.0311, -0.0166, -0.0164,  0.0253, -0.0095,\n",
            "         0.0224,  0.0103, -0.0157, -0.0261, -0.0098,  0.0195, -0.0319, -0.0312,\n",
            "        -0.0297,  0.0054, -0.0197, -0.0277,  0.0196,  0.0094, -0.0282, -0.0322,\n",
            "         0.0334,  0.0060, -0.0179, -0.0188,  0.0188,  0.0106,  0.0332, -0.0255,\n",
            "        -0.0127,  0.0029, -0.0241, -0.0325,  0.0156,  0.0187,  0.0231,  0.0077],\n",
            "       device='cuda:0')), ('inception_block_8.b4.2.weight', tensor([1.0065, 1.0189, 1.0226, 1.0078, 0.9937, 1.0183, 1.0136, 1.0167, 1.0301,\n",
            "        1.0034, 0.9920, 1.0169, 1.0216, 1.0058, 1.0335, 1.0322, 1.0168, 1.0139,\n",
            "        1.0055, 1.0260, 0.9967, 1.0093, 1.0195, 1.0074, 1.0246, 1.0056, 1.0149,\n",
            "        0.9999, 1.0268, 1.0036, 1.0199, 0.9999, 1.0101, 1.0041, 1.0230, 1.0034,\n",
            "        1.0081, 1.0069, 1.0168, 1.0092, 1.0218, 1.0125, 1.0275, 1.0150, 0.9900,\n",
            "        1.0051, 1.0223, 1.0228, 1.0290, 1.0225, 1.0196, 1.0346, 1.0094, 1.0110,\n",
            "        1.0109, 1.0210, 1.0105, 1.0146, 1.0325, 1.0242, 1.0079, 1.0212, 1.0140,\n",
            "        1.0132, 1.0101, 1.0196, 1.0301, 1.0152, 1.0204, 1.0045, 1.0167, 1.0006,\n",
            "        1.0229, 1.0098, 1.0163, 1.0263, 1.0336, 1.0343, 1.0181, 1.0095, 1.0272,\n",
            "        1.0163, 1.0122, 1.0198, 0.9985, 1.0240, 1.0203, 1.0089, 1.0141, 0.9965,\n",
            "        1.0213, 0.9916, 1.0029, 1.0142, 1.0436, 1.0312, 1.0147, 1.0265, 1.0215,\n",
            "        1.0148, 1.0202, 1.0148, 1.0190, 1.0231, 1.0126, 1.0187, 1.0268, 1.0151,\n",
            "        1.0273, 1.0104, 1.0328, 1.0164, 1.0169, 1.0322, 1.0028, 1.0220, 1.0239,\n",
            "        1.0307, 0.9961, 1.0037, 1.0049, 1.0157, 0.9946, 1.0201, 1.0087, 1.0093,\n",
            "        1.0238, 1.0233], device='cuda:0')), ('inception_block_8.b4.2.bias', tensor([ 8.4641e-03, -1.4772e-02, -4.7863e-03, -8.1939e-03,  1.3841e-03,\n",
            "         9.8059e-03,  6.6516e-04,  1.2849e-05,  7.5165e-03,  6.4924e-03,\n",
            "        -5.8258e-03, -1.2888e-02,  1.1607e-04, -3.3934e-03,  1.2951e-02,\n",
            "         1.3573e-02,  9.5856e-03, -1.1381e-03,  1.2369e-03,  9.7692e-03,\n",
            "        -2.6784e-03, -2.1515e-03,  4.8082e-03, -1.3710e-02,  7.5996e-03,\n",
            "        -8.5753e-04,  1.0526e-03, -1.7078e-03,  8.3223e-03, -1.9163e-02,\n",
            "         1.6703e-03, -3.6363e-03, -1.3859e-04, -3.4239e-02,  7.1613e-03,\n",
            "         3.7512e-03,  1.9417e-03, -2.1699e-03,  7.3591e-03,  6.6251e-03,\n",
            "         9.2165e-03,  8.7243e-03,  1.0968e-02, -6.2863e-03, -1.0334e-02,\n",
            "        -4.4792e-03,  5.1172e-05,  3.6845e-03, -5.6904e-04,  5.7410e-03,\n",
            "         1.7280e-04,  1.0338e-02,  2.1826e-04, -5.4477e-04, -6.7666e-03,\n",
            "         2.3942e-03,  8.8160e-03, -4.9226e-03,  1.5757e-02,  1.0497e-02,\n",
            "         1.5513e-04,  4.8883e-03,  2.8081e-03,  5.6622e-03, -8.9015e-03,\n",
            "         4.4183e-03,  7.8402e-03,  1.2328e-03,  8.3206e-04,  2.1395e-03,\n",
            "        -2.8291e-03, -1.5964e-02, -4.7905e-03, -4.1787e-03,  6.1521e-03,\n",
            "         3.0317e-03,  4.7374e-03,  1.0162e-02,  1.8646e-03,  4.6419e-03,\n",
            "         7.2520e-03,  1.0228e-03,  5.5526e-03,  5.0124e-03,  7.8258e-04,\n",
            "        -1.5094e-03, -5.3725e-03, -3.1517e-03,  9.8567e-04,  5.8983e-03,\n",
            "        -1.3735e-03, -5.0919e-03, -8.0628e-03,  1.0762e-02,  7.8935e-03,\n",
            "         9.3556e-03, -1.8296e-03, -4.1129e-03,  2.5466e-03, -1.7117e-03,\n",
            "        -1.3699e-03, -5.4326e-03,  6.5762e-03,  1.2221e-03,  5.3366e-04,\n",
            "        -3.3046e-03,  1.4598e-02,  4.9825e-03, -7.2524e-04, -2.8867e-03,\n",
            "         1.2194e-02, -6.8901e-04,  6.0566e-03,  2.0988e-02, -5.3809e-03,\n",
            "        -1.2345e-03,  4.7255e-03,  1.9076e-03, -3.1563e-03, -3.4562e-03,\n",
            "        -2.9912e-03, -9.2537e-03, -1.0045e-03,  6.2430e-03,  3.7318e-03,\n",
            "        -1.6069e-03,  8.9375e-03,  1.3161e-02], device='cuda:0')), ('inception_block_8.b4.2.running_mean', tensor([-3.0488,  0.1115,  0.2814, -0.5154, -1.5210, -1.3016,  0.5652,  0.4193,\n",
            "         0.9761, -3.5469,  0.4123,  1.7483,  0.9677,  0.8001,  1.2314,  1.3664,\n",
            "         1.2102,  0.6836, -0.6157,  0.4475, -1.2853,  1.7447,  0.1249,  0.4473,\n",
            "         0.0051,  1.3258,  0.5796, -0.7521,  0.8617,  1.6951,  0.2474, -0.1032,\n",
            "         1.3844,  1.0073, -0.3566, -2.7730,  0.5516, -1.3535,  0.4014, -1.1755,\n",
            "        -0.1580, -0.0648,  0.8971,  1.3538, -0.1908, -0.8174,  2.0897,  0.6566,\n",
            "         1.2840,  1.0323, -0.8517,  0.4497,  1.1712, -0.5546, -0.1171,  1.1350,\n",
            "        -1.0196, -0.0734,  0.9296, -0.1798,  0.8809, -0.5363, -1.0420, -2.4849,\n",
            "         1.2528,  0.4512,  0.5746, -0.5121,  0.0111, -0.7944, -1.1682,  0.1410,\n",
            "         0.7215,  1.3110, -0.1279,  0.3732,  0.6358,  0.8706,  1.2602,  1.2330,\n",
            "        -0.4453, -1.2630, -0.0962,  0.7518, -3.1597,  1.8565,  0.4188,  1.3227,\n",
            "         1.3057, -1.6327,  0.7826, -1.2619,  1.1733,  1.6618,  1.4666,  0.5298,\n",
            "         1.3956,  0.6686,  0.1266,  0.3193, -0.1967,  1.4286,  0.8601,  1.2659,\n",
            "         0.6615,  1.9121,  0.6705, -0.4794,  1.2710,  1.0709,  1.1037, -0.3539,\n",
            "         1.5550,  1.2992, -0.0225,  1.5579,  1.1734,  0.2870, -0.9960,  2.0231,\n",
            "        -1.2275,  1.5999, -0.7623, -0.4932,  0.6965,  0.2710,  0.6865, -0.4917],\n",
            "       device='cuda:0')), ('inception_block_8.b4.2.running_var', tensor([0.4708, 0.3430, 0.2950, 0.2805, 0.7024, 0.4023, 0.3187, 0.2791, 0.2455,\n",
            "        1.1500, 0.5478, 0.3007, 0.2345, 0.3512, 0.3164, 0.2944, 0.3637, 0.3188,\n",
            "        0.4220, 0.2238, 0.5359, 0.3548, 0.2969, 0.5603, 0.3802, 0.4575, 0.3334,\n",
            "        0.6759, 0.2184, 0.3443, 0.2758, 0.4078, 0.3735, 0.3462, 0.4318, 0.9263,\n",
            "        0.4008, 0.5158, 0.3400, 0.6269, 0.4395, 0.3784, 0.3202, 0.2916, 0.3761,\n",
            "        0.4962, 0.2676, 0.2130, 0.2936, 0.4105, 0.4361, 0.2165, 0.3983, 0.4173,\n",
            "        0.2925, 0.3573, 0.3745, 0.3337, 0.3427, 0.3283, 0.5147, 0.2807, 0.4102,\n",
            "        0.6721, 0.3965, 0.3074, 0.2417, 0.2366, 0.2726, 0.4250, 0.4000, 0.3297,\n",
            "        0.2768, 0.3415, 0.3546, 0.2043, 0.2370, 0.2573, 0.3425, 0.5197, 0.3264,\n",
            "        0.4032, 0.4114, 0.3099, 0.7081, 0.2314, 0.3468, 0.4672, 0.2808, 0.3143,\n",
            "        0.2789, 0.3686, 0.2420, 0.3625, 0.2611, 0.2516, 0.3659, 0.2942, 0.3418,\n",
            "        0.5050, 0.2570, 0.4131, 0.3146, 0.3705, 0.3324, 0.5784, 0.2950, 0.4853,\n",
            "        0.2784, 0.4389, 0.2947, 0.2831, 0.4097, 0.3247, 0.2975, 0.4334, 0.2842,\n",
            "        0.2679, 0.5256, 0.3468, 0.4546, 0.3476, 0.4857, 0.2862, 0.3164, 0.3379,\n",
            "        0.3054, 0.2925], device='cuda:0')), ('inception_block_8.b4.2.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_9.b1.0.weight', tensor([[[[-0.0037]],\n",
            "\n",
            "         [[-0.0221]],\n",
            "\n",
            "         [[-0.0208]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0241]],\n",
            "\n",
            "         [[-0.0198]],\n",
            "\n",
            "         [[-0.0236]]],\n",
            "\n",
            "\n",
            "        [[[-0.0212]],\n",
            "\n",
            "         [[ 0.0216]],\n",
            "\n",
            "         [[ 0.0351]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0263]],\n",
            "\n",
            "         [[ 0.0054]],\n",
            "\n",
            "         [[ 0.0027]]],\n",
            "\n",
            "\n",
            "        [[[-0.0155]],\n",
            "\n",
            "         [[ 0.0153]],\n",
            "\n",
            "         [[ 0.0280]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0128]],\n",
            "\n",
            "         [[-0.0200]],\n",
            "\n",
            "         [[ 0.0284]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0161]],\n",
            "\n",
            "         [[ 0.0242]],\n",
            "\n",
            "         [[ 0.0101]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0200]],\n",
            "\n",
            "         [[-0.0200]],\n",
            "\n",
            "         [[-0.0136]]],\n",
            "\n",
            "\n",
            "        [[[-0.0093]],\n",
            "\n",
            "         [[-0.0318]],\n",
            "\n",
            "         [[ 0.0133]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0167]],\n",
            "\n",
            "         [[ 0.0137]],\n",
            "\n",
            "         [[ 0.0354]]],\n",
            "\n",
            "\n",
            "        [[[-0.0074]],\n",
            "\n",
            "         [[-0.0326]],\n",
            "\n",
            "         [[ 0.0202]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0104]],\n",
            "\n",
            "         [[-0.0221]],\n",
            "\n",
            "         [[-0.0212]]]], device='cuda:0')), ('inception_block_9.b1.0.bias', tensor([ 4.9880e-03,  1.9090e-02,  2.2090e-02, -2.5946e-02,  2.3040e-02,\n",
            "        -2.3900e-02, -2.0214e-02,  3.0530e-03, -1.6648e-02,  1.4900e-03,\n",
            "         5.2442e-03, -2.8267e-02,  3.3517e-02, -1.2571e-02, -5.6968e-03,\n",
            "        -9.1813e-03, -8.3791e-03, -5.3797e-03, -1.4060e-03, -2.7027e-02,\n",
            "        -8.4609e-03, -1.0422e-02,  9.6678e-03,  3.4447e-03, -1.6348e-02,\n",
            "        -1.8345e-02,  2.9432e-02, -2.0774e-02,  2.8385e-02, -1.7222e-02,\n",
            "        -5.7468e-04,  6.5303e-03,  9.8580e-03, -8.9922e-05, -4.9025e-03,\n",
            "        -3.0214e-02,  3.3627e-02, -2.7722e-02,  2.9642e-02, -2.4853e-02,\n",
            "         6.6628e-03,  1.9338e-02, -1.3573e-02,  1.3080e-02, -3.5151e-03,\n",
            "        -1.7499e-02, -2.4652e-03, -1.3451e-02, -2.6236e-02,  2.2779e-03,\n",
            "         9.5951e-03, -1.4545e-03, -3.4677e-02, -9.9278e-03,  3.2525e-02,\n",
            "         3.0230e-02, -3.0409e-02, -3.2928e-02,  4.2474e-03, -1.7056e-02,\n",
            "        -1.8538e-02, -1.1549e-02, -1.5197e-02,  1.2621e-02, -1.9539e-02,\n",
            "        -8.0830e-03, -5.4413e-03,  9.4324e-03, -2.3213e-02, -1.3507e-02,\n",
            "        -1.3187e-02, -1.6298e-02,  2.3462e-02, -3.2453e-02,  1.8181e-03,\n",
            "         2.1512e-02, -2.0402e-02, -1.3497e-02, -1.4126e-02, -1.8549e-02,\n",
            "        -1.1714e-02, -3.4741e-02, -3.8222e-03, -3.7492e-03, -3.3650e-02,\n",
            "         6.9585e-03, -3.0313e-02, -3.6983e-03,  1.1679e-02,  1.6022e-02,\n",
            "         1.5093e-02,  1.0754e-03,  2.4976e-02,  1.6452e-02,  7.1119e-03,\n",
            "         1.8157e-02,  6.9459e-03, -3.3915e-02, -2.1745e-02,  1.7146e-02,\n",
            "         2.6576e-02,  2.8289e-02, -2.9813e-02,  2.2096e-02, -2.3105e-02,\n",
            "         1.2364e-02, -2.1437e-02, -3.4452e-02,  1.2469e-04, -2.4667e-02,\n",
            "        -2.9489e-02,  1.8747e-03,  7.8611e-03, -6.6369e-03, -2.6920e-02,\n",
            "         2.3871e-02, -2.9050e-02,  9.5844e-03,  1.4977e-02, -8.3561e-03,\n",
            "         4.8183e-03,  4.7082e-03,  8.9873e-05,  8.6079e-03, -1.0720e-02,\n",
            "        -2.3718e-02,  3.0486e-02,  5.2623e-03,  1.1271e-02, -2.5708e-02,\n",
            "         2.1311e-02, -2.7418e-02,  2.6262e-02, -3.1878e-02,  6.9377e-03,\n",
            "        -2.1312e-02, -1.1094e-02,  2.3446e-02, -2.4107e-03,  2.3887e-02,\n",
            "        -3.0653e-02,  2.1247e-03,  1.0129e-02,  2.2670e-02, -1.2519e-02,\n",
            "         2.1820e-02, -2.7580e-02,  6.6003e-03, -8.8832e-03, -4.5603e-04,\n",
            "         4.1685e-03, -2.6835e-02,  2.4246e-02,  2.0726e-02, -1.9449e-02,\n",
            "        -6.9076e-03, -2.1544e-02,  1.4250e-02,  2.2249e-03,  2.4264e-02,\n",
            "        -3.3971e-02,  1.9097e-02,  2.4632e-02, -2.8623e-02,  3.1173e-02,\n",
            "         1.7583e-02,  1.6219e-02,  2.2978e-03, -8.0975e-03,  2.8575e-02,\n",
            "        -5.2454e-05,  2.1684e-02, -2.4381e-02, -1.5189e-03,  3.4560e-02,\n",
            "         2.6000e-02, -2.4960e-02, -3.3837e-02,  3.1075e-02,  2.5388e-02,\n",
            "         3.1532e-02,  3.6060e-03,  2.2159e-02, -1.9566e-02, -3.2592e-02,\n",
            "         1.3618e-02, -3.1718e-02, -1.1080e-02,  1.7089e-02, -1.1859e-02,\n",
            "         2.7035e-02, -1.1069e-02, -1.7863e-02,  2.0397e-02, -1.3391e-02,\n",
            "         3.3816e-02, -3.9052e-03,  1.5334e-02, -1.4412e-02,  1.0680e-02,\n",
            "         1.4763e-02,  1.3045e-02, -3.0030e-02, -3.3722e-02, -1.9762e-02,\n",
            "         1.7745e-02, -3.1947e-02, -2.6347e-02, -1.8142e-02, -1.3029e-02,\n",
            "         7.9220e-03,  1.5485e-03, -1.9910e-02, -2.0732e-02,  7.8127e-03,\n",
            "        -3.3094e-02,  4.0332e-03,  2.5516e-02, -9.9445e-03,  3.3545e-02,\n",
            "        -2.1447e-02, -2.1395e-02,  6.8309e-03,  1.7827e-03,  2.1863e-02,\n",
            "         2.1103e-02,  8.2271e-03,  1.9701e-02, -5.8653e-03, -7.6545e-03,\n",
            "        -6.4989e-03,  4.1307e-03,  2.8998e-03, -5.8438e-03,  1.1061e-02,\n",
            "        -5.4341e-03, -4.6641e-03,  1.1045e-02, -1.9130e-02, -2.4697e-02,\n",
            "        -1.3779e-02,  6.4582e-03, -9.6071e-03, -1.2409e-02, -1.6566e-02,\n",
            "        -1.5036e-02,  2.6267e-02,  4.6886e-03, -9.8062e-03, -3.9923e-03,\n",
            "        -3.0032e-02, -3.0687e-02, -6.7831e-03,  1.8974e-02,  4.2398e-03,\n",
            "        -3.3044e-02,  1.2566e-02, -2.4554e-02,  2.2861e-02, -1.8048e-02,\n",
            "        -2.2349e-02, -2.0889e-02,  2.4038e-02, -3.0469e-02, -3.0762e-02,\n",
            "        -1.6093e-02,  3.3644e-02, -9.9753e-03, -3.1495e-02,  2.8181e-02,\n",
            "         2.3960e-02, -3.2732e-02,  1.9228e-03,  1.3633e-02, -1.7474e-04,\n",
            "         1.6740e-02,  2.8530e-02,  3.4256e-02, -3.3504e-02,  5.2397e-03,\n",
            "         1.8880e-02, -1.3956e-02, -1.2347e-02,  4.6102e-03,  5.9126e-03,\n",
            "         5.1077e-03, -1.0297e-02, -3.4467e-02,  1.2476e-02, -1.8477e-02,\n",
            "         2.8720e-02, -7.8279e-03, -6.6095e-03, -1.0212e-02,  2.5033e-02,\n",
            "         2.3655e-02, -3.1794e-03, -3.4481e-03, -4.1454e-03,  1.6871e-02,\n",
            "         2.0001e-02,  1.3596e-02,  2.3449e-02, -3.3514e-02, -1.2715e-02,\n",
            "         2.1259e-02,  2.7299e-03,  7.2476e-04,  6.0878e-03, -2.3524e-03,\n",
            "        -9.7961e-03,  3.0354e-02, -1.0906e-02,  1.2750e-02,  8.3417e-03,\n",
            "         2.7074e-03, -3.2949e-02,  3.3329e-04, -2.7804e-02, -2.2605e-03,\n",
            "         1.2303e-02, -8.8820e-03, -2.9756e-02, -1.1950e-02,  8.0531e-03,\n",
            "         1.9038e-02, -3.1721e-02, -9.4708e-03, -2.8731e-02, -2.3078e-02,\n",
            "        -2.6814e-03, -5.6845e-03,  3.3304e-02,  2.8215e-02,  9.5540e-04,\n",
            "         1.1352e-02,  8.1298e-03, -3.0078e-02, -2.5922e-02,  6.3137e-03,\n",
            "         2.5790e-02, -3.2344e-02, -2.8439e-02, -4.5651e-03,  2.7280e-02,\n",
            "         1.3685e-03, -1.2728e-02, -6.9667e-03,  2.8180e-02, -2.8276e-02,\n",
            "         1.6017e-02, -1.5115e-02,  1.5982e-02,  2.6073e-02,  3.0165e-02,\n",
            "         2.0788e-02,  7.3450e-03, -2.0252e-03,  3.4225e-02, -1.4457e-02,\n",
            "        -1.2167e-04, -2.7752e-02, -3.0060e-02, -2.9337e-03, -2.8480e-02,\n",
            "         1.0219e-02, -2.4685e-02, -3.2255e-02, -1.3838e-02, -2.5196e-02,\n",
            "         1.3517e-02,  1.7964e-02,  2.4497e-02,  1.8162e-02,  2.9520e-04,\n",
            "         4.9453e-03, -1.2634e-02, -3.0073e-04, -1.7492e-02,  6.5734e-03,\n",
            "        -9.2027e-03, -3.0877e-02, -2.0709e-02, -1.1826e-02], device='cuda:0')), ('inception_block_9.b1.1.weight', tensor([1.0461, 1.0370, 1.0463, 1.0324, 1.0197, 1.0245, 1.0246, 1.0436, 1.0265,\n",
            "        1.0411, 1.0244, 1.0385, 1.0323, 1.0273, 1.0337, 1.0333, 1.0171, 1.0316,\n",
            "        1.0206, 1.0288, 1.0331, 1.0336, 1.0434, 1.0246, 1.0268, 1.0313, 1.0324,\n",
            "        1.0436, 1.0215, 1.0365, 1.0134, 1.0271, 1.0250, 1.0385, 1.0235, 1.0287,\n",
            "        1.0326, 1.0276, 1.0489, 1.0235, 1.0261, 1.0326, 1.0311, 1.0253, 1.0293,\n",
            "        1.0452, 1.0353, 1.0293, 1.0327, 1.0195, 1.0430, 1.0313, 1.0304, 1.0440,\n",
            "        1.0396, 1.0159, 1.0165, 1.0407, 1.0207, 1.0223, 1.0396, 1.0270, 1.0338,\n",
            "        1.0299, 1.0418, 1.0270, 1.0329, 1.0355, 1.0343, 1.0231, 1.0259, 1.0282,\n",
            "        1.0417, 1.0356, 1.0238, 1.0270, 1.0215, 1.0318, 1.0297, 1.0303, 1.0261,\n",
            "        1.0399, 1.0301, 1.0419, 1.0405, 1.0277, 1.0266, 1.0281, 1.0293, 1.0360,\n",
            "        1.0194, 1.0233, 1.0263, 1.0396, 1.0286, 1.0406, 1.0260, 1.0254, 1.0255,\n",
            "        1.0336, 1.0352, 1.0280, 1.0338, 1.0224, 1.0306, 1.0324, 1.0284, 1.0306,\n",
            "        1.0572, 1.0382, 1.0344, 1.0511, 1.0321, 1.0352, 1.0276, 1.0393, 1.0440,\n",
            "        1.0432, 1.0292, 1.0363, 1.0277, 1.0289, 1.0360, 1.0389, 1.0333, 1.0313,\n",
            "        1.0345, 1.0256, 1.0320, 1.0312, 1.0227, 1.0443, 1.0291, 1.0357, 1.0377,\n",
            "        1.0467, 1.0286, 1.0280, 1.0246, 1.0287, 1.0305, 1.0354, 1.0409, 1.0253,\n",
            "        1.0354, 1.0343, 1.0289, 1.0282, 1.0224, 1.0293, 1.0300, 1.0452, 1.0425,\n",
            "        1.0275, 1.0267, 1.0268, 1.0265, 1.0285, 1.0280, 1.0293, 1.0275, 1.0519,\n",
            "        1.0454, 1.0314, 1.0392, 1.0349, 1.0236, 1.0291, 1.0244, 1.0336, 1.0346,\n",
            "        1.0249, 1.0202, 1.0196, 1.0286, 1.0273, 1.0252, 1.0425, 1.0269, 1.0280,\n",
            "        1.0459, 1.0329, 1.0216, 1.0337, 1.0214, 1.0290, 1.0296, 1.0248, 1.0213,\n",
            "        1.0248, 1.0397, 1.0266, 1.0297, 1.0218, 1.0305, 1.0357, 1.0277, 1.0250,\n",
            "        1.0383, 1.0228, 1.0284, 1.0288, 1.0236, 1.0262, 1.0295, 1.0493, 1.0187,\n",
            "        1.0215, 1.0230, 1.0391, 1.0291, 1.0255, 1.0327, 1.0206, 1.0336, 1.0312,\n",
            "        1.0348, 1.0538, 1.0471, 1.0246, 1.0308, 1.0307, 1.0291, 1.0269, 1.0375,\n",
            "        1.0318, 1.0549, 1.0330, 1.0276, 1.0272, 1.0261, 1.0310, 1.0552, 1.0364,\n",
            "        1.0423, 1.0338, 1.0508, 1.0290, 1.0412, 1.0240, 1.0378, 1.0398, 1.0377,\n",
            "        1.0233, 1.0242, 1.0232, 1.0248, 1.0328, 1.0236, 1.0518, 1.0312, 1.0370,\n",
            "        1.0261, 1.0359, 1.0317, 1.0301, 1.0174, 1.0291, 1.0370, 1.0311, 1.0366,\n",
            "        1.0329, 1.0320, 1.0304, 1.0389, 1.0459, 1.0358, 1.0179, 1.0297, 1.0392,\n",
            "        1.0205, 1.0209, 1.0185, 1.0243, 1.0348, 1.0374, 1.0373, 1.0338, 1.0297,\n",
            "        1.0318, 1.0327, 1.0292, 1.0434, 1.0298, 1.0389, 1.0270, 1.0389, 1.0261,\n",
            "        1.0479, 1.0306, 1.0251, 1.0406, 1.0264, 1.0341, 1.0273, 1.0457, 1.0336,\n",
            "        1.0258, 1.0331, 1.0326, 1.0332, 1.0253, 1.0334, 1.0329, 1.0263, 1.0286,\n",
            "        1.0386, 1.0213, 1.0261, 1.0260, 1.0243, 1.0336, 1.0268, 1.0323, 1.0428,\n",
            "        1.0338, 1.0309, 1.0354, 1.0338, 1.0174, 1.0306, 1.0480, 1.0322, 1.0445,\n",
            "        1.0180, 1.0507, 1.0367, 1.0288, 1.0234, 1.0371, 1.0306, 1.0254, 1.0272,\n",
            "        1.0315, 1.0228, 1.0332, 1.0423, 1.0397, 1.0284, 1.0208, 1.0405, 1.0217,\n",
            "        1.0356, 1.0348, 1.0331, 1.0271, 1.0269, 1.0255, 1.0257, 1.0321, 1.0148,\n",
            "        1.0281, 1.0307, 1.0469, 1.0313, 1.0273, 1.0256, 1.0182, 1.0271, 1.0346,\n",
            "        1.0329, 1.0403, 1.0370, 1.0208, 1.0241, 1.0225, 1.0280, 1.0269, 1.0265,\n",
            "        1.0253, 1.0272, 1.0334, 1.0397, 1.0203, 1.0310, 1.0270, 1.0337, 1.0255,\n",
            "        1.0309, 1.0254, 1.0359, 1.0385, 1.0356, 1.0278], device='cuda:0')), ('inception_block_9.b1.1.bias', tensor([0.0184, 0.0219, 0.0298, 0.0142, 0.0071, 0.0093, 0.0123, 0.0225, 0.0138,\n",
            "        0.0158, 0.0088, 0.0220, 0.0177, 0.0110, 0.0186, 0.0162, 0.0082, 0.0157,\n",
            "        0.0055, 0.0146, 0.0154, 0.0113, 0.0162, 0.0115, 0.0122, 0.0129, 0.0192,\n",
            "        0.0184, 0.0096, 0.0179, 0.0041, 0.0107, 0.0132, 0.0130, 0.0154, 0.0151,\n",
            "        0.0207, 0.0133, 0.0281, 0.0123, 0.0151, 0.0130, 0.0200, 0.0088, 0.0140,\n",
            "        0.0249, 0.0208, 0.0112, 0.0166, 0.0122, 0.0180, 0.0186, 0.0203, 0.0200,\n",
            "        0.0284, 0.0089, 0.0030, 0.0273, 0.0125, 0.0075, 0.0147, 0.0119, 0.0121,\n",
            "        0.0150, 0.0273, 0.0163, 0.0185, 0.0162, 0.0131, 0.0144, 0.0142, 0.0118,\n",
            "        0.0202, 0.0215, 0.0077, 0.0116, 0.0095, 0.0178, 0.0185, 0.0185, 0.0117,\n",
            "        0.0147, 0.0130, 0.0226, 0.0185, 0.0114, 0.0141, 0.0112, 0.0116, 0.0177,\n",
            "        0.0112, 0.0146, 0.0112, 0.0165, 0.0146, 0.0229, 0.0144, 0.0105, 0.0144,\n",
            "        0.0219, 0.0141, 0.0102, 0.0163, 0.0135, 0.0102, 0.0163, 0.0110, 0.0127,\n",
            "        0.0310, 0.0276, 0.0160, 0.0238, 0.0167, 0.0236, 0.0151, 0.0170, 0.0214,\n",
            "        0.0280, 0.0181, 0.0168, 0.0172, 0.0101, 0.0169, 0.0240, 0.0137, 0.0142,\n",
            "        0.0139, 0.0132, 0.0165, 0.0181, 0.0105, 0.0255, 0.0117, 0.0221, 0.0217,\n",
            "        0.0235, 0.0147, 0.0169, 0.0149, 0.0166, 0.0143, 0.0157, 0.0182, 0.0098,\n",
            "        0.0130, 0.0180, 0.0160, 0.0093, 0.0125, 0.0139, 0.0135, 0.0245, 0.0190,\n",
            "        0.0159, 0.0141, 0.0160, 0.0094, 0.0145, 0.0126, 0.0184, 0.0133, 0.0305,\n",
            "        0.0204, 0.0158, 0.0186, 0.0180, 0.0127, 0.0123, 0.0131, 0.0211, 0.0166,\n",
            "        0.0059, 0.0040, 0.0049, 0.0150, 0.0092, 0.0096, 0.0229, 0.0122, 0.0107,\n",
            "        0.0192, 0.0128, 0.0095, 0.0154, 0.0098, 0.0175, 0.0119, 0.0123, 0.0094,\n",
            "        0.0128, 0.0261, 0.0133, 0.0150, 0.0079, 0.0166, 0.0226, 0.0121, 0.0146,\n",
            "        0.0119, 0.0048, 0.0166, 0.0120, 0.0104, 0.0139, 0.0173, 0.0266, 0.0102,\n",
            "        0.0081, 0.0052, 0.0162, 0.0136, 0.0119, 0.0164, 0.0159, 0.0114, 0.0147,\n",
            "        0.0108, 0.0260, 0.0291, 0.0099, 0.0107, 0.0131, 0.0139, 0.0103, 0.0164,\n",
            "        0.0102, 0.0268, 0.0168, 0.0118, 0.0145, 0.0143, 0.0156, 0.0228, 0.0194,\n",
            "        0.0234, 0.0200, 0.0270, 0.0105, 0.0129, 0.0161, 0.0237, 0.0209, 0.0184,\n",
            "        0.0135, 0.0095, 0.0146, 0.0065, 0.0142, 0.0099, 0.0270, 0.0108, 0.0221,\n",
            "        0.0089, 0.0159, 0.0159, 0.0165, 0.0085, 0.0105, 0.0188, 0.0147, 0.0189,\n",
            "        0.0175, 0.0207, 0.0132, 0.0279, 0.0207, 0.0140, 0.0097, 0.0123, 0.0172,\n",
            "        0.0116, 0.0101, 0.0085, 0.0093, 0.0142, 0.0235, 0.0184, 0.0164, 0.0124,\n",
            "        0.0159, 0.0133, 0.0129, 0.0213, 0.0154, 0.0169, 0.0112, 0.0167, 0.0108,\n",
            "        0.0269, 0.0136, 0.0096, 0.0163, 0.0108, 0.0140, 0.0144, 0.0294, 0.0129,\n",
            "        0.0131, 0.0130, 0.0195, 0.0176, 0.0100, 0.0134, 0.0166, 0.0133, 0.0146,\n",
            "        0.0212, 0.0084, 0.0091, 0.0139, 0.0100, 0.0189, 0.0150, 0.0178, 0.0254,\n",
            "        0.0186, 0.0148, 0.0169, 0.0192, 0.0051, 0.0119, 0.0252, 0.0227, 0.0194,\n",
            "        0.0084, 0.0266, 0.0184, 0.0148, 0.0046, 0.0142, 0.0143, 0.0135, 0.0161,\n",
            "        0.0127, 0.0122, 0.0153, 0.0220, 0.0214, 0.0140, 0.0116, 0.0141, 0.0081,\n",
            "        0.0161, 0.0170, 0.0181, 0.0158, 0.0146, 0.0117, 0.0171, 0.0149, 0.0051,\n",
            "        0.0136, 0.0101, 0.0226, 0.0193, 0.0136, 0.0082, 0.0069, 0.0089, 0.0137,\n",
            "        0.0164, 0.0206, 0.0189, 0.0084, 0.0110, 0.0097, 0.0093, 0.0113, 0.0107,\n",
            "        0.0117, 0.0083, 0.0121, 0.0151, 0.0087, 0.0182, 0.0099, 0.0157, 0.0074,\n",
            "        0.0135, 0.0148, 0.0163, 0.0180, 0.0126, 0.0152], device='cuda:0')), ('inception_block_9.b1.1.running_mean', tensor([-0.0253, -0.3596, -0.1846, -0.4374,  0.2060, -0.3033, -0.2063, -0.4711,\n",
            "        -0.0917,  0.1487, -0.3221, -0.0948, -0.0403,  0.1312, -0.1825, -0.4545,\n",
            "        -0.4394, -0.1987,  0.3242, -0.2294, -0.3230, -0.0612, -0.0075, -0.3321,\n",
            "        -0.2502,  0.0558,  0.2676, -0.3300,  0.0167, -0.2742, -0.1465, -0.1625,\n",
            "        -0.0297,  0.1533, -0.0119, -0.0694, -0.1958, -0.4445, -0.2804, -0.0676,\n",
            "        -0.0165, -0.2326, -0.1301, -0.0702, -0.4233, -0.5816,  0.2378,  0.0630,\n",
            "        -0.1855, -0.3282, -0.2962, -0.4818, -0.0422, -0.3569, -0.1918,  0.0014,\n",
            "        -0.1904, -0.2750,  0.0867,  0.1990,  0.0542,  0.0658,  0.3249, -0.0661,\n",
            "        -0.6175, -0.4784,  0.0877, -0.2536,  0.0061, -0.0876,  0.1711, -0.3782,\n",
            "        -0.0428,  0.0924,  0.1852,  0.0871, -0.0247, -0.5020, -0.1093, -0.5263,\n",
            "        -0.2828, -0.1277, -0.3384,  0.0570,  0.0260, -0.4040,  0.0615, -0.4506,\n",
            "        -0.2748, -0.2873,  0.0855, -0.1489, -0.2102, -0.2478, -0.1858, -0.1418,\n",
            "        -0.1162, -0.2712,  0.1680, -0.1314,  0.2219,  0.0572, -0.2482,  0.0147,\n",
            "         0.2117, -0.0571, -0.2938, -0.0280, -0.4075, -0.1942, -0.0582, -0.2053,\n",
            "        -0.1129, -0.2672, -0.2144,  0.0450, -0.3278, -0.0820, -0.3695, -0.3640,\n",
            "         0.2155,  0.0307,  0.2082,  0.1001, -0.1505, -0.3335, -0.1285, -0.3125,\n",
            "        -0.0529, -0.3351, -0.6762, -0.4932,  0.1317,  0.0439, -0.4582, -0.3832,\n",
            "        -0.1973, -0.0555,  0.1078,  0.0127, -0.0637, -0.0349,  0.0243, -0.1028,\n",
            "         0.3917, -0.1155, -0.0313, -0.1368, -0.2035, -0.3794, -0.2929, -0.4479,\n",
            "        -0.1979, -0.0763, -0.4317, -0.3052, -0.4368,  0.2930, -0.2644,  0.0589,\n",
            "        -0.7265, -0.4541, -0.1179, -0.3936,  0.2197, -0.1431, -0.1360, -0.0759,\n",
            "         0.3335, -0.0141,  0.0079,  0.1439, -0.2188, -0.1649, -0.2645, -0.2472,\n",
            "         0.1066, -0.3254,  0.0906,  0.2275, -0.2742, -0.4409,  0.0856,  0.0853,\n",
            "        -0.2222, -0.1168, -0.2709, -0.0325,  0.1754, -0.0424, -0.0351, -0.1766,\n",
            "        -0.4902,  0.3641, -0.3682, -0.1803, -0.1672,  0.0106, -0.2976,  0.4271,\n",
            "        -0.4665, -0.1107, -0.1021,  0.1121,  0.3200,  0.0982, -0.4172, -0.0409,\n",
            "        -0.0711, -0.2159,  0.0287, -0.2086,  0.0222, -0.2006,  0.0049, -0.5516,\n",
            "        -0.0417, -0.4817, -0.2755, -0.4170,  0.0902, -0.0272,  0.1359,  0.0950,\n",
            "         0.0356,  0.5030, -0.2125, -0.2474, -0.4963, -0.0846, -0.4205,  0.1072,\n",
            "         0.2538, -0.0961, -0.2187, -0.2588, -0.0715,  0.2494,  0.0434,  0.1086,\n",
            "        -0.3009, -0.1286, -0.6603, -0.0171,  0.1095, -0.1358,  0.2721, -0.0783,\n",
            "         0.0301, -0.5158, -0.2684, -0.2623, -0.1581,  0.0285, -0.0386, -0.4061,\n",
            "         0.0337,  0.1413, -0.1550, -0.2288,  0.0574, -0.4344, -0.2261, -0.2150,\n",
            "        -0.1430, -0.2064, -0.0344, -0.0295, -0.3126,  0.1005, -0.0621, -0.0351,\n",
            "        -0.5491, -0.5405, -0.2271,  0.0661, -0.0634, -0.3364,  0.1579,  0.1341,\n",
            "        -0.0068,  0.0654, -0.1497, -0.2229, -0.5119,  0.0165, -0.1606, -0.1157,\n",
            "        -0.2066, -0.0205,  0.2173, -0.1259, -0.4098,  0.0220, -0.2712, -0.2792,\n",
            "        -0.2277,  0.0472, -0.2090, -0.1698, -0.2657, -0.2702,  0.1181, -0.0067,\n",
            "        -0.0424, -0.0258, -0.2248, -0.2462, -0.2514, -0.1141,  0.0537, -0.0589,\n",
            "        -0.0953, -0.0339, -0.1539, -0.0766,  0.0092, -0.0690, -0.1841, -0.1326,\n",
            "        -0.4082, -0.0560, -0.5430, -0.2767, -0.6178, -0.2439, -0.4663, -0.2660,\n",
            "        -0.1022,  0.1151,  0.0923, -0.4861, -0.1538, -0.1628, -0.3269, -0.0084,\n",
            "         0.0275, -0.2116, -0.7019,  0.0358,  0.0985,  0.1188, -0.3232,  0.0197,\n",
            "        -0.0443,  0.0945, -0.4291,  0.0338, -0.1765, -0.0748,  0.0507, -0.0146,\n",
            "        -0.0271, -0.3976, -0.2292, -0.0451,  0.0366,  0.0088, -0.0595, -0.2818,\n",
            "         0.1031, -0.3781, -0.4814, -0.2038, -0.0258, -0.0060, -0.4775, -0.4051,\n",
            "        -0.1287, -0.3081,  0.1167, -0.1388,  0.1309,  0.1694,  0.0714, -0.0744,\n",
            "         0.0508,  0.2236, -0.5816,  0.2590, -0.2309, -0.2442,  0.3406, -0.0516],\n",
            "       device='cuda:0')), ('inception_block_9.b1.1.running_var', tensor([0.3282, 0.2439, 0.2884, 0.1715, 0.2006, 0.2356, 0.1572, 0.3187, 0.2042,\n",
            "        0.3149, 0.1495, 0.2814, 0.2806, 0.2049, 0.1963, 0.2751, 0.1506, 0.1670,\n",
            "        0.2007, 0.2207, 0.2608, 0.2455, 0.2437, 0.2054, 0.2013, 0.1866, 0.2993,\n",
            "        0.3104, 0.2665, 0.2277, 0.1487, 0.2062, 0.2555, 0.2742, 0.2107, 0.1791,\n",
            "        0.1963, 0.1710, 0.4074, 0.1627, 0.2480, 0.2203, 0.2669, 0.1838, 0.2288,\n",
            "        0.3545, 0.2861, 0.1916, 0.2253, 0.1851, 0.2966, 0.2839, 0.2608, 0.2901,\n",
            "        0.2255, 0.1571, 0.1579, 0.2621, 0.1462, 0.2279, 0.1804, 0.1852, 0.2256,\n",
            "        0.2008, 0.2916, 0.2029, 0.1866, 0.2179, 0.2360, 0.2235, 0.2568, 0.1957,\n",
            "        0.3151, 0.2292, 0.2664, 0.2678, 0.1606, 0.2218, 0.2174, 0.2484, 0.1343,\n",
            "        0.3768, 0.2086, 0.3274, 0.2060, 0.2088, 0.1928, 0.2227, 0.2016, 0.2268,\n",
            "        0.1591, 0.2807, 0.1749, 0.4708, 0.2580, 0.2294, 0.1859, 0.2193, 0.1878,\n",
            "        0.2837, 0.2495, 0.1818, 0.1811, 0.2117, 0.2367, 0.2496, 0.1985, 0.2271,\n",
            "        0.3458, 0.2146, 0.1929, 0.2859, 0.2158, 0.2375, 0.2408, 0.2820, 0.3955,\n",
            "        0.2501, 0.1863, 0.3725, 0.1800, 0.2246, 0.2333, 0.2819, 0.2221, 0.2208,\n",
            "        0.1862, 0.2126, 0.2192, 0.2241, 0.2152, 0.2405, 0.1984, 0.2674, 0.1731,\n",
            "        0.3338, 0.1864, 0.2103, 0.2176, 0.2325, 0.2180, 0.1817, 0.2558, 0.2150,\n",
            "        0.2757, 0.2504, 0.1911, 0.1906, 0.2318, 0.1926, 0.1650, 0.2966, 0.2349,\n",
            "        0.2233, 0.1647, 0.1874, 0.1858, 0.1970, 0.2042, 0.1970, 0.1771, 0.3903,\n",
            "        0.3211, 0.2185, 0.2376, 0.1923, 0.1553, 0.2498, 0.2469, 0.1943, 0.1707,\n",
            "        0.1823, 0.1465, 0.1487, 0.2196, 0.1789, 0.2202, 0.2944, 0.1746, 0.1682,\n",
            "        0.2689, 0.1881, 0.1703, 0.2157, 0.2664, 0.2331, 0.1957, 0.2146, 0.2414,\n",
            "        0.1505, 0.2229, 0.2334, 0.1920, 0.2014, 0.1845, 0.2078, 0.2497, 0.1626,\n",
            "        0.3076, 0.1873, 0.2127, 0.2592, 0.1693, 0.2608, 0.2865, 0.2712, 0.1384,\n",
            "        0.1974, 0.1581, 0.2473, 0.2214, 0.1646, 0.2145, 0.2177, 0.2744, 0.1762,\n",
            "        0.2745, 0.2146, 0.3347, 0.2310, 0.2132, 0.2155, 0.1731, 0.2093, 0.2846,\n",
            "        0.2520, 0.3032, 0.2101, 0.2974, 0.1988, 0.1470, 0.2139, 0.3596, 0.3343,\n",
            "        0.2374, 0.2148, 0.3429, 0.2673, 0.3097, 0.1606, 0.2491, 0.3310, 0.1850,\n",
            "        0.1779, 0.2488, 0.1340, 0.1674, 0.2521, 0.2047, 0.1843, 0.2531, 0.2502,\n",
            "        0.2222, 0.2493, 0.1849, 0.1892, 0.1735, 0.2447, 0.2219, 0.1593, 0.3239,\n",
            "        0.2192, 0.2993, 0.2246, 0.2723, 0.1848, 0.2914, 0.1441, 0.2212, 0.3129,\n",
            "        0.2207, 0.2129, 0.1863, 0.2083, 0.2220, 0.1901, 0.2323, 0.2555, 0.1926,\n",
            "        0.2732, 0.2306, 0.2222, 0.3515, 0.2214, 0.1612, 0.1793, 0.2190, 0.1728,\n",
            "        0.2934, 0.1815, 0.2153, 0.2342, 0.1425, 0.3406, 0.1891, 0.3152, 0.2354,\n",
            "        0.2048, 0.2409, 0.2642, 0.2228, 0.1394, 0.2878, 0.2245, 0.2127, 0.1847,\n",
            "        0.3835, 0.2069, 0.2027, 0.1840, 0.2065, 0.2048, 0.2582, 0.2087, 0.2567,\n",
            "        0.2636, 0.2179, 0.2600, 0.2567, 0.1944, 0.2358, 0.3032, 0.2144, 0.3093,\n",
            "        0.2310, 0.4349, 0.2733, 0.2425, 0.1566, 0.2916, 0.1898, 0.1912, 0.1832,\n",
            "        0.2044, 0.2358, 0.2378, 0.2839, 0.2355, 0.2750, 0.1614, 0.2506, 0.1635,\n",
            "        0.2780, 0.2586, 0.1898, 0.1787, 0.2236, 0.2316, 0.2406, 0.2183, 0.2214,\n",
            "        0.1673, 0.2403, 0.3501, 0.2689, 0.1667, 0.1556, 0.1141, 0.1762, 0.2044,\n",
            "        0.2900, 0.3019, 0.2503, 0.1341, 0.2207, 0.2121, 0.2058, 0.1507, 0.1801,\n",
            "        0.2080, 0.1845, 0.2316, 0.3784, 0.1618, 0.2554, 0.1851, 0.2415, 0.1966,\n",
            "        0.1891, 0.2125, 0.2037, 0.2737, 0.1990, 0.2013], device='cuda:0')), ('inception_block_9.b1.1.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_9.b2.0.weight', tensor([[[[-0.0150]],\n",
            "\n",
            "         [[ 0.0247]],\n",
            "\n",
            "         [[-0.0326]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0276]],\n",
            "\n",
            "         [[-0.0012]],\n",
            "\n",
            "         [[ 0.0035]]],\n",
            "\n",
            "\n",
            "        [[[-0.0095]],\n",
            "\n",
            "         [[ 0.0103]],\n",
            "\n",
            "         [[-0.0199]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0139]],\n",
            "\n",
            "         [[-0.0341]],\n",
            "\n",
            "         [[-0.0344]]],\n",
            "\n",
            "\n",
            "        [[[-0.0196]],\n",
            "\n",
            "         [[-0.0343]],\n",
            "\n",
            "         [[-0.0009]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0101]],\n",
            "\n",
            "         [[ 0.0211]],\n",
            "\n",
            "         [[-0.0104]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0112]],\n",
            "\n",
            "         [[ 0.0145]],\n",
            "\n",
            "         [[ 0.0100]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0209]],\n",
            "\n",
            "         [[-0.0246]],\n",
            "\n",
            "         [[-0.0021]]],\n",
            "\n",
            "\n",
            "        [[[-0.0393]],\n",
            "\n",
            "         [[ 0.0014]],\n",
            "\n",
            "         [[-0.0046]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0185]],\n",
            "\n",
            "         [[ 0.0127]],\n",
            "\n",
            "         [[-0.0213]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0278]],\n",
            "\n",
            "         [[-0.0346]],\n",
            "\n",
            "         [[ 0.0019]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0482]],\n",
            "\n",
            "         [[-0.0327]],\n",
            "\n",
            "         [[ 0.0323]]]], device='cuda:0')), ('inception_block_9.b2.0.bias', tensor([ 0.0242,  0.0320,  0.0065,  0.0269, -0.0298,  0.0260,  0.0055, -0.0215,\n",
            "         0.0244,  0.0029, -0.0273, -0.0198, -0.0096,  0.0114, -0.0223,  0.0182,\n",
            "        -0.0206, -0.0115,  0.0249, -0.0158, -0.0245, -0.0133, -0.0266, -0.0113,\n",
            "        -0.0176,  0.0167, -0.0094,  0.0157, -0.0146, -0.0126,  0.0233, -0.0011,\n",
            "         0.0280,  0.0082,  0.0122,  0.0336,  0.0112, -0.0311,  0.0262, -0.0063,\n",
            "        -0.0033,  0.0016,  0.0019,  0.0205, -0.0214,  0.0190, -0.0115,  0.0217,\n",
            "         0.0060, -0.0102,  0.0322,  0.0029,  0.0126, -0.0014, -0.0118,  0.0039,\n",
            "        -0.0239,  0.0298,  0.0010, -0.0095, -0.0153,  0.0291,  0.0264, -0.0269,\n",
            "        -0.0246, -0.0056,  0.0302, -0.0263, -0.0106, -0.0282,  0.0127,  0.0075,\n",
            "         0.0156, -0.0330, -0.0165,  0.0116,  0.0125, -0.0265, -0.0063, -0.0023,\n",
            "        -0.0221, -0.0208, -0.0295,  0.0066, -0.0106,  0.0210, -0.0283,  0.0119,\n",
            "         0.0102, -0.0151, -0.0247,  0.0045,  0.0263,  0.0126, -0.0183,  0.0225,\n",
            "        -0.0010, -0.0214,  0.0256,  0.0140, -0.0256,  0.0017, -0.0315,  0.0332,\n",
            "        -0.0155, -0.0039, -0.0058,  0.0076,  0.0280,  0.0265, -0.0193,  0.0280,\n",
            "        -0.0033, -0.0213,  0.0295,  0.0330,  0.0166,  0.0322, -0.0072,  0.0225,\n",
            "        -0.0245, -0.0241,  0.0246,  0.0181, -0.0104, -0.0144,  0.0307, -0.0314,\n",
            "         0.0152, -0.0054, -0.0175,  0.0291,  0.0149, -0.0304,  0.0070, -0.0329,\n",
            "         0.0200,  0.0319,  0.0105,  0.0208, -0.0312,  0.0180,  0.0076, -0.0274,\n",
            "        -0.0019, -0.0241, -0.0259,  0.0267,  0.0294,  0.0223,  0.0041, -0.0186,\n",
            "        -0.0232, -0.0145, -0.0038,  0.0251,  0.0292,  0.0109, -0.0299,  0.0040,\n",
            "         0.0334,  0.0026, -0.0205,  0.0255,  0.0206, -0.0179,  0.0239, -0.0017,\n",
            "         0.0104, -0.0227, -0.0171, -0.0268, -0.0221,  0.0125, -0.0189,  0.0314,\n",
            "        -0.0158, -0.0192,  0.0166,  0.0248,  0.0004, -0.0064,  0.0086, -0.0119,\n",
            "        -0.0210, -0.0040, -0.0051,  0.0060, -0.0339, -0.0088, -0.0298,  0.0185],\n",
            "       device='cuda:0')), ('inception_block_9.b2.1.weight', tensor([0.9977, 0.9844, 0.9963, 0.9934, 1.0142, 0.9982, 1.0048, 1.0072, 1.0014,\n",
            "        0.9859, 1.0194, 0.9991, 0.9932, 0.9997, 0.9986, 0.9910, 1.0209, 0.9972,\n",
            "        0.9978, 1.0031, 0.9959, 1.0053, 0.9997, 0.9893, 0.9973, 0.9955, 1.0045,\n",
            "        0.9945, 0.9958, 1.0042, 0.9970, 0.9863, 0.9924, 0.9956, 0.9860, 0.9975,\n",
            "        0.9992, 0.9845, 0.9955, 0.9977, 1.0089, 1.0008, 0.9943, 1.0009, 1.0028,\n",
            "        0.9930, 0.9861, 1.0078, 1.0058, 1.0051, 1.0094, 1.0023, 0.9990, 1.0002,\n",
            "        0.9994, 0.9934, 1.0059, 0.9889, 0.9966, 0.9899, 1.0061, 0.9953, 0.9943,\n",
            "        1.0098, 1.0041, 0.9981, 1.0104, 1.0068, 0.9959, 0.9888, 0.9963, 1.0005,\n",
            "        0.9989, 0.9914, 1.0094, 1.0036, 0.9972, 1.0056, 0.9979, 0.9980, 0.9993,\n",
            "        0.9971, 0.9931, 0.9937, 0.9924, 0.9948, 0.9992, 0.9917, 1.0007, 0.9804,\n",
            "        0.9923, 0.9993, 1.0049, 0.9990, 0.9920, 0.9987, 0.9896, 1.0060, 0.9984,\n",
            "        1.0007, 0.9927, 1.0167, 1.0095, 1.0105, 0.9978, 1.0035, 1.0086, 0.9959,\n",
            "        1.0036, 1.0117, 0.9928, 1.0090, 1.0140, 0.9896, 1.0091, 1.0039, 1.0028,\n",
            "        1.0017, 1.0076, 0.9999, 0.9898, 1.0013, 0.9890, 0.9965, 0.9949, 0.9815,\n",
            "        1.0020, 1.0049, 1.0007, 0.9972, 0.9961, 1.0098, 1.0072, 0.9917, 0.9999,\n",
            "        0.9966, 0.9891, 0.9983, 0.9998, 0.9996, 0.9963, 1.0021, 0.9958, 0.9986,\n",
            "        0.9797, 0.9980, 0.9866, 1.0070, 1.0048, 0.9853, 0.9849, 1.0046, 1.0062,\n",
            "        0.9831, 0.9934, 0.9942, 1.0019, 0.9921, 0.9956, 0.9880, 0.9880, 0.9907,\n",
            "        0.9957, 1.0023, 0.9922, 0.9970, 0.9884, 0.9962, 0.9839, 1.0038, 0.9876,\n",
            "        0.9873, 1.0015, 0.9925, 0.9898, 1.0062, 0.9974, 0.9858, 1.0010, 1.0050,\n",
            "        0.9937, 0.9963, 1.0014, 0.9815, 1.0047, 1.0059, 0.9811, 1.0094, 1.0112,\n",
            "        0.9907, 1.0082, 1.0068], device='cuda:0')), ('inception_block_9.b2.1.bias', tensor([-0.0111, -0.0139, -0.0066, -0.0228, -0.0027, -0.0124, -0.0200, -0.0035,\n",
            "        -0.0083, -0.0153, -0.0040, -0.0175, -0.0105, -0.0161, -0.0134, -0.0105,\n",
            "        -0.0002, -0.0103, -0.0147, -0.0107, -0.0085, -0.0097, -0.0144, -0.0144,\n",
            "        -0.0102, -0.0080, -0.0170, -0.0055, -0.0108, -0.0063, -0.0116, -0.0136,\n",
            "        -0.0168, -0.0115, -0.0116, -0.0129, -0.0201, -0.0148, -0.0165, -0.0182,\n",
            "        -0.0091, -0.0119, -0.0121, -0.0026, -0.0012, -0.0074, -0.0177, -0.0119,\n",
            "        -0.0042, -0.0240, -0.0076, -0.0120, -0.0154, -0.0106, -0.0061, -0.0226,\n",
            "        -0.0018, -0.0134, -0.0172, -0.0271, -0.0123, -0.0069, -0.0107, -0.0081,\n",
            "        -0.0046, -0.0122, -0.0186, -0.0173, -0.0127, -0.0101, -0.0239, -0.0077,\n",
            "        -0.0094, -0.0161, -0.0043, -0.0192, -0.0107, -0.0116, -0.0104, -0.0144,\n",
            "        -0.0119, -0.0136, -0.0190, -0.0122, -0.0126, -0.0060, -0.0124, -0.0058,\n",
            "        -0.0024, -0.0175, -0.0069, -0.0172, -0.0059, -0.0075, -0.0118, -0.0154,\n",
            "        -0.0052, -0.0213, -0.0136, -0.0081, -0.0143, -0.0021, -0.0057, -0.0084,\n",
            "        -0.0225, -0.0098, -0.0072, -0.0211, -0.0100, -0.0133, -0.0036, -0.0052,\n",
            "        -0.0128, -0.0168, -0.0070, -0.0047, -0.0138, -0.0076, -0.0164, -0.0250,\n",
            "        -0.0101, -0.0199, -0.0142, -0.0147, -0.0159, -0.0213, -0.0058, -0.0086,\n",
            "        -0.0148, -0.0076, -0.0076, -0.0065, -0.0070, -0.0214, -0.0084, -0.0133,\n",
            "        -0.0050, -0.0151, -0.0118, -0.0098, -0.0126, -0.0080, -0.0165, -0.0048,\n",
            "        -0.0150, -0.0061, -0.0131, -0.0134, -0.0088, -0.0111, -0.0096, -0.0098,\n",
            "        -0.0053, -0.0195, -0.0091, -0.0020, -0.0139, -0.0116, -0.0209, -0.0153,\n",
            "        -0.0119, -0.0086, -0.0118, -0.0089, -0.0174, -0.0066, -0.0168, -0.0101,\n",
            "        -0.0181,  0.0052, -0.0089, -0.0073, -0.0157, -0.0085, -0.0069, -0.0157,\n",
            "        -0.0149, -0.0111, -0.0109, -0.0095, -0.0005, -0.0105, -0.0148, -0.0209,\n",
            "        -0.0217, -0.0058, -0.0151, -0.0102, -0.0218, -0.0081, -0.0128, -0.0078],\n",
            "       device='cuda:0')), ('inception_block_9.b2.1.running_mean', tensor([-2.8336e-01, -4.6603e-01, -2.6685e-01,  1.1001e-01, -9.1528e-01,\n",
            "        -7.5934e-01, -1.2312e-01, -3.6115e-01, -6.3887e-01, -1.2385e-01,\n",
            "        -8.0931e-01, -8.2242e-01, -4.4944e-01, -8.4598e-01, -2.3292e-01,\n",
            "        -8.3851e-02, -8.3862e-01, -1.5249e-01, -3.1251e-01, -5.9842e-01,\n",
            "        -2.6176e-01, -2.4876e-01, -1.0805e+00,  1.7752e-01,  2.0276e-01,\n",
            "        -5.9829e-01, -2.1614e-01,  5.0260e-01, -2.0945e-01, -8.8666e-01,\n",
            "        -1.6627e-01, -8.4925e-01,  5.9613e-03,  2.7756e-02, -8.2877e-01,\n",
            "        -3.5251e-02, -7.2724e-01, -4.8651e-02, -4.7221e-02, -8.4525e-01,\n",
            "        -5.2197e-01, -1.2627e-01, -1.8234e-01, -3.8959e-01, -8.2752e-01,\n",
            "        -5.2130e-01, -1.8527e-01, -3.6602e-01, -3.9306e-01, -3.8635e-01,\n",
            "        -3.3449e-01, -4.0987e-01, -2.6636e-01, -2.9757e-03, -7.8050e-01,\n",
            "        -4.9344e-01, -4.8742e-01, -7.2641e-01, -5.2090e-01, -5.4322e-01,\n",
            "        -8.0718e-01,  4.0547e-01, -1.6207e-01, -4.5106e-01, -9.2488e-01,\n",
            "         1.0819e-02,  5.2280e-02, -5.1000e-01, -3.1269e-01, -5.6642e-01,\n",
            "        -4.2176e-01, -9.2661e-01, -5.2322e-01, -6.7947e-01, -7.1184e-01,\n",
            "        -4.6185e-01, -7.6470e-01, -5.9878e-01, -8.4563e-01, -6.9565e-01,\n",
            "        -8.4425e-01, -8.4191e-03, -4.8046e-01, -1.5998e-01, -8.7587e-02,\n",
            "        -5.6904e-01, -7.0183e-01,  2.0712e-01, -4.4837e-01,  3.6879e-03,\n",
            "        -4.5796e-01, -4.5318e-01, -5.8453e-01, -2.1211e-01,  2.6024e-02,\n",
            "        -5.5584e-01, -3.6723e-01, -3.4146e-01,  2.3137e-02, -3.6822e-01,\n",
            "        -3.3436e-01, -7.4537e-01, -3.0642e-01, -4.6981e-01,  6.1531e-01,\n",
            "        -5.1295e-01, -3.5704e-01,  7.1563e-02,  1.0114e-01, -3.9491e-01,\n",
            "        -7.0692e-01, -4.2855e-01, -4.9882e-01,  5.2113e-02, -1.9744e-01,\n",
            "        -3.8257e-01, -5.7616e-01, -5.6870e-01, -9.9285e-02, -3.7268e-01,\n",
            "        -7.3951e-01, -3.3315e-01, -2.7034e-01, -2.1043e-01, -4.4616e-01,\n",
            "        -5.8055e-01, -2.0106e-01, -1.5252e-01, -4.9440e-01, -7.8311e-02,\n",
            "        -9.2916e-02, -5.3346e-01,  1.4345e-02, -5.2026e-01, -4.1357e-01,\n",
            "        -3.2691e-01, -7.5232e-01,  3.6478e-04, -3.8134e-01, -2.1842e-01,\n",
            "        -2.1705e-01, -1.3037e-02, -8.3712e-03, -8.5339e-01, -5.5768e-01,\n",
            "        -5.4638e-01, -7.0931e-01, -3.8768e-01, -2.0241e-01, -1.5698e-02,\n",
            "        -8.5109e-01,  5.5511e-02, -5.7311e-01, -1.0003e+00, -1.4107e-01,\n",
            "        -3.6277e-01, -5.4123e-02, -1.2661e-01, -5.3160e-01,  2.4072e-01,\n",
            "        -3.5962e-01, -3.6095e-01, -5.4917e-01, -4.1808e-01, -4.2215e-01,\n",
            "        -3.3807e-01, -1.2856e-01, -5.4213e-01,  1.1249e-02, -5.6412e-01,\n",
            "        -4.8058e-01, -2.3678e-01, -4.2624e-01,  5.6978e-02,  4.0501e-03,\n",
            "        -6.9606e-01, -7.6933e-01, -2.7293e-01, -2.2185e-01, -5.9115e-01,\n",
            "        -3.4142e-01, -3.5749e-01, -6.5672e-01, -1.1347e-01, -4.2164e-01,\n",
            "        -9.1332e-01, -4.4474e-01, -1.7418e-01, -5.8757e-01, -1.9473e-01,\n",
            "        -3.5860e-01, -3.9917e-01], device='cuda:0')), ('inception_block_9.b2.1.running_var', tensor([0.1842, 0.3773, 0.1631, 0.1850, 0.1656, 0.1880, 0.1810, 0.1688, 0.1539,\n",
            "        0.5924, 0.1472, 0.1573, 0.1473, 0.1561, 0.2359, 0.1661, 0.1735, 0.1786,\n",
            "        0.1652, 0.1678, 0.2671, 0.2109, 0.2478, 0.3888, 0.1738, 0.1647, 0.1290,\n",
            "        0.1750, 0.1844, 0.2006, 0.1804, 0.2692, 0.2303, 0.1286, 0.2113, 0.2069,\n",
            "        0.1781, 0.2590, 0.1540, 0.1337, 0.1625, 0.1353, 0.2523, 0.1326, 0.2871,\n",
            "        0.2246, 0.2020, 0.1750, 0.2058, 0.1300, 0.1499, 0.1483, 0.1625, 0.1894,\n",
            "        0.1649, 0.1602, 0.2527, 0.2155, 0.1796, 0.1518, 0.1966, 0.3026, 0.2143,\n",
            "        0.1404, 0.2025, 0.2133, 0.1862, 0.1568, 0.1718, 0.2215, 0.2382, 0.1686,\n",
            "        0.2037, 0.2404, 0.2615, 0.1625, 0.1648, 0.1830, 0.1435, 0.1407, 0.1853,\n",
            "        0.1858, 0.1348, 0.2049, 0.2158, 0.2161, 0.2709, 0.4120, 0.1652, 0.4448,\n",
            "        0.3321, 0.1652, 0.1598, 0.2159, 0.4140, 0.1612, 0.2793, 0.1353, 0.1573,\n",
            "        0.1763, 0.2379, 0.1662, 0.1814, 0.1958, 0.1658, 0.1579, 0.1907, 0.2022,\n",
            "        0.1630, 0.2359, 0.3225, 0.1877, 0.1543, 0.2262, 0.1648, 0.1843, 0.1502,\n",
            "        0.2198, 0.1959, 0.1595, 0.1918, 0.2050, 0.2255, 0.1290, 0.1272, 0.1739,\n",
            "        0.1957, 0.1898, 0.1749, 0.2180, 0.2684, 0.1562, 0.2447, 0.1600, 0.1434,\n",
            "        0.1623, 0.2384, 0.2461, 0.2074, 0.1592, 0.2123, 0.2149, 0.1666, 0.1516,\n",
            "        0.2741, 0.1431, 0.2402, 0.1825, 0.1696, 0.1546, 0.2996, 0.1821, 0.1962,\n",
            "        0.1644, 0.3074, 0.3131, 0.2072, 0.2434, 0.1948, 0.1996, 0.1347, 0.2090,\n",
            "        0.2017, 0.2698, 0.1891, 0.2133, 0.1594, 0.1503, 0.2034, 0.1979, 0.1871,\n",
            "        0.3451, 0.1627, 0.2765, 0.2401, 0.1372, 0.1786, 0.1734, 0.1987, 0.1318,\n",
            "        0.2703, 0.2132, 0.1620, 0.1963, 0.1246, 0.1678, 0.2060, 0.1599, 0.1385,\n",
            "        0.2073, 0.1659, 0.1360], device='cuda:0')), ('inception_block_9.b2.1.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_9.b2.3.weight', tensor([[[[-3.0231e-02, -7.9230e-03,  1.0856e-02],\n",
            "          [ 7.6545e-03,  2.8811e-03, -8.8751e-03],\n",
            "          [ 8.9317e-03,  2.7038e-04, -5.2301e-03]],\n",
            "\n",
            "         [[ 1.6248e-02, -1.0427e-02,  8.1170e-03],\n",
            "          [ 1.2987e-02, -1.1319e-02,  2.1259e-02],\n",
            "          [-9.3498e-03, -1.2926e-02,  1.9105e-02]],\n",
            "\n",
            "         [[-2.6294e-03, -5.5812e-03,  1.4692e-02],\n",
            "          [ 1.6196e-02,  1.9324e-02,  1.6279e-02],\n",
            "          [ 7.7438e-03, -7.6845e-03, -1.9329e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6611e-02,  7.9156e-04, -8.7646e-03],\n",
            "          [-1.7652e-02,  2.6429e-04, -6.4285e-04],\n",
            "          [ 4.8569e-03,  1.4082e-02, -1.2820e-02]],\n",
            "\n",
            "         [[-2.6058e-02, -4.5530e-03, -1.1464e-02],\n",
            "          [ 3.8276e-03,  8.8037e-03,  9.3248e-03],\n",
            "          [-2.2519e-03, -2.4920e-02, -2.0165e-02]],\n",
            "\n",
            "         [[ 6.5438e-03,  2.0185e-02, -1.4952e-02],\n",
            "          [-2.2303e-02, -2.0340e-02,  6.4977e-03],\n",
            "          [-2.2165e-02, -6.0699e-03, -1.0793e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.8221e-03,  4.6851e-03, -4.6537e-03],\n",
            "          [ 1.7904e-02, -1.4178e-03, -1.7500e-02],\n",
            "          [ 9.3194e-03, -2.3485e-02,  1.3662e-02]],\n",
            "\n",
            "         [[ 2.5425e-02, -7.4975e-03, -7.8909e-03],\n",
            "          [ 1.2564e-02,  2.0736e-02,  1.5644e-02],\n",
            "          [-4.3489e-04,  2.2672e-02,  6.4184e-03]],\n",
            "\n",
            "         [[-7.2230e-03, -1.0677e-02,  9.8638e-03],\n",
            "          [-2.4606e-02, -1.5352e-02,  1.2649e-02],\n",
            "          [ 1.5919e-02, -8.8167e-04,  3.4567e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5459e-02, -1.1615e-02, -7.3512e-03],\n",
            "          [ 7.1282e-03,  1.7251e-02,  1.0611e-03],\n",
            "          [-1.5684e-02,  2.4019e-03, -9.4656e-03]],\n",
            "\n",
            "         [[ 1.5097e-02,  1.4746e-02,  1.9471e-02],\n",
            "          [-2.0567e-02,  1.4397e-02,  4.7089e-03],\n",
            "          [-2.3596e-02,  1.7363e-03, -4.4893e-03]],\n",
            "\n",
            "         [[-1.0442e-02,  1.1570e-02,  2.5771e-03],\n",
            "          [-9.8812e-03, -4.3897e-03, -6.2887e-03],\n",
            "          [ 2.3233e-02,  1.4484e-02,  2.4563e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3269e-02,  8.5193e-03,  8.3203e-03],\n",
            "          [ 1.7376e-02, -1.4955e-02,  1.9817e-02],\n",
            "          [-1.2461e-02,  2.4202e-02, -1.2746e-03]],\n",
            "\n",
            "         [[-2.3000e-02, -2.1852e-02, -8.3136e-03],\n",
            "          [ 4.2732e-03, -2.7482e-02, -4.1393e-03],\n",
            "          [ 4.9862e-03, -1.0388e-02,  1.4272e-02]],\n",
            "\n",
            "         [[-2.0497e-02, -2.1150e-02,  1.4093e-02],\n",
            "          [-2.5485e-03,  1.1390e-02, -2.1800e-02],\n",
            "          [-9.7687e-03,  8.2442e-03, -5.9217e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4145e-02,  4.9605e-03,  1.9190e-03],\n",
            "          [-1.4653e-02,  8.4055e-03,  9.9136e-03],\n",
            "          [ 1.0367e-02, -2.7899e-03, -1.3276e-02]],\n",
            "\n",
            "         [[-1.7763e-04, -1.4406e-02, -9.3307e-03],\n",
            "          [-2.3978e-02, -3.0459e-03,  1.8504e-02],\n",
            "          [-1.0796e-02, -7.6930e-03, -8.3307e-03]],\n",
            "\n",
            "         [[ 1.2042e-02, -3.6184e-03,  5.8807e-03],\n",
            "          [ 9.2350e-03,  1.8666e-02, -1.6029e-02],\n",
            "          [-1.8698e-02, -6.6272e-03, -7.3078e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2142e-02, -1.7222e-02,  2.2911e-02],\n",
            "          [ 9.0392e-04,  1.4599e-02, -5.7095e-03],\n",
            "          [-3.3833e-03,  1.5529e-02,  3.4589e-03]],\n",
            "\n",
            "         [[ 1.2450e-02,  2.2096e-03,  1.9772e-02],\n",
            "          [-7.9984e-04, -2.0125e-02,  1.2310e-02],\n",
            "          [-2.5522e-02,  1.9083e-02,  1.0762e-02]],\n",
            "\n",
            "         [[-1.1341e-02,  1.9167e-03,  2.1626e-02],\n",
            "          [ 3.7593e-03, -1.1136e-02,  1.2558e-02],\n",
            "          [ 1.5289e-02,  9.7368e-03, -8.2883e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6909e-03, -2.3142e-02,  1.9900e-02],\n",
            "          [-1.5185e-02, -1.8774e-02,  6.1776e-03],\n",
            "          [-1.9917e-02,  5.2876e-04, -2.7091e-02]],\n",
            "\n",
            "         [[ 2.1721e-02, -1.0637e-02,  1.7064e-03],\n",
            "          [-1.3666e-02,  9.7213e-03, -2.4914e-03],\n",
            "          [ 1.9068e-02,  2.9317e-03,  2.4342e-02]],\n",
            "\n",
            "         [[-4.7282e-04, -2.6618e-02, -3.0607e-02],\n",
            "          [-1.9514e-02,  3.8237e-03, -1.8140e-02],\n",
            "          [-1.0603e-02,  2.8524e-03,  1.4829e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.8102e-02, -1.0418e-02,  1.4722e-02],\n",
            "          [-1.6484e-02, -9.1518e-03, -1.4012e-02],\n",
            "          [-2.6139e-02, -1.7801e-02,  4.5739e-03]],\n",
            "\n",
            "         [[-9.2467e-03,  1.5742e-02,  2.2064e-02],\n",
            "          [ 2.6550e-02, -1.2914e-02,  1.2470e-02],\n",
            "          [-1.3969e-02,  2.2175e-02,  2.1779e-02]],\n",
            "\n",
            "         [[ 2.0961e-02, -3.2186e-03,  5.3282e-04],\n",
            "          [-6.8440e-03,  2.1068e-02,  1.1115e-02],\n",
            "          [-8.6310e-03, -1.3930e-02,  7.9200e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4905e-02, -1.1799e-02,  1.4708e-02],\n",
            "          [ 2.6717e-03, -1.9005e-02,  5.9171e-03],\n",
            "          [-1.6785e-03, -2.1532e-02,  2.0337e-03]],\n",
            "\n",
            "         [[-3.1051e-02, -2.1648e-02, -1.4770e-02],\n",
            "          [-2.6488e-04,  9.0696e-03, -1.3080e-02],\n",
            "          [-1.4060e-02, -1.7792e-03, -1.4528e-02]],\n",
            "\n",
            "         [[-5.3230e-03,  2.2925e-02,  2.3348e-05],\n",
            "          [-1.2661e-02,  9.1919e-03, -4.4566e-03],\n",
            "          [-1.1061e-02,  1.5219e-02, -1.0653e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.6059e-04,  2.2169e-02, -9.7213e-03],\n",
            "          [ 2.6726e-02,  1.0445e-02, -1.7316e-02],\n",
            "          [ 1.1575e-03,  2.5993e-02,  7.8770e-03]],\n",
            "\n",
            "         [[ 4.1316e-03, -1.5248e-03,  2.8781e-02],\n",
            "          [ 2.0995e-02, -3.7224e-03,  7.9954e-03],\n",
            "          [ 2.3376e-02,  1.1359e-02, -6.5142e-03]],\n",
            "\n",
            "         [[-7.9905e-03, -3.7722e-03,  1.1438e-02],\n",
            "          [-7.4436e-03,  9.7978e-03,  1.5212e-02],\n",
            "          [ 1.3211e-02, -1.5158e-02, -1.7495e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3512e-02, -1.1420e-02,  1.1253e-02],\n",
            "          [ 3.7591e-03, -9.1065e-03, -2.6977e-02],\n",
            "          [-2.3112e-02,  1.0148e-03, -7.1458e-03]],\n",
            "\n",
            "         [[-1.7185e-02,  3.6976e-03, -2.5060e-02],\n",
            "          [-6.2302e-03, -9.3852e-03,  5.9649e-03],\n",
            "          [ 1.0545e-02, -2.4759e-02, -2.7320e-02]],\n",
            "\n",
            "         [[ 3.5239e-03,  3.1062e-03, -1.2638e-02],\n",
            "          [-1.1922e-02, -3.3826e-03, -1.3852e-02],\n",
            "          [-1.6105e-02,  1.6360e-02,  3.9121e-03]]]], device='cuda:0')), ('inception_block_9.b2.3.bias', tensor([-1.8595e-02,  1.5075e-02, -1.4581e-02,  8.9055e-03,  2.2928e-02,\n",
            "         1.4715e-02,  1.8075e-02, -1.2291e-02,  1.4124e-02,  2.4330e-03,\n",
            "         3.3341e-03, -1.4778e-02,  2.2972e-02,  1.3815e-02,  5.7839e-04,\n",
            "        -9.7286e-03, -1.9733e-02,  1.1072e-02,  2.8072e-03,  1.4089e-02,\n",
            "         2.3531e-02,  5.4735e-03, -1.4854e-02,  1.6252e-02,  1.6561e-02,\n",
            "        -2.2708e-02,  8.7321e-03,  2.6455e-03, -4.2827e-03,  6.7990e-03,\n",
            "        -1.0025e-02,  8.1772e-04,  3.8070e-03,  1.5765e-02, -5.6638e-03,\n",
            "         4.4842e-03,  1.8308e-03, -5.5638e-03, -8.2478e-03, -1.1773e-02,\n",
            "        -1.7691e-02, -1.0108e-02, -2.2143e-02, -2.2080e-02,  9.6589e-03,\n",
            "         1.7416e-02, -1.4297e-02,  2.3475e-02,  2.3395e-02, -1.6710e-02,\n",
            "        -1.1196e-02, -1.5841e-02,  1.2147e-02, -2.0227e-02, -5.2833e-03,\n",
            "         3.7139e-03, -2.1164e-02,  2.1618e-02,  1.9513e-02, -2.2425e-02,\n",
            "        -1.3736e-02,  2.0347e-02,  1.4344e-02, -1.8573e-03, -3.5877e-03,\n",
            "        -6.9253e-03,  1.8228e-02, -2.0716e-02,  8.1386e-03,  2.1864e-02,\n",
            "         1.7981e-02,  1.5358e-02,  7.0805e-03, -2.2291e-02, -1.8824e-02,\n",
            "        -1.0465e-02,  2.2303e-02, -1.7201e-02, -2.3286e-02,  1.2333e-02,\n",
            "        -8.7123e-04,  1.4084e-02,  9.7190e-03, -1.2862e-02,  7.0112e-03,\n",
            "         1.7246e-02, -2.2685e-02,  9.7420e-03, -1.1153e-02, -2.3445e-02,\n",
            "         1.4574e-02, -6.9066e-03, -1.0424e-02,  1.2334e-02,  1.8505e-02,\n",
            "        -1.7249e-02,  1.6526e-02, -6.9924e-03, -1.3717e-02, -5.4930e-03,\n",
            "         3.0532e-04, -1.6138e-02, -1.7680e-02, -3.3569e-03,  1.9132e-02,\n",
            "        -1.5088e-02, -1.7793e-02, -6.9846e-03, -1.0326e-02, -2.3824e-02,\n",
            "        -2.9149e-03,  1.7691e-02, -1.2081e-02,  6.5899e-03,  1.8859e-02,\n",
            "         2.4411e-04, -7.0911e-03, -6.6807e-03, -2.1933e-02, -1.2447e-02,\n",
            "        -1.2867e-03,  1.6548e-02,  9.4045e-03, -1.6390e-02, -1.4474e-02,\n",
            "         4.2376e-03, -8.9186e-03,  1.9577e-02, -9.5860e-03,  2.7232e-03,\n",
            "         9.1371e-03, -1.8156e-02,  9.7430e-03, -1.2032e-02, -2.1694e-02,\n",
            "        -1.1488e-02,  1.4008e-02,  7.8781e-03, -2.1023e-02, -3.9803e-03,\n",
            "         7.8698e-04, -7.2557e-03, -2.6998e-03,  2.3809e-02,  1.7631e-02,\n",
            "        -1.5510e-02,  4.9449e-03,  1.5048e-02,  1.3672e-02, -2.1164e-03,\n",
            "        -1.2738e-02, -8.3978e-03, -2.1132e-02,  1.7198e-02,  2.0156e-02,\n",
            "         2.0543e-02,  7.7967e-03,  1.5763e-02,  1.1543e-02,  6.6988e-03,\n",
            "         5.8443e-03,  1.9381e-02,  3.5197e-03,  2.0713e-03,  1.7321e-03,\n",
            "        -4.1286e-03, -2.7872e-03,  3.4272e-03, -4.9411e-04,  9.9462e-03,\n",
            "        -6.1822e-03,  4.1987e-03, -2.3992e-02, -6.3677e-03, -4.1427e-03,\n",
            "         1.8192e-02, -1.1725e-03, -1.6801e-02,  1.1013e-02, -8.3998e-03,\n",
            "         2.8541e-03,  1.0799e-02,  1.2075e-02, -3.6808e-04,  1.9251e-02,\n",
            "         2.1412e-02, -1.1785e-03,  2.2374e-02,  2.3356e-02,  1.4387e-02,\n",
            "        -2.3696e-02,  2.1077e-02, -1.5154e-02,  8.5305e-03,  2.6369e-04,\n",
            "        -5.0538e-03,  2.0467e-02, -7.8572e-03,  3.4090e-03, -8.7548e-03,\n",
            "        -2.1958e-02,  3.4623e-03, -8.2558e-03,  2.2088e-02,  6.0473e-03,\n",
            "        -2.8449e-03, -1.0395e-02, -2.1035e-02, -1.9103e-02,  1.8264e-02,\n",
            "        -9.4998e-03,  9.9636e-03,  2.2403e-02, -7.4355e-03,  8.3540e-03,\n",
            "        -6.2755e-03,  7.0059e-03,  7.9797e-03, -8.6061e-03, -5.9598e-03,\n",
            "         1.1323e-02,  1.6429e-03,  6.6318e-03,  4.3576e-03, -7.7867e-03,\n",
            "        -1.4580e-02,  8.5420e-03,  1.1844e-02,  1.7866e-02, -9.2095e-03,\n",
            "        -1.3152e-02,  1.8711e-02,  1.8133e-02, -1.0124e-03, -1.5715e-05,\n",
            "        -1.3436e-02,  1.0482e-02, -1.3410e-02,  1.8694e-02, -1.8509e-02,\n",
            "        -1.7622e-02,  4.4984e-03, -1.7745e-02,  1.2366e-02,  6.3852e-03,\n",
            "        -8.9332e-03,  1.8167e-02,  1.2305e-02,  1.6445e-02,  1.6505e-02,\n",
            "        -6.2819e-03, -1.5053e-02,  1.8717e-02,  5.8847e-03,  1.6709e-02,\n",
            "         1.7958e-02, -1.0196e-02, -3.5418e-03, -4.3538e-03,  6.9200e-03,\n",
            "         8.1173e-03,  4.7664e-03,  1.1614e-02,  6.9541e-03,  7.8964e-03,\n",
            "        -2.8897e-03, -1.5470e-02,  1.6926e-02,  2.6844e-03, -8.4283e-03,\n",
            "         2.0190e-02,  1.7171e-02, -2.2829e-02, -2.2185e-02,  2.0574e-02,\n",
            "         1.7939e-02, -4.0615e-03, -1.2375e-02, -2.3546e-02,  1.2701e-02,\n",
            "        -2.0463e-02,  7.4787e-03, -1.4857e-02,  1.5336e-02,  2.3519e-03,\n",
            "        -1.3331e-02, -1.8157e-02, -1.2438e-02,  1.2362e-02,  1.8271e-02,\n",
            "        -1.1067e-02, -8.5122e-03,  4.1618e-03, -1.1265e-02, -1.8803e-02,\n",
            "         1.6118e-02,  8.5519e-03,  2.3477e-04, -2.1631e-02,  8.6738e-03,\n",
            "         2.6302e-03,  1.3997e-02, -1.7306e-02, -4.1400e-03,  3.2678e-03,\n",
            "        -1.0849e-02,  1.6115e-02,  2.1996e-02,  9.6589e-03, -9.8671e-03,\n",
            "         1.7337e-02, -5.8811e-03, -1.0881e-02, -1.6181e-02,  1.2575e-02,\n",
            "        -1.6693e-02, -1.8968e-02, -9.6211e-03, -4.6151e-03, -1.0604e-02,\n",
            "         2.3325e-02, -2.7529e-03,  1.5855e-02, -1.9417e-02,  1.7691e-02,\n",
            "         5.4151e-03, -1.9765e-02, -2.2286e-02,  4.2604e-03,  8.4258e-03,\n",
            "        -1.4754e-02, -1.9563e-02,  6.2987e-03,  1.6041e-02, -2.2011e-02,\n",
            "         1.5235e-02, -8.1581e-03,  2.2968e-02,  1.9881e-02,  9.9193e-03,\n",
            "         1.2908e-03,  3.1925e-03, -2.1230e-02, -2.2077e-02, -2.8618e-03,\n",
            "         2.3874e-02, -2.3870e-02, -9.2827e-03, -5.5136e-03, -1.4300e-02,\n",
            "        -3.9598e-03,  7.0027e-03, -1.3759e-02, -1.1086e-02,  2.3278e-02,\n",
            "         1.3827e-02, -4.7783e-03, -1.9569e-02, -1.5666e-02, -8.4971e-03,\n",
            "        -9.0875e-03, -2.2878e-02,  2.1153e-02,  1.4826e-02,  5.3265e-03,\n",
            "        -3.2665e-03, -8.3223e-03,  1.1527e-02,  2.0749e-02, -1.3940e-02,\n",
            "         1.7773e-02,  1.7257e-02, -1.2651e-02,  7.2851e-03, -4.7106e-03,\n",
            "         3.8915e-03,  6.0690e-03, -9.4070e-03, -2.0102e-02, -1.8821e-02,\n",
            "        -1.1540e-02, -1.9393e-02, -2.1020e-02, -1.3458e-02], device='cuda:0')), ('inception_block_9.b2.4.weight', tensor([1.0401, 1.0512, 1.0345, 1.0432, 1.0460, 1.0614, 1.0601, 1.0443, 1.0438,\n",
            "        1.0454, 1.0672, 1.0483, 1.0446, 1.0455, 1.0423, 1.0572, 1.0370, 1.0645,\n",
            "        1.0370, 1.0595, 1.0543, 1.0428, 1.0459, 1.0457, 1.0524, 1.0520, 1.0374,\n",
            "        1.0346, 1.0417, 1.0528, 1.0492, 1.0394, 1.0454, 1.0714, 1.0375, 1.0422,\n",
            "        1.0447, 1.0326, 1.0445, 1.0442, 1.0376, 1.0416, 1.0447, 1.0472, 1.0296,\n",
            "        1.0449, 1.0391, 1.0417, 1.0671, 1.0472, 1.0404, 1.0450, 1.0665, 1.0476,\n",
            "        1.0489, 1.0391, 1.0438, 1.0456, 1.0415, 1.0466, 1.0436, 1.0402, 1.0402,\n",
            "        1.0503, 1.0397, 1.0387, 1.0479, 1.0428, 1.0491, 1.0497, 1.0342, 1.0451,\n",
            "        1.0562, 1.0520, 1.0502, 1.0442, 1.0547, 1.0442, 1.0450, 1.0357, 1.0500,\n",
            "        1.0461, 1.0462, 1.0314, 1.0347, 1.0367, 1.0351, 1.0415, 1.0502, 1.0467,\n",
            "        1.0431, 1.0462, 1.0429, 1.0526, 1.0471, 1.0422, 1.0496, 1.0470, 1.0396,\n",
            "        1.0447, 1.0437, 1.0423, 1.0410, 1.0524, 1.0388, 1.0367, 1.0577, 1.0534,\n",
            "        1.0319, 1.0459, 1.0384, 1.0419, 1.0342, 1.0420, 1.0522, 1.0543, 1.0499,\n",
            "        1.0394, 1.0532, 1.0475, 1.0420, 1.0520, 1.0403, 1.0441, 1.0515, 1.0364,\n",
            "        1.0517, 1.0380, 1.0403, 1.0495, 1.0383, 1.0371, 1.0488, 1.0449, 1.0356,\n",
            "        1.0535, 1.0428, 1.0525, 1.0382, 1.0479, 1.0361, 1.0437, 1.0499, 1.0354,\n",
            "        1.0394, 1.0446, 1.0426, 1.0503, 1.0326, 1.0479, 1.0437, 1.0388, 1.0439,\n",
            "        1.0459, 1.0373, 1.0406, 1.0399, 1.0356, 1.0341, 1.0398, 1.0304, 1.0407,\n",
            "        1.0531, 1.0471, 1.0536, 1.0391, 1.0520, 1.0558, 1.0407, 1.0411, 1.0454,\n",
            "        1.0472, 1.0526, 1.0516, 1.0403, 1.0306, 1.0354, 1.0398, 1.0391, 1.0378,\n",
            "        1.0467, 1.0415, 1.0304, 1.0325, 1.0561, 1.0385, 1.0554, 1.0478, 1.0513,\n",
            "        1.0441, 1.0353, 1.0531, 1.0503, 1.0382, 1.0524, 1.0430, 1.0350, 1.0470,\n",
            "        1.0521, 1.0310, 1.0456, 1.0497, 1.0451, 1.0398, 1.0417, 1.0485, 1.0487,\n",
            "        1.0467, 1.0427, 1.0356, 1.0463, 1.0436, 1.0457, 1.0338, 1.0320, 1.0459,\n",
            "        1.0342, 1.0611, 1.0513, 1.0378, 1.0311, 1.0495, 1.0360, 1.0353, 1.0531,\n",
            "        1.0370, 1.0602, 1.0437, 1.0387, 1.0505, 1.0412, 1.0382, 1.0535, 1.0405,\n",
            "        1.0394, 1.0541, 1.0460, 1.0436, 1.0612, 1.0508, 1.0421, 1.0461, 1.0392,\n",
            "        1.0512, 1.0377, 1.0457, 1.0432, 1.0471, 1.0338, 1.0316, 1.0505, 1.0509,\n",
            "        1.0557, 1.0351, 1.0340, 1.0419, 1.0385, 1.0725, 1.0411, 1.0479, 1.0444,\n",
            "        1.0355, 1.0481, 1.0397, 1.0443, 1.0441, 1.0418, 1.0510, 1.0367, 1.0437,\n",
            "        1.0478, 1.0424, 1.0466, 1.0426, 1.0371, 1.0344, 1.0561, 1.0518, 1.0524,\n",
            "        1.0448, 1.0413, 1.0430, 1.0352, 1.0465, 1.0414, 1.0419, 1.0474, 1.0468,\n",
            "        1.0483, 1.0439, 1.0373, 1.0486, 1.0428, 1.0400, 1.0413, 1.0485, 1.0374,\n",
            "        1.0471, 1.0426, 1.0483, 1.0467, 1.0442, 1.0391, 1.0371, 1.0448, 1.0447,\n",
            "        1.0355, 1.0479, 1.0367, 1.0497, 1.0431, 1.0429, 1.0382, 1.0380, 1.0476,\n",
            "        1.0316, 1.0388, 1.0398, 1.0433, 1.0560, 1.0598, 1.0308, 1.0508, 1.0569,\n",
            "        1.0497, 1.0427, 1.0445, 1.0452, 1.0377, 1.0347, 1.0351, 1.0377, 1.0554,\n",
            "        1.0279, 1.0441, 1.0351, 1.0367, 1.0493, 1.0432, 1.0451, 1.0354, 1.0370,\n",
            "        1.0396, 1.0445, 1.0502, 1.0435, 1.0411, 1.0470, 1.0460, 1.0383, 1.0431,\n",
            "        1.0362, 1.0375, 1.0446, 1.0468, 1.0460, 1.0429, 1.0451, 1.0515, 1.0409,\n",
            "        1.0490, 1.0467, 1.0345, 1.0448, 1.0426, 1.0382, 1.0423, 1.0448, 1.0408,\n",
            "        1.0392, 1.0587, 1.0430, 1.0372, 1.0502, 1.0442, 1.0611, 1.0432, 1.0418,\n",
            "        1.0315, 1.0482, 1.0371, 1.0453, 1.0451, 1.0383], device='cuda:0')), ('inception_block_9.b2.4.bias', tensor([0.0174, 0.0306, 0.0142, 0.0220, 0.0201, 0.0337, 0.0331, 0.0210, 0.0220,\n",
            "        0.0241, 0.0410, 0.0228, 0.0216, 0.0191, 0.0255, 0.0313, 0.0178, 0.0309,\n",
            "        0.0197, 0.0296, 0.0247, 0.0206, 0.0282, 0.0284, 0.0342, 0.0275, 0.0154,\n",
            "        0.0194, 0.0193, 0.0270, 0.0253, 0.0196, 0.0238, 0.0389, 0.0226, 0.0237,\n",
            "        0.0238, 0.0122, 0.0269, 0.0240, 0.0140, 0.0188, 0.0239, 0.0331, 0.0177,\n",
            "        0.0162, 0.0180, 0.0207, 0.0407, 0.0307, 0.0201, 0.0252, 0.0378, 0.0327,\n",
            "        0.0255, 0.0179, 0.0209, 0.0248, 0.0251, 0.0275, 0.0252, 0.0182, 0.0234,\n",
            "        0.0255, 0.0210, 0.0181, 0.0242, 0.0243, 0.0264, 0.0267, 0.0121, 0.0215,\n",
            "        0.0298, 0.0224, 0.0231, 0.0237, 0.0258, 0.0247, 0.0252, 0.0186, 0.0230,\n",
            "        0.0302, 0.0204, 0.0106, 0.0125, 0.0138, 0.0129, 0.0232, 0.0268, 0.0236,\n",
            "        0.0283, 0.0241, 0.0219, 0.0310, 0.0262, 0.0249, 0.0319, 0.0237, 0.0184,\n",
            "        0.0186, 0.0235, 0.0217, 0.0219, 0.0287, 0.0210, 0.0116, 0.0285, 0.0288,\n",
            "        0.0101, 0.0250, 0.0215, 0.0206, 0.0177, 0.0169, 0.0264, 0.0226, 0.0264,\n",
            "        0.0153, 0.0292, 0.0325, 0.0198, 0.0373, 0.0199, 0.0238, 0.0273, 0.0203,\n",
            "        0.0254, 0.0210, 0.0178, 0.0259, 0.0193, 0.0172, 0.0261, 0.0220, 0.0159,\n",
            "        0.0281, 0.0191, 0.0306, 0.0147, 0.0258, 0.0157, 0.0190, 0.0237, 0.0144,\n",
            "        0.0183, 0.0208, 0.0245, 0.0259, 0.0154, 0.0243, 0.0205, 0.0163, 0.0182,\n",
            "        0.0201, 0.0173, 0.0149, 0.0243, 0.0177, 0.0128, 0.0194, 0.0111, 0.0206,\n",
            "        0.0245, 0.0262, 0.0271, 0.0213, 0.0270, 0.0262, 0.0211, 0.0179, 0.0236,\n",
            "        0.0214, 0.0244, 0.0273, 0.0198, 0.0163, 0.0144, 0.0204, 0.0225, 0.0175,\n",
            "        0.0257, 0.0238, 0.0132, 0.0150, 0.0365, 0.0192, 0.0336, 0.0253, 0.0272,\n",
            "        0.0315, 0.0090, 0.0248, 0.0261, 0.0166, 0.0275, 0.0257, 0.0126, 0.0263,\n",
            "        0.0310, 0.0144, 0.0219, 0.0247, 0.0258, 0.0217, 0.0237, 0.0277, 0.0230,\n",
            "        0.0217, 0.0244, 0.0141, 0.0247, 0.0258, 0.0188, 0.0161, 0.0132, 0.0212,\n",
            "        0.0186, 0.0290, 0.0274, 0.0178, 0.0111, 0.0282, 0.0132, 0.0160, 0.0316,\n",
            "        0.0214, 0.0287, 0.0246, 0.0238, 0.0262, 0.0234, 0.0204, 0.0299, 0.0178,\n",
            "        0.0241, 0.0303, 0.0219, 0.0272, 0.0294, 0.0239, 0.0203, 0.0228, 0.0183,\n",
            "        0.0226, 0.0174, 0.0260, 0.0174, 0.0231, 0.0178, 0.0141, 0.0239, 0.0274,\n",
            "        0.0293, 0.0203, 0.0142, 0.0237, 0.0158, 0.0385, 0.0241, 0.0257, 0.0263,\n",
            "        0.0156, 0.0240, 0.0213, 0.0280, 0.0246, 0.0236, 0.0240, 0.0221, 0.0255,\n",
            "        0.0209, 0.0139, 0.0268, 0.0197, 0.0199, 0.0097, 0.0304, 0.0232, 0.0293,\n",
            "        0.0241, 0.0221, 0.0210, 0.0188, 0.0222, 0.0206, 0.0219, 0.0224, 0.0269,\n",
            "        0.0250, 0.0237, 0.0167, 0.0261, 0.0162, 0.0210, 0.0167, 0.0222, 0.0190,\n",
            "        0.0188, 0.0218, 0.0315, 0.0260, 0.0211, 0.0255, 0.0186, 0.0205, 0.0262,\n",
            "        0.0142, 0.0303, 0.0135, 0.0230, 0.0203, 0.0240, 0.0176, 0.0209, 0.0223,\n",
            "        0.0131, 0.0214, 0.0219, 0.0244, 0.0310, 0.0317, 0.0099, 0.0267, 0.0322,\n",
            "        0.0270, 0.0215, 0.0261, 0.0256, 0.0196, 0.0184, 0.0228, 0.0178, 0.0279,\n",
            "        0.0118, 0.0170, 0.0169, 0.0170, 0.0253, 0.0185, 0.0147, 0.0168, 0.0152,\n",
            "        0.0197, 0.0275, 0.0254, 0.0196, 0.0211, 0.0231, 0.0222, 0.0159, 0.0236,\n",
            "        0.0194, 0.0187, 0.0211, 0.0245, 0.0230, 0.0237, 0.0175, 0.0250, 0.0230,\n",
            "        0.0215, 0.0244, 0.0188, 0.0231, 0.0225, 0.0188, 0.0226, 0.0201, 0.0185,\n",
            "        0.0224, 0.0305, 0.0195, 0.0218, 0.0219, 0.0226, 0.0350, 0.0160, 0.0176,\n",
            "        0.0141, 0.0274, 0.0218, 0.0254, 0.0248, 0.0241], device='cuda:0')), ('inception_block_9.b2.4.running_mean', tensor([-0.0900,  0.1182, -0.0158,  0.1749,  0.0530,  0.0132,  0.0573, -0.0481,\n",
            "         0.2078,  0.1730,  0.0606,  0.0956,  0.0848,  0.2120,  0.0818, -0.1527,\n",
            "        -0.0141,  0.1146,  0.2004,  0.0948,  0.0278,  0.0615, -0.0184,  0.0321,\n",
            "         0.3576,  0.1053,  0.0974, -0.0507,  0.4107,  0.2743, -0.2116,  0.1884,\n",
            "         0.3031,  0.3848,  0.0287,  0.2895,  0.3001,  0.1176,  0.2540,  0.2660,\n",
            "         0.2417, -0.1461,  0.4029,  0.0205,  0.2337,  0.0307,  0.1615,  0.3393,\n",
            "         0.0333, -0.0993,  0.3168,  0.1080,  0.0802, -0.0750,  0.1900,  0.2614,\n",
            "         0.2054,  0.2834,  0.0926,  0.1972,  0.3800,  0.1429,  0.1748,  0.2690,\n",
            "         0.4158,  0.1246,  0.0233, -0.2608, -0.0444,  0.0597,  0.4019,  0.1698,\n",
            "        -0.0756,  0.4890, -0.0193,  0.2692,  0.0049,  0.0411,  0.2849,  0.1455,\n",
            "         0.0679,  0.1709,  0.0121,  0.2443, -0.0071,  0.2771,  0.0109,  0.1616,\n",
            "         0.0842,  0.4414,  0.5056,  0.1811,  0.1324, -0.1674,  0.1523, -0.2713,\n",
            "         0.1332,  0.3569,  0.3814,  0.0497,  0.1608,  0.0054,  0.1846,  0.2217,\n",
            "         0.0898,  0.0211,  0.1206,  0.2458, -0.1395,  0.0686,  0.0645,  0.2534,\n",
            "         0.2568, -0.0373,  0.1373, -0.0395,  0.0733,  0.0595,  0.1446,  0.1954,\n",
            "         0.0260, -0.1963, -0.0200, -0.0231,  0.1319, -0.0131,  0.1464,  0.1160,\n",
            "         0.3532,  0.4629,  0.3212,  0.1116, -0.0916,  0.1031,  0.1807,  0.2083,\n",
            "        -0.0031,  0.2393,  0.1427,  0.0961, -0.0079,  0.2160,  0.1403,  0.0956,\n",
            "         0.2561,  0.1436,  0.3039, -0.2161,  0.3985,  0.2483,  0.2968,  0.1590,\n",
            "         0.0929,  0.3150,  0.0490,  0.1168, -0.2461,  0.2043,  0.0989,  0.0064,\n",
            "        -0.2626,  0.3201,  0.0917, -0.0471,  0.3394,  0.4031,  0.2888, -0.2135,\n",
            "         0.2436,  0.2658,  0.1122,  0.1938,  0.1596,  0.0906,  0.1536,  0.1892,\n",
            "         0.0733,  0.0856,  0.0230, -0.1905,  0.0785,  0.1953,  0.1672,  0.1026,\n",
            "         0.2776,  0.1544,  0.1212,  0.0320,  0.3163,  0.5864, -0.0175,  0.0716,\n",
            "         0.3220,  0.0721, -0.0499,  0.4017,  0.2698, -0.0604, -0.0013,  0.0896,\n",
            "         0.4449,  0.3447,  0.1520, -0.2010,  0.3713, -0.0037,  0.3923, -0.0026,\n",
            "         0.0386,  0.2780,  0.0165, -0.0512,  0.4024, -0.1359,  0.1660,  0.4389,\n",
            "         0.0541,  0.3655,  0.2688,  0.2021, -0.1200,  0.5803,  0.2833,  0.0613,\n",
            "        -0.0478,  0.0121,  0.3175,  0.5097,  0.1839,  0.4809,  0.1168,  0.1189,\n",
            "         0.1651,  0.2469,  0.3318,  0.1362,  0.1364,  0.0656,  0.4183, -0.0832,\n",
            "         0.0349,  0.0557,  0.2063,  0.0099, -0.0643,  0.0176,  0.0368,  0.4242,\n",
            "         0.0832,  0.1584, -0.0373,  0.5272,  0.1637, -0.0189,  0.2285,  0.1466,\n",
            "         0.1988,  0.4172, -0.0626,  0.4520,  0.0511,  0.2300, -0.2550,  0.1742,\n",
            "         0.2969,  0.1916, -0.1574,  0.3916,  0.3033,  0.4162,  0.2959,  0.0982,\n",
            "        -0.1756,  0.2176,  0.1279, -0.0512,  0.3656, -0.0460,  0.2055,  0.0451,\n",
            "        -0.0086, -0.1668,  0.1673,  0.0371,  0.1141,  0.2378, -0.1288,  0.1134,\n",
            "         0.0345, -0.0797,  0.2793,  0.0964,  0.1714,  0.0168, -0.0301,  0.1313,\n",
            "         0.0043,  0.2934,  0.0758,  0.2535,  0.4951,  0.0145,  0.2345,  0.0760,\n",
            "         0.2291,  0.3317,  0.1727, -0.0918,  0.2521,  0.2447,  0.2987,  0.2450,\n",
            "         0.0675,  0.3532, -0.0309,  0.0199,  0.1482,  0.0730,  0.1456,  0.1177,\n",
            "         0.0438,  0.1587,  0.2229,  0.0193,  0.3654,  0.1668,  0.2896,  0.0911,\n",
            "        -0.1153, -0.0943, -0.0021,  0.1565,  0.0631,  0.2473,  0.2193, -0.1442,\n",
            "        -0.1032,  0.1503, -0.1432,  0.3096, -0.0560,  0.0717,  0.4120, -0.0185,\n",
            "        -0.0466, -0.0024, -0.1469,  0.1871,  0.0992,  0.1883,  0.2117,  0.0923,\n",
            "         0.1743, -0.0209,  0.1541,  0.1083,  0.0607, -0.0250,  0.0258,  0.1910,\n",
            "         0.1810,  0.1539,  0.2162,  0.2948,  0.1323, -0.0359, -0.1385,  0.2889,\n",
            "         0.2342,  0.2959,  0.1858,  0.1712,  0.0532,  0.5095,  0.3424,  0.2819,\n",
            "         0.1991,  0.3116, -0.0910,  0.0948,  0.0214,  0.2291, -0.1033, -0.1375],\n",
            "       device='cuda:0')), ('inception_block_9.b2.4.running_var', tensor([0.6887, 0.6595, 0.6597, 0.6333, 0.6104, 0.8274, 0.7308, 0.6269, 0.6288,\n",
            "        0.7733, 0.7220, 0.7108, 0.7489, 0.6143, 0.6300, 0.5486, 0.5748, 0.6632,\n",
            "        0.6935, 0.6570, 0.8226, 0.5877, 0.7322, 0.6671, 0.8686, 0.6092, 0.6697,\n",
            "        0.6772, 0.7400, 0.7126, 0.7010, 0.7342, 0.6961, 0.6714, 0.7314, 0.6563,\n",
            "        0.5748, 0.6521, 0.7082, 0.7624, 0.6663, 0.7747, 0.6399, 0.6717, 0.7320,\n",
            "        0.6332, 0.6887, 0.7186, 0.9150, 0.7403, 0.8368, 0.7235, 0.5540, 0.7319,\n",
            "        0.7071, 0.6724, 0.7477, 0.5856, 0.6639, 0.6566, 0.5840, 0.5492, 0.6204,\n",
            "        0.7213, 0.5747, 0.7005, 0.6315, 0.5643, 0.6327, 0.6775, 0.6436, 0.5488,\n",
            "        0.8074, 0.6290, 0.6895, 0.7300, 0.6183, 0.5832, 0.7933, 0.5377, 0.7487,\n",
            "        0.8993, 0.6769, 0.6748, 0.7294, 0.7353, 0.6784, 0.6052, 0.6153, 0.7311,\n",
            "        0.6149, 0.6077, 0.8325, 0.5392, 0.6290, 0.6309, 0.8782, 0.7838, 0.6499,\n",
            "        0.6489, 0.7789, 0.6307, 0.8155, 0.6817, 0.5819, 0.6547, 0.6342, 0.7547,\n",
            "        0.7019, 0.6820, 0.7434, 0.7694, 0.6817, 0.6346, 0.7640, 0.6987, 0.8000,\n",
            "        0.6810, 0.8154, 0.7204, 0.7495, 0.5911, 0.6868, 0.5006, 0.7464, 0.5139,\n",
            "        0.6919, 0.7211, 0.8542, 0.8212, 0.7267, 0.6391, 0.7721, 0.6828, 0.6896,\n",
            "        0.7177, 0.6553, 0.5741, 0.7531, 0.6188, 0.5908, 0.6569, 0.8993, 0.6911,\n",
            "        0.6810, 0.7094, 0.6534, 0.5178, 0.7007, 0.7718, 0.6704, 0.5995, 0.7062,\n",
            "        0.7077, 0.7146, 0.6502, 0.8102, 0.7020, 0.7160, 0.6426, 0.6116, 0.7842,\n",
            "        0.7519, 0.7354, 0.8149, 0.6961, 0.6261, 0.6883, 0.7360, 0.7185, 0.6973,\n",
            "        0.7562, 0.6460, 0.6082, 0.6179, 0.6965, 0.6072, 0.7212, 0.7178, 0.5878,\n",
            "        0.6875, 0.7152, 0.7654, 0.6520, 0.9263, 0.6840, 0.6479, 0.6788, 0.7450,\n",
            "        0.7690, 0.6672, 0.7886, 0.7469, 0.7184, 0.4281, 0.7474, 0.6957, 0.6029,\n",
            "        0.5438, 0.6054, 0.7796, 0.6373, 0.7030, 0.6552, 0.7449, 0.8151, 0.8022,\n",
            "        0.8993, 0.8925, 0.7131, 0.7500, 0.7341, 0.5981, 0.5890, 0.7186, 0.8627,\n",
            "        0.8239, 0.7459, 0.7622, 0.7214, 0.6092, 0.7049, 0.8722, 0.6616, 0.7706,\n",
            "        0.5297, 0.6802, 0.8171, 0.6926, 0.7247, 0.8313, 0.8041, 0.6352, 0.6527,\n",
            "        0.8294, 0.6573, 0.6989, 0.6011, 0.7806, 0.7095, 0.7247, 0.5616, 0.6499,\n",
            "        0.5833, 0.5676, 0.7117, 0.8145, 0.7538, 0.7184, 0.7616, 0.6209, 0.8040,\n",
            "        0.6099, 0.8130, 0.7135, 0.7379, 0.6218, 0.6076, 0.8022, 0.6374, 0.8276,\n",
            "        0.6831, 0.6560, 0.6774, 0.7140, 0.6648, 0.7204, 0.8798, 0.7303, 0.7645,\n",
            "        0.8695, 0.7921, 0.7717, 0.7760, 0.5545, 0.8627, 0.7509, 0.5952, 0.6449,\n",
            "        0.6462, 0.7964, 0.5975, 0.5729, 0.7007, 0.6394, 0.7217, 0.6522, 0.6528,\n",
            "        0.7757, 0.5815, 0.6619, 0.6997, 0.6669, 0.5025, 0.6036, 0.6308, 0.7772,\n",
            "        0.7643, 0.6914, 0.7956, 0.8103, 0.6765, 0.7660, 0.6151, 0.8492, 0.8111,\n",
            "        0.7098, 0.7123, 0.7137, 0.5212, 0.7141, 0.5693, 0.8356, 0.6665, 0.6172,\n",
            "        0.7404, 0.7967, 0.6892, 0.6329, 0.7400, 0.5897, 0.6892, 0.7717, 0.8716,\n",
            "        0.6935, 0.6066, 0.6676, 0.5949, 0.7477, 0.6645, 0.7415, 0.5631, 0.6684,\n",
            "        0.7277, 0.7402, 0.6027, 0.6599, 0.6783, 0.7785, 0.8388, 0.7642, 0.6741,\n",
            "        0.7480, 0.8638, 0.5857, 0.8089, 0.6208, 0.5568, 0.7880, 0.7152, 0.6572,\n",
            "        0.7021, 0.7581, 0.6820, 0.6863, 0.6584, 0.7529, 0.6520, 0.6088, 0.6865,\n",
            "        0.8332, 0.5878, 0.7484, 0.6913, 0.7381, 0.6757, 0.5795, 0.7396, 0.5597,\n",
            "        0.6967, 0.7377, 0.7516, 0.8553, 0.7439, 0.7063, 0.8153, 0.9155, 0.7363,\n",
            "        0.7220, 0.6928, 0.7151, 0.6610, 0.6760, 0.6984], device='cuda:0')), ('inception_block_9.b2.4.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_9.b3.0.weight', tensor([[[[ 0.0003]],\n",
            "\n",
            "         [[-0.0002]],\n",
            "\n",
            "         [[-0.0116]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0082]],\n",
            "\n",
            "         [[ 0.0127]],\n",
            "\n",
            "         [[ 0.0198]]],\n",
            "\n",
            "\n",
            "        [[[-0.0175]],\n",
            "\n",
            "         [[-0.0313]],\n",
            "\n",
            "         [[ 0.0318]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0504]],\n",
            "\n",
            "         [[ 0.0037]],\n",
            "\n",
            "         [[-0.0029]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0339]],\n",
            "\n",
            "         [[-0.0178]],\n",
            "\n",
            "         [[ 0.0035]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0313]],\n",
            "\n",
            "         [[-0.0401]],\n",
            "\n",
            "         [[-0.0185]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0336]],\n",
            "\n",
            "         [[-0.0261]],\n",
            "\n",
            "         [[ 0.0248]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0417]],\n",
            "\n",
            "         [[ 0.0129]],\n",
            "\n",
            "         [[-0.0358]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0078]],\n",
            "\n",
            "         [[ 0.0137]],\n",
            "\n",
            "         [[ 0.0064]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0213]],\n",
            "\n",
            "         [[ 0.0134]],\n",
            "\n",
            "         [[-0.0036]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0216]],\n",
            "\n",
            "         [[-0.0073]],\n",
            "\n",
            "         [[-0.0201]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0292]],\n",
            "\n",
            "         [[ 0.0276]],\n",
            "\n",
            "         [[-0.0092]]]], device='cuda:0')), ('inception_block_9.b3.0.bias', tensor([ 0.0084,  0.0083,  0.0039, -0.0280,  0.0180,  0.0184,  0.0211,  0.0209,\n",
            "         0.0269, -0.0073,  0.0052,  0.0027, -0.0215,  0.0206,  0.0169,  0.0095,\n",
            "         0.0100, -0.0031, -0.0161, -0.0167, -0.0193,  0.0286,  0.0271, -0.0254,\n",
            "        -0.0284,  0.0304,  0.0133,  0.0205,  0.0190,  0.0178, -0.0056,  0.0211,\n",
            "        -0.0310,  0.0282, -0.0077,  0.0338, -0.0053,  0.0065,  0.0328, -0.0046,\n",
            "        -0.0251, -0.0105,  0.0213, -0.0136, -0.0285,  0.0034,  0.0331, -0.0027],\n",
            "       device='cuda:0')), ('inception_block_9.b3.1.weight', tensor([0.9940, 1.0023, 0.9926, 1.0005, 1.0005, 1.0052, 1.0034, 1.0064, 0.9915,\n",
            "        0.9974, 0.9832, 1.0059, 1.0112, 0.9984, 1.0005, 1.0007, 1.0058, 0.9965,\n",
            "        1.0032, 1.0001, 1.0057, 0.9846, 0.9958, 0.9912, 0.9993, 0.9957, 1.0015,\n",
            "        0.9874, 0.9979, 0.9994, 1.0053, 1.0058, 1.0055, 0.9957, 0.9926, 0.9976,\n",
            "        1.0023, 0.9997, 0.9898, 1.0034, 0.9977, 0.9947, 1.0020, 1.0064, 1.0106,\n",
            "        0.9945, 0.9964, 0.9985], device='cuda:0')), ('inception_block_9.b3.1.bias', tensor([-4.1618e-03, -8.6774e-03, -5.4239e-03, -4.9584e-03, -1.7270e-02,\n",
            "        -5.9380e-03, -2.8587e-03, -1.4817e-02, -3.0788e-03, -1.3090e-02,\n",
            "        -1.5832e-02,  6.7390e-03, -3.1397e-03, -9.2780e-03, -9.3524e-03,\n",
            "        -1.0101e-04, -6.7534e-03, -1.9947e-02, -1.4582e-03, -5.1401e-03,\n",
            "        -1.8533e-02, -6.7366e-03, -1.1797e-02, -5.6367e-03, -1.3499e-02,\n",
            "        -4.3204e-03, -8.7994e-03, -1.4119e-02, -3.4036e-03, -4.1544e-03,\n",
            "        -5.0625e-03, -1.6243e-02, -1.3798e-02, -1.6499e-03, -8.6876e-03,\n",
            "        -9.1922e-03, -1.4784e-02, -7.8044e-03, -1.9143e-02, -9.9255e-03,\n",
            "        -2.1764e-03, -1.8618e-02, -1.6480e-02, -1.1537e-02, -5.2383e-04,\n",
            "        -1.0332e-02,  8.5965e-05, -1.5434e-02], device='cuda:0')), ('inception_block_9.b3.1.running_mean', tensor([-0.6498, -1.0216, -0.2282, -0.7726, -0.2075, -0.2262,  0.0639, -0.8689,\n",
            "         0.2280, -0.3949, -0.5507, -0.8659,  0.1834,  0.0685, -0.1700, -0.4748,\n",
            "        -0.2660, -0.2625,  0.1877, -0.2023, -0.3962,  0.3403, -0.3222,  0.3762,\n",
            "        -0.6495, -0.7950, -0.5161,  0.0813, -0.8229, -0.2166, -0.1761,  0.4036,\n",
            "        -0.8254,  0.1784, -0.0070, -0.6390, -0.2423, -0.5620,  0.3428, -1.0944,\n",
            "         0.5109, -0.2096, -0.3500, -0.3330,  0.3668,  0.0098,  0.1362, -0.4709],\n",
            "       device='cuda:0')), ('inception_block_9.b3.1.running_var', tensor([0.2332, 0.1594, 0.2842, 0.1388, 0.1680, 0.2275, 0.2279, 0.2108, 0.1801,\n",
            "        0.3043, 0.2417, 0.3098, 0.2213, 0.2282, 0.1932, 0.2726, 0.1722, 0.2247,\n",
            "        0.3392, 0.2124, 0.1716, 0.2281, 0.1680, 0.1849, 0.2185, 0.2290, 0.1996,\n",
            "        0.1987, 0.2186, 0.2928, 0.1528, 0.1324, 0.2352, 0.1710, 0.2478, 0.2530,\n",
            "        0.1948, 0.2109, 0.1765, 0.2474, 0.1776, 0.2488, 0.2155, 0.2479, 0.2481,\n",
            "        0.3055, 0.3094, 0.1704], device='cuda:0')), ('inception_block_9.b3.1.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_9.b3.3.weight', tensor([[[[ 0.0360,  0.0505, -0.0026],\n",
            "          [-0.0245, -0.0431,  0.0147],\n",
            "          [ 0.0209, -0.0023,  0.0376]],\n",
            "\n",
            "         [[-0.0156, -0.0370,  0.0044],\n",
            "          [-0.0530, -0.0325, -0.0141],\n",
            "          [-0.0505,  0.0068,  0.0227]],\n",
            "\n",
            "         [[ 0.0111,  0.0010, -0.0426],\n",
            "          [ 0.0377, -0.0420, -0.0270],\n",
            "          [-0.0058,  0.0373, -0.0248]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0390, -0.0391, -0.0256],\n",
            "          [-0.0347, -0.0480, -0.0314],\n",
            "          [ 0.0376,  0.0423, -0.0402]],\n",
            "\n",
            "         [[ 0.0088,  0.0162, -0.0306],\n",
            "          [-0.0158, -0.0368,  0.0351],\n",
            "          [ 0.0374,  0.0384, -0.0450]],\n",
            "\n",
            "         [[ 0.0106, -0.0082, -0.0210],\n",
            "          [ 0.0008, -0.0334,  0.0204],\n",
            "          [ 0.0103,  0.0127,  0.0040]]],\n",
            "\n",
            "\n",
            "        [[[-0.0192,  0.0494, -0.0336],\n",
            "          [ 0.0383,  0.0221, -0.0052],\n",
            "          [-0.0267,  0.0436,  0.0243]],\n",
            "\n",
            "         [[-0.0343, -0.0018,  0.0567],\n",
            "          [ 0.0035,  0.0040,  0.0170],\n",
            "          [ 0.0225,  0.0203, -0.0227]],\n",
            "\n",
            "         [[ 0.0347, -0.0319,  0.0330],\n",
            "          [-0.0394,  0.0206,  0.0007],\n",
            "          [-0.0037, -0.0511, -0.0581]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0017,  0.0323, -0.0036],\n",
            "          [ 0.0251, -0.0517, -0.0414],\n",
            "          [-0.0182, -0.0287,  0.0088]],\n",
            "\n",
            "         [[ 0.0456, -0.0418, -0.0303],\n",
            "          [-0.0235,  0.0211,  0.0289],\n",
            "          [ 0.0432,  0.0204, -0.0187]],\n",
            "\n",
            "         [[-0.0222,  0.0083,  0.0233],\n",
            "          [-0.0427, -0.0456,  0.0145],\n",
            "          [-0.0284, -0.0302, -0.0028]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0485,  0.0181,  0.0377],\n",
            "          [ 0.0421, -0.0495,  0.0123],\n",
            "          [-0.0243, -0.0339,  0.0115]],\n",
            "\n",
            "         [[-0.0246, -0.0353, -0.0174],\n",
            "          [ 0.0030, -0.0195, -0.0037],\n",
            "          [ 0.0553,  0.0139,  0.0487]],\n",
            "\n",
            "         [[ 0.0381,  0.0367,  0.0164],\n",
            "          [ 0.0076,  0.0315,  0.0150],\n",
            "          [-0.0346, -0.0331, -0.0101]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0154, -0.0335,  0.0438],\n",
            "          [-0.0305, -0.0052, -0.0302],\n",
            "          [-0.0040, -0.0113,  0.0095]],\n",
            "\n",
            "         [[ 0.0182,  0.0496, -0.0383],\n",
            "          [-0.0099,  0.0265, -0.0416],\n",
            "          [ 0.0401,  0.0063,  0.0003]],\n",
            "\n",
            "         [[-0.0367, -0.0111, -0.0042],\n",
            "          [ 0.0462,  0.0443, -0.0327],\n",
            "          [-0.0235,  0.0453, -0.0078]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0022,  0.0396,  0.0116],\n",
            "          [ 0.0267, -0.0283, -0.0227],\n",
            "          [-0.0355, -0.0348, -0.0396]],\n",
            "\n",
            "         [[-0.0218,  0.0221, -0.0117],\n",
            "          [-0.0051, -0.0457,  0.0096],\n",
            "          [ 0.0227,  0.0037,  0.0038]],\n",
            "\n",
            "         [[ 0.0454,  0.0313,  0.0287],\n",
            "          [-0.0263,  0.0175, -0.0351],\n",
            "          [-0.0178,  0.0405, -0.0211]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0096, -0.0037, -0.0131],\n",
            "          [-0.0133, -0.0050,  0.0055],\n",
            "          [ 0.0283, -0.0482, -0.0524]],\n",
            "\n",
            "         [[-0.0386,  0.0372,  0.0328],\n",
            "          [ 0.0264, -0.0437, -0.0370],\n",
            "          [-0.0426, -0.0329, -0.0143]],\n",
            "\n",
            "         [[-0.0261, -0.0161,  0.0475],\n",
            "          [ 0.0310,  0.0319,  0.0158],\n",
            "          [-0.0137,  0.0517,  0.0323]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0129,  0.0152,  0.0410],\n",
            "          [ 0.0048,  0.0042,  0.0144],\n",
            "          [-0.0061, -0.0075,  0.0509]],\n",
            "\n",
            "         [[ 0.0474, -0.0173, -0.0151],\n",
            "          [ 0.0299,  0.0319, -0.0068],\n",
            "          [ 0.0395,  0.0090, -0.0118]],\n",
            "\n",
            "         [[ 0.0081,  0.0390,  0.0156],\n",
            "          [ 0.0460, -0.0010,  0.0336],\n",
            "          [ 0.0072, -0.0052,  0.0367]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0137, -0.0246,  0.0463],\n",
            "          [ 0.0407, -0.0010,  0.0209],\n",
            "          [-0.0132,  0.0004,  0.0083]],\n",
            "\n",
            "         [[-0.0413,  0.0112,  0.0342],\n",
            "          [-0.0351, -0.0334,  0.0076],\n",
            "          [ 0.0438, -0.0072, -0.0102]],\n",
            "\n",
            "         [[-0.0345,  0.0309, -0.0133],\n",
            "          [ 0.0286,  0.0329, -0.0368],\n",
            "          [ 0.0149,  0.0185, -0.0132]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0093,  0.0505,  0.0052],\n",
            "          [ 0.0222,  0.0404, -0.0255],\n",
            "          [-0.0087, -0.0262,  0.0250]],\n",
            "\n",
            "         [[-0.0217,  0.0014, -0.0046],\n",
            "          [ 0.0434,  0.0211, -0.0231],\n",
            "          [ 0.0424,  0.0284, -0.0068]],\n",
            "\n",
            "         [[ 0.0428,  0.0069,  0.0080],\n",
            "          [ 0.0259, -0.0452,  0.0356],\n",
            "          [ 0.0252, -0.0124, -0.0146]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0168, -0.0299,  0.0204],\n",
            "          [-0.0172,  0.0049,  0.0198],\n",
            "          [ 0.0283,  0.0202,  0.0115]],\n",
            "\n",
            "         [[-0.0295,  0.0289,  0.0033],\n",
            "          [-0.0412, -0.0210,  0.0392],\n",
            "          [ 0.0091,  0.0290, -0.0114]],\n",
            "\n",
            "         [[-0.0069, -0.0417, -0.0510],\n",
            "          [ 0.0039,  0.0103, -0.0303],\n",
            "          [-0.0394,  0.0352, -0.0172]]]], device='cuda:0')), ('inception_block_9.b3.3.bias', tensor([ 0.0156, -0.0326,  0.0154,  0.0088,  0.0464, -0.0056, -0.0434, -0.0118,\n",
            "         0.0390,  0.0006, -0.0146, -0.0076,  0.0174, -0.0287,  0.0397,  0.0460,\n",
            "         0.0464,  0.0019, -0.0420,  0.0351,  0.0277,  0.0267, -0.0221,  0.0034,\n",
            "        -0.0033,  0.0051,  0.0233,  0.0407, -0.0349,  0.0412,  0.0159, -0.0140,\n",
            "         0.0090,  0.0269,  0.0033, -0.0099, -0.0416,  0.0340,  0.0396, -0.0353,\n",
            "        -0.0477, -0.0401, -0.0435, -0.0444, -0.0177,  0.0262, -0.0119,  0.0251,\n",
            "        -0.0148,  0.0481,  0.0350, -0.0326, -0.0454,  0.0265, -0.0152, -0.0409,\n",
            "         0.0196,  0.0407,  0.0373,  0.0361,  0.0281, -0.0199, -0.0359,  0.0016,\n",
            "        -0.0465,  0.0228,  0.0203, -0.0375,  0.0325,  0.0076, -0.0031, -0.0412,\n",
            "         0.0240,  0.0264,  0.0245, -0.0053, -0.0227,  0.0093, -0.0351,  0.0445,\n",
            "         0.0198, -0.0004,  0.0207, -0.0153, -0.0189, -0.0350, -0.0040, -0.0392,\n",
            "         0.0312,  0.0446, -0.0057,  0.0457, -0.0268,  0.0117, -0.0435,  0.0121,\n",
            "         0.0332,  0.0457, -0.0246,  0.0102,  0.0409, -0.0332, -0.0018, -0.0307,\n",
            "         0.0477, -0.0234, -0.0218,  0.0329, -0.0218, -0.0371,  0.0207, -0.0480,\n",
            "        -0.0455, -0.0179, -0.0119,  0.0261, -0.0131,  0.0011, -0.0152,  0.0266,\n",
            "         0.0392,  0.0330,  0.0137, -0.0166,  0.0013, -0.0098,  0.0198, -0.0262],\n",
            "       device='cuda:0')), ('inception_block_9.b3.4.weight', tensor([0.9936, 1.0018, 1.0187, 1.0196, 0.9973, 0.9978, 0.9982, 0.9893, 1.0053,\n",
            "        0.9936, 1.0110, 1.0096, 1.0034, 0.9964, 1.0054, 0.9888, 1.0039, 1.0047,\n",
            "        0.9948, 0.9940, 0.9995, 0.9974, 1.0021, 0.9991, 1.0007, 0.9907, 0.9991,\n",
            "        0.9961, 0.9868, 0.9901, 1.0060, 0.9891, 1.0033, 0.9996, 1.0036, 0.9918,\n",
            "        0.9878, 0.9980, 0.9819, 0.9923, 0.9836, 1.0001, 0.9961, 0.9975, 1.0007,\n",
            "        1.0032, 1.0143, 1.0076, 0.9869, 0.9953, 0.9869, 0.9842, 1.0052, 0.9930,\n",
            "        0.9852, 1.0034, 0.9963, 0.9973, 0.9944, 0.9847, 1.0077, 1.0047, 0.9967,\n",
            "        1.0039, 0.9952, 1.0043, 0.9901, 0.9950, 1.0041, 1.0148, 0.9922, 1.0002,\n",
            "        0.9929, 1.0068, 0.9998, 0.9895, 0.9921, 1.0013, 1.0009, 0.9831, 1.0026,\n",
            "        0.9983, 1.0137, 0.9983, 0.9826, 1.0035, 0.9858, 1.0005, 1.0165, 0.9863,\n",
            "        0.9877, 0.9836, 0.9790, 0.9958, 0.9972, 0.9960, 1.0044, 0.9983, 1.0013,\n",
            "        0.9898, 0.9965, 0.9878, 0.9962, 1.0027, 0.9968, 1.0005, 0.9927, 1.0087,\n",
            "        1.0096, 0.9832, 1.0263, 0.9951, 1.0046, 0.9940, 0.9990, 0.9975, 1.0106,\n",
            "        0.9959, 0.9966, 1.0035, 0.9824, 1.0022, 1.0066, 0.9810, 0.9883, 1.0083,\n",
            "        1.0047, 0.9910], device='cuda:0')), ('inception_block_9.b3.4.bias', tensor([-0.0045,  0.0037,  0.0054, -0.0071,  0.0007, -0.0025, -0.0011, -0.0064,\n",
            "        -0.0024, -0.0090,  0.0023, -0.0072, -0.0028, -0.0049, -0.0020, -0.0029,\n",
            "        -0.0057, -0.0065, -0.0135, -0.0162, -0.0134, -0.0004, -0.0010, -0.0024,\n",
            "         0.0007, -0.0040, -0.0071,  0.0017, -0.0075, -0.0093, -0.0026, -0.0066,\n",
            "        -0.0049, -0.0057, -0.0004, -0.0043, -0.0162, -0.0046, -0.0099,  0.0054,\n",
            "        -0.0104, -0.0142, -0.0039, -0.0013, -0.0036, -0.0052, -0.0084,  0.0021,\n",
            "        -0.0068, -0.0042, -0.0035, -0.0160, -0.0012, -0.0109, -0.0063, -0.0051,\n",
            "         0.0020, -0.0134, -0.0044, -0.0105,  0.0052, -0.0101, -0.0061, -0.0059,\n",
            "        -0.0070, -0.0126, -0.0096, -0.0037,  0.0010,  0.0020, -0.0085, -0.0039,\n",
            "        -0.0024, -0.0019,  0.0020, -0.0154, -0.0142, -0.0025,  0.0035, -0.0086,\n",
            "        -0.0198,  0.0015,  0.0066, -0.0023, -0.0147,  0.0052, -0.0196,  0.0074,\n",
            "        -0.0026, -0.0064, -0.0164, -0.0153, -0.0174,  0.0027, -0.0036, -0.0123,\n",
            "        -0.0100, -0.0085, -0.0086, -0.0046, -0.0056, -0.0058, -0.0021, -0.0098,\n",
            "        -0.0066, -0.0041, -0.0137,  0.0018, -0.0035, -0.0097,  0.0048, -0.0092,\n",
            "        -0.0010, -0.0056, -0.0027, -0.0121, -0.0006,  0.0044, -0.0045, -0.0088,\n",
            "        -0.0115, -0.0051, -0.0083, -0.0068, -0.0080,  0.0071, -0.0076,  0.0022],\n",
            "       device='cuda:0')), ('inception_block_9.b3.4.running_mean', tensor([-0.2032, -0.2895, -0.0041, -0.2202,  0.3164,  0.3206, -0.3046, -0.2367,\n",
            "        -0.0968, -0.3129, -0.1671, -0.1357,  0.1382, -0.1448, -0.0832,  0.0025,\n",
            "        -0.3647, -0.0691, -0.1625, -0.2055, -0.1280,  0.0732, -0.1722,  0.0561,\n",
            "        -0.3090,  0.1260, -0.0788, -0.0206, -0.1577,  0.7785, -0.0745,  0.4924,\n",
            "         0.1127, -0.0805, -0.5141,  0.0698, -0.1151, -0.4430,  0.1399, -0.4755,\n",
            "        -0.0161, -0.0872,  0.1932, -0.3423, -0.1126,  0.0169, -0.0595, -0.1303,\n",
            "        -0.4457, -0.2750,  0.1744, -0.3181, -0.4835, -0.0434, -0.0271, -0.8534,\n",
            "        -0.3283, -0.0996,  0.1407,  0.0426, -0.1792, -0.2052,  0.0222, -0.2566,\n",
            "        -0.2593,  0.0729, -0.1157, -0.2507, -0.0254, -0.2340, -0.5682, -0.3838,\n",
            "        -0.5374, -0.3549, -0.2557,  0.0522, -0.6111, -0.4498, -0.1227,  0.0339,\n",
            "         0.1024, -0.2887, -0.2922, -0.0142,  0.0985, -0.6026, -0.3663,  0.0369,\n",
            "        -0.1113, -0.2709, -0.4138, -0.4726,  0.0767, -0.3118,  0.1322,  0.0484,\n",
            "        -0.0504, -0.1192,  0.0128, -0.0583, -0.1744, -0.5113, -0.2236, -0.0643,\n",
            "        -0.2294, -0.2878, -0.3471, -0.2137,  0.0222, -0.7093, -0.2336, -0.4311,\n",
            "        -0.3545, -0.4711, -0.1470, -0.2207, -0.1830, -0.3034, -0.1710, -0.0478,\n",
            "         0.0066,  0.0644, -0.0968, -0.1069, -0.2951, -0.2872,  0.0172, -0.0036],\n",
            "       device='cuda:0')), ('inception_block_9.b3.4.running_var', tensor([0.1669, 0.1771, 0.1647, 0.1674, 0.1936, 0.2483, 0.2372, 0.1776, 0.1801,\n",
            "        0.2688, 0.1817, 0.1796, 0.2000, 0.2299, 0.2298, 0.2095, 0.2244, 0.1941,\n",
            "        0.2042, 0.2210, 0.2431, 0.2058, 0.2023, 0.2045, 0.2632, 0.1746, 0.2087,\n",
            "        0.2460, 0.1344, 0.2934, 0.1521, 0.2769, 0.2325, 0.1839, 0.2821, 0.1391,\n",
            "        0.2638, 0.2443, 0.1704, 0.3106, 0.1949, 0.2157, 0.2276, 0.1859, 0.1866,\n",
            "        0.2067, 0.1631, 0.2432, 0.2822, 0.3114, 0.2575, 0.1694, 0.2306, 0.1998,\n",
            "        0.1935, 0.4163, 0.3015, 0.1644, 0.1848, 0.1100, 0.2819, 0.2700, 0.1848,\n",
            "        0.2597, 0.2183, 0.1937, 0.1339, 0.2106, 0.1859, 0.2094, 0.2510, 0.1862,\n",
            "        0.2106, 0.1892, 0.1855, 0.2150, 0.1880, 0.3094, 0.1356, 0.2125, 0.2731,\n",
            "        0.1718, 0.1842, 0.1967, 0.2155, 0.2505, 0.2088, 0.2795, 0.2034, 0.1652,\n",
            "        0.2387, 0.2568, 0.2053, 0.1669, 0.2559, 0.1660, 0.1887, 0.2367, 0.2670,\n",
            "        0.1969, 0.2369, 0.2967, 0.1789, 0.2185, 0.1619, 0.2155, 0.1484, 0.1564,\n",
            "        0.1927, 0.3002, 0.1588, 0.1549, 0.1677, 0.1866, 0.2023, 0.1425, 0.2288,\n",
            "        0.2624, 0.2267, 0.2791, 0.1978, 0.1937, 0.1600, 0.1566, 0.1845, 0.2912,\n",
            "        0.2206, 0.2126], device='cuda:0')), ('inception_block_9.b3.4.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_9.b3.6.weight', tensor([[[[ 0.0092,  0.0180,  0.0134],\n",
            "          [ 0.0198, -0.0071,  0.0230],\n",
            "          [-0.0191,  0.0248,  0.0126]],\n",
            "\n",
            "         [[ 0.0266,  0.0034, -0.0002],\n",
            "          [ 0.0092,  0.0200,  0.0259],\n",
            "          [ 0.0294,  0.0236,  0.0091]],\n",
            "\n",
            "         [[ 0.0222,  0.0298,  0.0019],\n",
            "          [ 0.0331,  0.0311,  0.0013],\n",
            "          [-0.0082,  0.0183,  0.0372]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0192,  0.0137,  0.0182],\n",
            "          [ 0.0280,  0.0275, -0.0290],\n",
            "          [-0.0031, -0.0241, -0.0242]],\n",
            "\n",
            "         [[-0.0042, -0.0166, -0.0235],\n",
            "          [ 0.0017,  0.0302, -0.0278],\n",
            "          [-0.0081, -0.0083, -0.0015]],\n",
            "\n",
            "         [[ 0.0005,  0.0033,  0.0082],\n",
            "          [-0.0004, -0.0318,  0.0061],\n",
            "          [ 0.0016,  0.0104, -0.0365]]],\n",
            "\n",
            "\n",
            "        [[[-0.0269,  0.0234, -0.0268],\n",
            "          [-0.0185,  0.0235, -0.0242],\n",
            "          [ 0.0125,  0.0203, -0.0224]],\n",
            "\n",
            "         [[ 0.0346, -0.0187,  0.0283],\n",
            "          [ 0.0322, -0.0168,  0.0064],\n",
            "          [ 0.0040, -0.0048,  0.0334]],\n",
            "\n",
            "         [[-0.0256,  0.0169, -0.0231],\n",
            "          [ 0.0182,  0.0153, -0.0246],\n",
            "          [-0.0383, -0.0247, -0.0238]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0140, -0.0084, -0.0008],\n",
            "          [ 0.0209, -0.0094, -0.0392],\n",
            "          [-0.0126,  0.0147, -0.0316]],\n",
            "\n",
            "         [[-0.0279,  0.0054,  0.0045],\n",
            "          [ 0.0205, -0.0257, -0.0085],\n",
            "          [ 0.0198, -0.0263, -0.0341]],\n",
            "\n",
            "         [[ 0.0267,  0.0025,  0.0276],\n",
            "          [ 0.0217, -0.0222, -0.0013],\n",
            "          [-0.0150,  0.0094, -0.0218]]],\n",
            "\n",
            "\n",
            "        [[[-0.0050, -0.0225,  0.0231],\n",
            "          [ 0.0028,  0.0179, -0.0241],\n",
            "          [-0.0033, -0.0022, -0.0263]],\n",
            "\n",
            "         [[ 0.0239, -0.0115,  0.0003],\n",
            "          [-0.0095,  0.0139, -0.0053],\n",
            "          [ 0.0217,  0.0023, -0.0093]],\n",
            "\n",
            "         [[ 0.0024,  0.0059, -0.0142],\n",
            "          [ 0.0097,  0.0264,  0.0078],\n",
            "          [-0.0072,  0.0343,  0.0046]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0026,  0.0264,  0.0243],\n",
            "          [-0.0142, -0.0126, -0.0116],\n",
            "          [-0.0063,  0.0213,  0.0108]],\n",
            "\n",
            "         [[-0.0127,  0.0216,  0.0203],\n",
            "          [ 0.0025, -0.0095,  0.0138],\n",
            "          [-0.0053, -0.0186, -0.0123]],\n",
            "\n",
            "         [[-0.0206, -0.0092, -0.0132],\n",
            "          [-0.0066,  0.0123, -0.0098],\n",
            "          [ 0.0130,  0.0067,  0.0053]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0110,  0.0327,  0.0052],\n",
            "          [-0.0022,  0.0194,  0.0016],\n",
            "          [ 0.0325,  0.0060,  0.0191]],\n",
            "\n",
            "         [[ 0.0115,  0.0111, -0.0079],\n",
            "          [-0.0207,  0.0137, -0.0197],\n",
            "          [-0.0044,  0.0183, -0.0106]],\n",
            "\n",
            "         [[-0.0035, -0.0126, -0.0060],\n",
            "          [ 0.0026, -0.0226,  0.0075],\n",
            "          [-0.0028, -0.0125, -0.0281]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0020, -0.0154, -0.0121],\n",
            "          [-0.0037,  0.0185, -0.0399],\n",
            "          [-0.0266, -0.0263,  0.0081]],\n",
            "\n",
            "         [[-0.0079, -0.0280,  0.0036],\n",
            "          [ 0.0036,  0.0027,  0.0129],\n",
            "          [-0.0253, -0.0008, -0.0055]],\n",
            "\n",
            "         [[ 0.0172,  0.0218,  0.0260],\n",
            "          [-0.0089,  0.0140, -0.0235],\n",
            "          [-0.0029,  0.0130,  0.0085]]],\n",
            "\n",
            "\n",
            "        [[[-0.0189,  0.0100, -0.0306],\n",
            "          [-0.0346,  0.0210,  0.0063],\n",
            "          [ 0.0141,  0.0197, -0.0300]],\n",
            "\n",
            "         [[ 0.0129,  0.0252, -0.0303],\n",
            "          [ 0.0157,  0.0080, -0.0282],\n",
            "          [-0.0188, -0.0012,  0.0035]],\n",
            "\n",
            "         [[-0.0045, -0.0246, -0.0064],\n",
            "          [-0.0016,  0.0107,  0.0168],\n",
            "          [-0.0203, -0.0149, -0.0151]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0270,  0.0223, -0.0047],\n",
            "          [ 0.0225,  0.0318,  0.0134],\n",
            "          [-0.0095, -0.0047,  0.0044]],\n",
            "\n",
            "         [[-0.0369, -0.0168, -0.0367],\n",
            "          [ 0.0072,  0.0113, -0.0246],\n",
            "          [-0.0023, -0.0072,  0.0070]],\n",
            "\n",
            "         [[ 0.0219,  0.0086, -0.0078],\n",
            "          [ 0.0064, -0.0101,  0.0250],\n",
            "          [ 0.0015, -0.0140,  0.0057]]],\n",
            "\n",
            "\n",
            "        [[[-0.0269,  0.0038,  0.0197],\n",
            "          [ 0.0176,  0.0147,  0.0153],\n",
            "          [ 0.0266, -0.0173,  0.0169]],\n",
            "\n",
            "         [[ 0.0096,  0.0101,  0.0088],\n",
            "          [-0.0247, -0.0206,  0.0113],\n",
            "          [ 0.0159, -0.0308, -0.0252]],\n",
            "\n",
            "         [[-0.0071,  0.0226,  0.0006],\n",
            "          [-0.0193,  0.0036, -0.0229],\n",
            "          [ 0.0300,  0.0301, -0.0191]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0216,  0.0190,  0.0462],\n",
            "          [ 0.0072,  0.0293,  0.0065],\n",
            "          [ 0.0268,  0.0167,  0.0140]],\n",
            "\n",
            "         [[-0.0291, -0.0253,  0.0077],\n",
            "          [ 0.0172, -0.0239,  0.0089],\n",
            "          [-0.0222, -0.0101, -0.0096]],\n",
            "\n",
            "         [[-0.0229, -0.0243,  0.0260],\n",
            "          [ 0.0114, -0.0007,  0.0057],\n",
            "          [ 0.0179, -0.0037, -0.0223]]]], device='cuda:0')), ('inception_block_9.b3.6.bias', tensor([ 0.0134, -0.0146, -0.0279,  0.0113,  0.0085, -0.0027,  0.0077,  0.0197,\n",
            "        -0.0239,  0.0078, -0.0238, -0.0063,  0.0108, -0.0090,  0.0203,  0.0060,\n",
            "         0.0267,  0.0172,  0.0180,  0.0160,  0.0232, -0.0140, -0.0135,  0.0123,\n",
            "        -0.0017,  0.0224, -0.0180, -0.0281, -0.0253,  0.0097, -0.0070,  0.0046,\n",
            "        -0.0160, -0.0162,  0.0120,  0.0049,  0.0179, -0.0023, -0.0032,  0.0176,\n",
            "         0.0248,  0.0203, -0.0278,  0.0060, -0.0123, -0.0194, -0.0240, -0.0266,\n",
            "        -0.0010,  0.0242, -0.0041,  0.0010, -0.0002, -0.0205,  0.0169, -0.0128,\n",
            "         0.0273, -0.0118, -0.0253, -0.0216,  0.0250,  0.0076,  0.0073, -0.0053,\n",
            "         0.0125,  0.0267,  0.0228,  0.0102, -0.0244,  0.0143,  0.0033,  0.0126,\n",
            "         0.0281,  0.0007,  0.0039, -0.0146, -0.0095, -0.0057,  0.0007,  0.0194,\n",
            "        -0.0176, -0.0030, -0.0157,  0.0217, -0.0275,  0.0104, -0.0252,  0.0056,\n",
            "        -0.0139,  0.0270, -0.0138,  0.0106, -0.0110, -0.0124, -0.0202, -0.0127,\n",
            "         0.0153, -0.0209, -0.0118,  0.0185,  0.0011, -0.0228, -0.0288, -0.0101,\n",
            "        -0.0183, -0.0077, -0.0176, -0.0287,  0.0131,  0.0029,  0.0102,  0.0234,\n",
            "        -0.0039, -0.0022,  0.0238,  0.0035, -0.0249,  0.0251,  0.0216,  0.0060,\n",
            "         0.0065,  0.0061,  0.0065, -0.0030, -0.0023, -0.0099,  0.0256,  0.0181],\n",
            "       device='cuda:0')), ('inception_block_9.b3.7.weight', tensor([1.0538, 1.0550, 1.0546, 1.0460, 1.0620, 1.0424, 1.0409, 1.0259, 1.0507,\n",
            "        1.0345, 1.0501, 1.0459, 1.0460, 1.0414, 1.0519, 1.0354, 1.0473, 1.0599,\n",
            "        1.0531, 1.0512, 1.0428, 1.0447, 1.0494, 1.0372, 1.0513, 1.0497, 1.0529,\n",
            "        1.0332, 1.0381, 1.0384, 1.0382, 1.0420, 1.0457, 1.0452, 1.0484, 1.0515,\n",
            "        1.0379, 1.0372, 1.0320, 1.0392, 1.0523, 1.0435, 1.0375, 1.0398, 1.0435,\n",
            "        1.0464, 1.0491, 1.0466, 1.0499, 1.0560, 1.0467, 1.0632, 1.0453, 1.0334,\n",
            "        1.0490, 1.0418, 1.0536, 1.0524, 1.0507, 1.0464, 1.0510, 1.0350, 1.0389,\n",
            "        1.0560, 1.0457, 1.0469, 1.0435, 1.0379, 1.0479, 1.0443, 1.0517, 1.0478,\n",
            "        1.0446, 1.0545, 1.0498, 1.0362, 1.0490, 1.0447, 1.0575, 1.0530, 1.0380,\n",
            "        1.0346, 1.0491, 1.0528, 1.0552, 1.0515, 1.0402, 1.0532, 1.0358, 1.0469,\n",
            "        1.0490, 1.0452, 1.0401, 1.0519, 1.0474, 1.0346, 1.0405, 1.0437, 1.0306,\n",
            "        1.0454, 1.0412, 1.0477, 1.0616, 1.0570, 1.0487, 1.0461, 1.0539, 1.0462,\n",
            "        1.0431, 1.0440, 1.0510, 1.0431, 1.0400, 1.0400, 1.0528, 1.0416, 1.0508,\n",
            "        1.0521, 1.0536, 1.0417, 1.0521, 1.0550, 1.0466, 1.0506, 1.0555, 1.0489,\n",
            "        1.0482, 1.0391], device='cuda:0')), ('inception_block_9.b3.7.bias', tensor([0.0289, 0.0303, 0.0317, 0.0225, 0.0353, 0.0214, 0.0240, 0.0089, 0.0224,\n",
            "        0.0174, 0.0278, 0.0203, 0.0235, 0.0221, 0.0276, 0.0201, 0.0262, 0.0317,\n",
            "        0.0284, 0.0301, 0.0191, 0.0246, 0.0261, 0.0178, 0.0289, 0.0288, 0.0228,\n",
            "        0.0153, 0.0201, 0.0183, 0.0201, 0.0234, 0.0276, 0.0239, 0.0277, 0.0308,\n",
            "        0.0202, 0.0223, 0.0182, 0.0197, 0.0295, 0.0205, 0.0205, 0.0219, 0.0299,\n",
            "        0.0246, 0.0232, 0.0241, 0.0288, 0.0282, 0.0229, 0.0344, 0.0258, 0.0158,\n",
            "        0.0262, 0.0201, 0.0249, 0.0312, 0.0291, 0.0307, 0.0247, 0.0207, 0.0210,\n",
            "        0.0297, 0.0215, 0.0225, 0.0243, 0.0185, 0.0282, 0.0237, 0.0268, 0.0245,\n",
            "        0.0250, 0.0306, 0.0265, 0.0211, 0.0296, 0.0230, 0.0342, 0.0274, 0.0197,\n",
            "        0.0180, 0.0232, 0.0236, 0.0320, 0.0238, 0.0227, 0.0351, 0.0182, 0.0233,\n",
            "        0.0287, 0.0260, 0.0201, 0.0306, 0.0265, 0.0179, 0.0213, 0.0243, 0.0141,\n",
            "        0.0247, 0.0169, 0.0224, 0.0317, 0.0311, 0.0307, 0.0242, 0.0295, 0.0237,\n",
            "        0.0240, 0.0245, 0.0287, 0.0235, 0.0242, 0.0254, 0.0334, 0.0250, 0.0309,\n",
            "        0.0282, 0.0302, 0.0242, 0.0297, 0.0251, 0.0277, 0.0276, 0.0300, 0.0255,\n",
            "        0.0266, 0.0193], device='cuda:0')), ('inception_block_9.b3.7.running_mean', tensor([-0.1473, -0.1820,  0.3340,  0.4120,  0.0708,  0.0042,  0.2088,  0.0859,\n",
            "         0.1152,  0.1770,  0.2125,  0.1738,  0.1303, -0.0129,  0.2025, -0.0201,\n",
            "         0.1009,  0.0831,  0.1164,  0.2832,  0.1775,  0.1718,  0.1301,  0.2038,\n",
            "         0.1891,  0.0195,  0.0627, -0.1435,  0.2110, -0.0849,  0.2536, -0.1355,\n",
            "         0.1399,  0.0527,  0.1593,  0.1534,  0.2013,  0.0285,  0.0230,  0.4951,\n",
            "         0.0881,  0.3559, -0.1808,  0.1409,  0.1701,  0.3115,  0.0379, -0.0578,\n",
            "         0.3516,  0.0981, -0.0043,  0.0945,  0.2987, -0.1355,  0.0665,  0.0634,\n",
            "         0.0482, -0.0105,  0.1228,  0.0495,  0.4202, -0.1213,  0.2840, -0.0439,\n",
            "         0.1036,  0.1520,  0.2224,  0.0569,  0.2474,  0.1950, -0.0250,  0.1577,\n",
            "         0.2419,  0.0047,  0.1221, -0.0951, -0.0341,  0.0376,  0.0503,  0.1751,\n",
            "         0.1106, -0.0202, -0.0062, -0.0753, -0.1419,  0.0124,  0.1462,  0.0750,\n",
            "         0.0397,  0.3516,  0.0320, -0.1114,  0.0598,  0.1659,  0.2669,  0.1202,\n",
            "         0.2960, -0.1417, -0.0717,  0.0967,  0.4608,  0.0348, -0.1619,  0.0720,\n",
            "         0.1506,  0.0424,  0.1302,  0.0876,  0.0584, -0.0355,  0.1370,  0.0702,\n",
            "         0.3262,  0.4833,  0.0957, -0.0572,  0.0851,  0.1285,  0.1582,  0.2267,\n",
            "         0.0318, -0.0354,  0.3487,  0.3582, -0.0218,  0.0951,  0.0884,  0.0551],\n",
            "       device='cuda:0')), ('inception_block_9.b3.7.running_var', tensor([0.4835, 0.6395, 0.6983, 0.8126, 0.5624, 0.5653, 0.6460, 0.8352, 0.4740,\n",
            "        0.6700, 0.6526, 0.6615, 0.5463, 0.5765, 0.6415, 0.4881, 0.5585, 0.6395,\n",
            "        0.4934, 0.4887, 0.5961, 0.6916, 0.5168, 0.5558, 0.7181, 0.6232, 0.6957,\n",
            "        0.3956, 0.6484, 0.5182, 0.6880, 0.5626, 0.4533, 0.4776, 0.7058, 0.5099,\n",
            "        0.4836, 0.3757, 0.6370, 0.7464, 0.5971, 0.5650, 0.4064, 0.6381, 0.7330,\n",
            "        0.6117, 0.5723, 0.4695, 0.7609, 0.4558, 0.6286, 0.6207, 0.5307, 0.4390,\n",
            "        0.4924, 0.4101, 0.4934, 0.5761, 0.5983, 0.6830, 0.7618, 0.4912, 0.4581,\n",
            "        0.5919, 0.7514, 0.7063, 0.6746, 0.5288, 0.5976, 0.5637, 0.6043, 0.6112,\n",
            "        0.4535, 0.6676, 0.6201, 0.3993, 0.6477, 0.4264, 0.6007, 0.6628, 0.4474,\n",
            "        0.5023, 0.4674, 0.4253, 0.7081, 0.5604, 0.5339, 0.5654, 0.5065, 0.7333,\n",
            "        0.5549, 0.6324, 0.4174, 0.4208, 0.5545, 0.5435, 0.5417, 0.5950, 0.6517,\n",
            "        0.5030, 0.5672, 0.6108, 0.6081, 0.6008, 0.5175, 0.4254, 0.6636, 0.3762,\n",
            "        0.6295, 0.5544, 0.5273, 0.6218, 0.5806, 0.7988, 0.5208, 0.6637, 0.4145,\n",
            "        0.5974, 0.7626, 0.6201, 0.5940, 0.6140, 0.6921, 0.6851, 0.4571, 0.4500,\n",
            "        0.7553, 0.6650], device='cuda:0')), ('inception_block_9.b3.7.num_batches_tracked', tensor(9775, device='cuda:0')), ('inception_block_9.b4.1.weight', tensor([[[[ 0.0043]],\n",
            "\n",
            "         [[ 0.0216]],\n",
            "\n",
            "         [[ 0.0278]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0200]],\n",
            "\n",
            "         [[ 0.0141]],\n",
            "\n",
            "         [[ 0.0175]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0364]],\n",
            "\n",
            "         [[ 0.0181]],\n",
            "\n",
            "         [[ 0.0057]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0233]],\n",
            "\n",
            "         [[ 0.0049]],\n",
            "\n",
            "         [[-0.0239]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0369]],\n",
            "\n",
            "         [[ 0.0135]],\n",
            "\n",
            "         [[ 0.0265]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0067]],\n",
            "\n",
            "         [[-0.0288]],\n",
            "\n",
            "         [[-0.0152]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0098]],\n",
            "\n",
            "         [[ 0.0023]],\n",
            "\n",
            "         [[ 0.0027]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0375]],\n",
            "\n",
            "         [[-0.0045]],\n",
            "\n",
            "         [[-0.0237]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0077]],\n",
            "\n",
            "         [[-0.0159]],\n",
            "\n",
            "         [[-0.0181]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0135]],\n",
            "\n",
            "         [[-0.0136]],\n",
            "\n",
            "         [[ 0.0026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0295]],\n",
            "\n",
            "         [[ 0.0281]],\n",
            "\n",
            "         [[ 0.0277]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0301]],\n",
            "\n",
            "         [[-0.0247]],\n",
            "\n",
            "         [[-0.0134]]]], device='cuda:0')), ('inception_block_9.b4.1.bias', tensor([ 0.0239, -0.0322,  0.0207,  0.0099, -0.0073, -0.0094, -0.0247,  0.0227,\n",
            "        -0.0261, -0.0322, -0.0190,  0.0080,  0.0280,  0.0205, -0.0255,  0.0032,\n",
            "        -0.0005, -0.0144,  0.0051,  0.0263, -0.0234, -0.0332,  0.0241, -0.0019,\n",
            "         0.0233,  0.0315,  0.0206, -0.0128,  0.0333,  0.0215,  0.0081, -0.0199,\n",
            "        -0.0304, -0.0277,  0.0332,  0.0052,  0.0287,  0.0073,  0.0334, -0.0207,\n",
            "         0.0331,  0.0221,  0.0319, -0.0192,  0.0129, -0.0305,  0.0067,  0.0008,\n",
            "        -0.0340, -0.0160,  0.0025, -0.0206, -0.0212, -0.0029,  0.0271, -0.0134,\n",
            "        -0.0104,  0.0194,  0.0097,  0.0293, -0.0140, -0.0155,  0.0326, -0.0246,\n",
            "         0.0184,  0.0158,  0.0176, -0.0192, -0.0057, -0.0264, -0.0281, -0.0015,\n",
            "        -0.0327,  0.0010, -0.0025,  0.0240,  0.0289,  0.0235,  0.0147,  0.0144,\n",
            "         0.0173, -0.0301, -0.0328,  0.0067, -0.0216, -0.0178,  0.0269,  0.0135,\n",
            "        -0.0148,  0.0293,  0.0063,  0.0127, -0.0020,  0.0183, -0.0336,  0.0045,\n",
            "        -0.0067,  0.0285,  0.0247, -0.0258, -0.0226, -0.0256,  0.0034, -0.0036,\n",
            "         0.0288, -0.0129,  0.0174,  0.0213,  0.0106,  0.0117,  0.0233, -0.0325,\n",
            "         0.0321, -0.0334,  0.0169,  0.0345, -0.0163,  0.0235,  0.0020, -0.0311,\n",
            "         0.0185, -0.0090, -0.0162, -0.0257,  0.0313,  0.0325, -0.0007,  0.0181],\n",
            "       device='cuda:0')), ('inception_block_9.b4.2.weight', tensor([1.0335, 1.0503, 1.0219, 1.0378, 1.0471, 1.0384, 1.0286, 1.0391, 1.0329,\n",
            "        1.0387, 1.0317, 1.0351, 1.0308, 1.0435, 1.0377, 1.0412, 1.0322, 1.0384,\n",
            "        1.0442, 1.0443, 1.0324, 1.0377, 1.0596, 1.0353, 1.0401, 1.0418, 1.0405,\n",
            "        1.0358, 1.0232, 1.0445, 1.0375, 1.0372, 1.0574, 1.0245, 1.0298, 1.0398,\n",
            "        1.0311, 1.0368, 1.0341, 1.0294, 1.0310, 1.0440, 1.0304, 1.0428, 1.0345,\n",
            "        1.0337, 1.0377, 1.0397, 1.0302, 1.0417, 1.0368, 1.0570, 1.0404, 1.0343,\n",
            "        1.0579, 1.0344, 1.0398, 1.0486, 1.0490, 1.0371, 1.0400, 1.0404, 1.0317,\n",
            "        1.0436, 1.0414, 1.0376, 1.0396, 1.0413, 1.0346, 1.0479, 1.0355, 1.0443,\n",
            "        1.0628, 1.0340, 1.0326, 1.0443, 1.0455, 1.0296, 1.0458, 1.0256, 1.0335,\n",
            "        1.0450, 1.0451, 1.0324, 1.0283, 1.0267, 1.0359, 1.0332, 1.0469, 1.0373,\n",
            "        1.0367, 1.0427, 1.0260, 1.0282, 1.0298, 1.0387, 1.0422, 1.0320, 1.0415,\n",
            "        1.0308, 1.0410, 1.0343, 1.0327, 1.0429, 1.0445, 1.0375, 1.0293, 1.0409,\n",
            "        1.0480, 1.0482, 1.0433, 1.0341, 1.0411, 1.0383, 1.0381, 1.0283, 1.0400,\n",
            "        1.0580, 1.0407, 1.0307, 1.0386, 1.0323, 1.0390, 1.0403, 1.0396, 1.0451,\n",
            "        1.0538, 1.0285], device='cuda:0')), ('inception_block_9.b4.2.bias', tensor([0.0162, 0.0312, 0.0106, 0.0237, 0.0190, 0.0230, 0.0153, 0.0174, 0.0183,\n",
            "        0.0204, 0.0177, 0.0137, 0.0148, 0.0256, 0.0183, 0.0231, 0.0182, 0.0153,\n",
            "        0.0196, 0.0225, 0.0139, 0.0235, 0.0300, 0.0136, 0.0181, 0.0218, 0.0211,\n",
            "        0.0166, 0.0079, 0.0197, 0.0199, 0.0173, 0.0336, 0.0135, 0.0133, 0.0196,\n",
            "        0.0169, 0.0192, 0.0184, 0.0208, 0.0161, 0.0196, 0.0132, 0.0276, 0.0166,\n",
            "        0.0183, 0.0220, 0.0186, 0.0156, 0.0157, 0.0226, 0.0319, 0.0200, 0.0153,\n",
            "        0.0319, 0.0153, 0.0213, 0.0284, 0.0212, 0.0179, 0.0241, 0.0168, 0.0158,\n",
            "        0.0176, 0.0228, 0.0187, 0.0220, 0.0170, 0.0209, 0.0303, 0.0181, 0.0251,\n",
            "        0.0327, 0.0217, 0.0168, 0.0240, 0.0244, 0.0115, 0.0249, 0.0034, 0.0202,\n",
            "        0.0235, 0.0231, 0.0152, 0.0130, 0.0116, 0.0155, 0.0236, 0.0342, 0.0217,\n",
            "        0.0219, 0.0253, 0.0111, 0.0060, 0.0170, 0.0229, 0.0169, 0.0204, 0.0218,\n",
            "        0.0157, 0.0213, 0.0206, 0.0122, 0.0267, 0.0208, 0.0211, 0.0128, 0.0218,\n",
            "        0.0273, 0.0268, 0.0228, 0.0155, 0.0288, 0.0222, 0.0173, 0.0173, 0.0202,\n",
            "        0.0256, 0.0206, 0.0126, 0.0157, 0.0121, 0.0199, 0.0236, 0.0209, 0.0227,\n",
            "        0.0294, 0.0155], device='cuda:0')), ('inception_block_9.b4.2.running_mean', tensor([ 0.6598,  0.1114, -0.5335,  0.2317, -0.4359,  0.0345, -0.2485,  0.3915,\n",
            "        -0.0717,  0.4270, -0.0637,  0.1248,  0.3555,  0.3480,  0.7487, -0.1079,\n",
            "         0.2288,  0.6281,  0.0945,  0.4945, -0.0853,  0.2582,  0.2628,  0.4733,\n",
            "         0.5346,  0.8756,  0.5013,  0.3671,  0.0457,  0.5688,  0.5377,  0.1804,\n",
            "         0.0436,  0.4525,  0.6912, -0.2436,  0.7880,  0.1910, -0.0217, -0.1840,\n",
            "        -0.3850, -0.3715, -0.0028,  0.2457,  0.0788,  0.0182,  0.2590, -0.1270,\n",
            "         0.0310,  0.2540, -0.2098,  0.2379,  0.5445, -0.1116,  0.3440,  0.1930,\n",
            "         0.2009,  0.1732,  0.3459,  0.5283, -0.0039,  0.3650, -0.3076,  0.2768,\n",
            "        -0.0458,  0.4568,  0.6476,  0.4332,  0.6518,  0.2674, -0.3726,  0.0139,\n",
            "         0.0091,  0.5281, -0.1807, -0.0822, -0.6107, -0.2440, -0.1552,  0.1086,\n",
            "         0.1663,  0.3510,  0.3031,  0.0689, -0.4121,  0.4078,  0.3893,  0.3501,\n",
            "         0.4749,  0.1299, -0.0265,  0.6216,  0.1606,  0.0368, -0.1268, -0.4531,\n",
            "         0.3302,  0.2860,  0.2069,  0.3134, -0.1553,  0.0212,  0.4448,  0.1061,\n",
            "         0.3379,  0.3737, -0.6614,  0.3258, -0.1692,  0.2329,  0.2571,  0.6504,\n",
            "         0.1973, -0.0559,  0.7114,  0.1729,  0.3272,  0.1268, -0.1009,  0.5124,\n",
            "         0.1616, -0.3087,  0.4852, -0.0822,  0.3911,  0.3886,  0.4093, -0.1741],\n",
            "       device='cuda:0')), ('inception_block_9.b4.2.running_var', tensor([0.4012, 0.2950, 0.4008, 0.3608, 0.3656, 0.2512, 0.2802, 0.3055, 0.3231,\n",
            "        0.3303, 0.3930, 0.3440, 0.3231, 0.3920, 0.3605, 0.3372, 0.3096, 0.3793,\n",
            "        0.3019, 0.3110, 0.3996, 0.4299, 0.3373, 0.4000, 0.3513, 0.4200, 0.3577,\n",
            "        0.3333, 0.3033, 0.4221, 0.5012, 0.4076, 0.5004, 0.3037, 0.2939, 0.5045,\n",
            "        0.3147, 0.3947, 0.2781, 0.4808, 0.3803, 0.5355, 0.3535, 0.4077, 0.2798,\n",
            "        0.3652, 0.3904, 0.5247, 0.2863, 0.3453, 0.3342, 0.2559, 0.3686, 0.3745,\n",
            "        0.6074, 0.3236, 0.4588, 0.4417, 0.2963, 0.4033, 0.4173, 0.4329, 0.3405,\n",
            "        0.3921, 0.5148, 0.3725, 0.4090, 0.3196, 0.4016, 0.3296, 0.4288, 0.5229,\n",
            "        0.5789, 0.3907, 0.3101, 0.4849, 0.4599, 0.3134, 0.6367, 0.3193, 0.2525,\n",
            "        0.3394, 0.3654, 0.2667, 0.2688, 0.2890, 0.4939, 0.4620, 0.4547, 0.3413,\n",
            "        0.4050, 0.3110, 0.4510, 0.2943, 0.3899, 0.3808, 0.2983, 0.3953, 0.2810,\n",
            "        0.3733, 0.4012, 0.2582, 0.2626, 0.6822, 0.5002, 0.4272, 0.4098, 0.3333,\n",
            "        0.3886, 0.4484, 0.4231, 0.3195, 0.3104, 0.3582, 0.3278, 0.3285, 0.4784,\n",
            "        0.6130, 0.4403, 0.4393, 0.3031, 0.3486, 0.4141, 0.3715, 0.3371, 0.4316,\n",
            "        0.4506, 0.2653], device='cuda:0')), ('inception_block_9.b4.2.num_batches_tracked', tensor(9775, device='cuda:0')), ('fully_connected_layer.weight', tensor([[-0.0352, -0.0297, -0.0682,  ...,  0.0369, -0.0287,  0.0426],\n",
            "        [ 0.0396, -0.0450, -0.0358,  ...,  0.0108,  0.0367, -0.0446],\n",
            "        [-0.0613, -0.0139,  0.0040,  ...,  0.0453, -0.0148, -0.0351],\n",
            "        ...,\n",
            "        [-0.0242,  0.0377,  0.0247,  ..., -0.0476, -0.0583, -0.0517],\n",
            "        [ 0.0217, -0.0492, -0.0345,  ...,  0.0289,  0.0394,  0.0063],\n",
            "        [ 0.0229,  0.0098, -0.0428,  ..., -0.0298,  0.0161, -0.0421]],\n",
            "       device='cuda:0')), ('fully_connected_layer.bias', tensor([ 0.0005,  0.0145,  0.0221, -0.0231,  0.0194, -0.0197, -0.0048,  0.0267,\n",
            "         0.0200,  0.0292], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}